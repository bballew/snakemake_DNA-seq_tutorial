{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First things first, let's check our working directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pwd  # some bash commands will work without additional characters in Jupyter notebooks if automagic is on"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To build our pipeline, we'll need to make sure we have access to some dependencies first.  You have a few options here:\n",
    "1. Use the JupyterLab binder button on the [github repo](https://github.com/marskar/snakemake/tree/master).  All of the depenencies are included in the environment.yml file used to build the binder container.\n",
    "2. Install dependencies locally:\n",
    "    - Clone the repo (`git clone https://github.com/marskar/snakemake.git`)\n",
    "    - Use conda to install the dependencies locally (`conda install -c bioconda <tool=version>`)\n",
    "3. Create a local environment:\n",
    "    - Clone the repo (`git clone https://github.com/marskar/snakemake.git`)\n",
    "    - Use the environment file to build a conda environment locally (`conda env create -f environment.yml`)\n",
    "    - Be sure to start up `jupyter notebook` from within this environment!\n",
    "\n",
    "Let's check the versions of the dependencies to ensure they're there and accessible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if using option 3 above, check your environment:\n",
    "!conda env list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check that we have the required dependencies\n",
    "!conda list | grep -Ei \"snakemake|samtools|picard|bwa|gatk|python\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're going to start with FASTQ files from real human samples, but instead of whole genome data, we're focusing on chromosome 5, position 100000000-101500000.  Our reference genome file also only includes a portion of chr5 (5:99900000-104100000).  This is to keep file sizes small and run times short!  Now, let's make sure we can see the raw files we intend to work on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls -lh raw_data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what does a fastq look like?\n",
    "!head -n8 raw_data/Patient_A.r1.fastq  # to run a single line of bash, prepend with \"!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls -lh ref_genome/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what does a reference genome look like?\n",
    "!head -n4 ref_genome/chr5_ref.fasta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Goal:__ assemble a working DNA-seq pipeline!\n",
    "\n",
    "- Align sequencing data to a reference genome\n",
    "- Call variants in the aligned data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First rule: indexing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our first rule is going to take our reference genome file, and index it so that the alignment tool can read it.  We can write the rule in any text editor, but for this class, we'll write it here in the notebook and save it to a file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile snakefile_test1\n",
    "\n",
    "'''\n",
    "Commands to run:\n",
    "bwa index <ref> --> indices with the endings .amb, .ann, .bwt, .pac\n",
    "samtools faidx <ref> --> index with ending .fai\n",
    "picard CreateSequenceDictionary REFERENCE=<ref> OUTPUT=<file> --> index that removes the original ending and appends .dict\n",
    "''' \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test our first rule!  You can run this rule from the command line or here in the notebook using cell magic.  For our first test, we're going to try a __dry-run__ by using the `-n` flag.  If your snakefile is called something other than \"Snakefile,\" use `-s <filename>`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!snakemake -ns snakefile_test1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks great!  Note that the dry-run does not actually execute any jobs; it shows the execution plan.  \n",
    "\n",
    "Now let's try running our pipeline for real.  Add the `-p` flag to print the job that's run for each rule."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!snakemake -ps snakefile_test1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls -lh ref_genome"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hooray!!  Our first rule worked.  Note that Snakemake stdout provides a beautiful log of steps run and errors encountered.\n",
    "\n",
    "What happens if we try to run it again?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!snakemake -ps snakefile_test1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Second rule: alignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our next rule is going to take the short reads in our FASTQ files, and align them to a reference sequence using a tool called [__bwa__](https://github.com/lh3/bwa).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Command to run:\n",
    "bwa mem -R \"@RG\\tID:<readgroup>\\tSM:<sample>\\tPL:<seq_platform>\" <reference> <r1 fastq> <r2 fastq> | samtools sort -o <output file>\n",
    "\n",
    "bwa requires the indices with endings .amb, .ann, .bwt, .pac, and .sa be present.\n",
    "\n",
    "First, try it by hard-coding a sample name.\n",
    "'''\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note how not all the listed input files are actually needed in the command line, but they are required for the command to run successfully (i.e. bwa will give an error if the index files are not there).  Snakemake recommends that you include all file dependencies in the input section, even if they're not used in the command invocation.\n",
    "\n",
    "This is a good example of the use of `params` in a rule.  Here, they're used to define the metadata for the bam file.\n",
    "\n",
    "Hold up.  We don't want to hard-code our sample files into a pipeline, or else we have to change the code for every sample! How do we handle this?\n",
    "\n",
    "![xkcd](https://imgs.xkcd.com/comics/the_general_problem.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Now, try it again using a list of samples.\n",
    "'''\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What if we use a list, as above?  This would run an alignment on each fastq individually, which would be fine if we had single-end reads.  But, we have paired-end reads, which means you've sequenced in both directions, and you need to align two related fastq files per sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Now, try it using a dict.\n",
    "'''\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What if we use a dict?  Much better!  Now our `rule align_fastqs` is generalizable.  If you were using this pipeline in real life, you'd probably require the user to provide a sample file where each line has the sample name, fastq1, and fastq2, and you'd read that in to a dict (rather than explicitly defining a dict like we did).\n",
    "\n",
    "Note that input (or params) can be the return value of a function, as in this example.\n",
    "\n",
    "Let's put the two rules together, and then try running them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile snakefile_test2\n",
    "\n",
    "ref = 'ref_genome/chr5_ref.fasta'\n",
    "refNoExt = os.path.splitext(ref)[0]\n",
    "\n",
    "rawDataPath = 'raw_data/'\n",
    "sampleDict = {\n",
    "    'PatientA':['Patient_A.r1.fastq', 'Patient_A.r2.fastq'],\n",
    "    'PatientB':['Patient_B.r1.fastq', 'Patient_B.r2.fastq']\n",
    "}\n",
    "\n",
    "def get_read1_fastq(wildcards):\n",
    "    (read1, read2) = sampleDict[wildcards.sample]\n",
    "    return rawDataPath + read1\n",
    "\n",
    "def get_read2_fastq(wildcards):\n",
    "    (read1, read2) = sampleDict[wildcards.sample]\n",
    "    return rawDataPath + read2\n",
    "\n",
    "\n",
    "rule index_ref:\n",
    "    input:\n",
    "        ref\n",
    "    output:\n",
    "        o1 = ref + '.amb',\n",
    "        o2 = ref + '.ann',\n",
    "        o3 = ref + '.bwt',\n",
    "        o4 = ref + '.pac',\n",
    "        o5 = ref + '.sa',\n",
    "        o6 = ref + '.fai',\n",
    "        o7 = refNoExt + '.dict'\n",
    "    shell:\n",
    "        'bwa index {input};'\n",
    "        'samtools faidx {input};'\n",
    "        'picard CreateSequenceDictionary REFERENCE={input} OUTPUT={output.o7}'\n",
    "\n",
    "rule align_fastqs: \n",
    "    input:\n",
    "        ref = ref,\n",
    "        r1 = ref + '.amb',\n",
    "        r2 = ref + '.ann',\n",
    "        r3 = ref + '.bwt',\n",
    "        r4 = ref + '.pac',\n",
    "        r5 = ref + '.sa',\n",
    "        fq1 = get_read1_fastq,\n",
    "        fq2 = get_read2_fastq\n",
    "    output:\n",
    "        'aligned/{sample}.bam'\n",
    "    params:\n",
    "        pl = 'ILLUMINA',\n",
    "        rg = '{sample}_rg',\n",
    "        sm = '{sample}'\n",
    "    shell:\n",
    "        'bwa mem -R \"@RG\\tID:{params.rg}\\tSM:{params.sm}\\tPL:{params.pl}\" {input.ref} {input.fq1} {input.fq2} | samtools sort -o {output}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!snakemake -ps snakefile_test2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oh no!  What went wrong?  We haven't given snakemake a target file.  Let's add a `rule all`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile snakefile_test3\n",
    "\n",
    "ref = 'ref_genome/chr5_ref.fasta'\n",
    "refNoExt = os.path.splitext(ref)[0]\n",
    "\n",
    "rawDataPath = 'raw_data/'\n",
    "sampleDict = {\n",
    "    'PatientA':['Patient_A.r1.fastq', 'Patient_A.r2.fastq'],\n",
    "    'PatientB':['Patient_B.r1.fastq', 'Patient_B.r2.fastq']\n",
    "}\n",
    "\n",
    "def get_read1_fastq(wildcards):\n",
    "    (read1, read2) = sampleDict[wildcards.sample]\n",
    "    return rawDataPath + read1\n",
    "\n",
    "def get_read2_fastq(wildcards):\n",
    "    (read1, read2) = sampleDict[wildcards.sample]\n",
    "    return rawDataPath + read2\n",
    "\n",
    "\n",
    "rule all:\n",
    "    '''\n",
    "    What goes here?\n",
    "    '''\n",
    "\n",
    "rule index_ref:\n",
    "    input:\n",
    "        ref\n",
    "    output:\n",
    "        o1 = ref + '.amb',\n",
    "        o2 = ref + '.ann',\n",
    "        o3 = ref + '.bwt',\n",
    "        o4 = ref + '.pac',\n",
    "        o5 = ref + '.sa',\n",
    "        o6 = ref + '.fai',\n",
    "        o7 = refNoExt + '.dict'\n",
    "    shell:\n",
    "        'bwa index {input};'\n",
    "        'samtools faidx {input};'\n",
    "        'picard CreateSequenceDictionary REFERENCE={input} OUTPUT={output.o7}'\n",
    "\n",
    "rule align_fastqs: \n",
    "    input:\n",
    "        ref = ref,\n",
    "        r1 = ref + '.amb',\n",
    "        r2 = ref + '.ann',\n",
    "        r3 = ref + '.bwt',\n",
    "        r4 = ref + '.pac',\n",
    "        r5 = ref + '.sa',\n",
    "        fq1 = get_read1_fastq,\n",
    "        fq2 = get_read2_fastq\n",
    "    output:\n",
    "        'aligned/{sample}.bam'\n",
    "    params:\n",
    "        pl = 'ILLUMINA',\n",
    "        rg = '{sample}_rg',\n",
    "        sm = '{sample}'\n",
    "    shell:\n",
    "        'bwa mem -R \"@RG\\\\tID:{params.rg}\\\\tSM:{params.sm}\\\\tPL:{params.pl}\" {input.ref} {input.fq1} {input.fq2} | samtools sort -o {output}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now snakemake knows that `{sample}` should expand to PatientA and PatientB, and that the pipeline should end up producing the files `'aligned/{sample}.bam'`.  Let's try running it (this will take a minute or two):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!snakemake -ps snakefile_test3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls -lh aligned/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yay!  A few things of note:\n",
    "- We now have one aligned bam file per patient!\n",
    "- Snakemake automatically created the directory `aligned/` for us.\n",
    "- The stdout also includes a bunch of information from bwa.  There are ways to clean this up, but we're going to skip over that for now.\n",
    "- Snakemake saw that the indexed reference files were already created, so it did not re-run that rule."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Third rule: index bams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like the reference genome, the aligned bam files need to be indexed for the next tool to be able to read them.  We'll need to write the rule and update the rule all with the new target file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile snakefile_test4\n",
    "\n",
    "ref = 'ref_genome/chr5_ref.fasta'\n",
    "refNoExt = os.path.splitext(ref)[0]\n",
    "\n",
    "rawDataPath = 'raw_data/'\n",
    "sampleDict = {\n",
    "    'PatientA':['Patient_A.r1.fastq', 'Patient_A.r2.fastq'],\n",
    "    'PatientB':['Patient_B.r1.fastq', 'Patient_B.r2.fastq']\n",
    "}\n",
    "\n",
    "def get_read1_fastq(wildcards):\n",
    "    (read1, read2) = sampleDict[wildcards.sample]\n",
    "    return rawDataPath + read1\n",
    "\n",
    "def get_read2_fastq(wildcards):\n",
    "    (read1, read2) = sampleDict[wildcards.sample]\n",
    "    return rawDataPath + read2\n",
    "\n",
    "\n",
    "rule all:\n",
    "    input:\n",
    "        '''\n",
    "        What goes here?\n",
    "        '''\n",
    "\n",
    "rule index_ref:\n",
    "    input:\n",
    "        ref\n",
    "    output:\n",
    "        o1 = ref + '.amb',\n",
    "        o2 = ref + '.ann',\n",
    "        o3 = ref + '.bwt',\n",
    "        o4 = ref + '.pac',\n",
    "        o5 = ref + '.sa',\n",
    "        o6 = ref + '.fai',\n",
    "        o7 = refNoExt + '.dict'\n",
    "    shell:\n",
    "        'bwa index {input};'\n",
    "        'samtools faidx {input};'\n",
    "        'picard CreateSequenceDictionary REFERENCE={input} OUTPUT={output.o7}'\n",
    "\n",
    "rule align_fastqs: \n",
    "    input:\n",
    "        ref = ref,\n",
    "        r1 = ref + '.amb',\n",
    "        r2 = ref + '.ann',\n",
    "        r3 = ref + '.bwt',\n",
    "        r4 = ref + '.pac',\n",
    "        r5 = ref + '.sa',\n",
    "        fq1 = get_read1_fastq,\n",
    "        fq2 = get_read2_fastq\n",
    "    output:\n",
    "        'aligned/{sample}.bam'\n",
    "    params:\n",
    "        pl = 'ILLUMINA',\n",
    "        rg = '{sample}_rg',\n",
    "        sm = '{sample}'\n",
    "    shell:\n",
    "        'bwa mem -R \"@RG\\\\tID:{params.rg}\\\\tSM:{params.sm}\\\\tPL:{params.pl}\" {input.ref} {input.fq1} {input.fq2} | samtools sort -o {output}'\n",
    "\n",
    "'''\n",
    "Command to run:\n",
    "samtools index <input file>  --> index with ending .bai\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!snakemake -ps snakefile_test4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls -lh aligned/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fourth rule: calling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This fourth rule will compare our aligned sequences to the reference genome, look at places where there's a discrepancy, and report back those variants.  We'll need to write the rule and update the rule all with the new target file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile snakefile_test5\n",
    "\n",
    "ref = 'ref_genome/chr5_ref.fasta'\n",
    "refNoExt = os.path.splitext(ref)[0]\n",
    "\n",
    "rawDataPath = 'raw_data/'\n",
    "sampleDict = {\n",
    "    'PatientA':['Patient_A.r1.fastq', 'Patient_A.r2.fastq'],\n",
    "    'PatientB':['Patient_B.r1.fastq', 'Patient_B.r2.fastq']\n",
    "}\n",
    "\n",
    "def get_read1_fastq(wildcards):\n",
    "    (read1, read2) = sampleDict[wildcards.sample]\n",
    "    return rawDataPath + read1\n",
    "\n",
    "def get_read2_fastq(wildcards):\n",
    "    (read1, read2) = sampleDict[wildcards.sample]\n",
    "    return rawDataPath + read2\n",
    "\n",
    "\n",
    "rule all:\n",
    "    input:\n",
    "        '''\n",
    "        What goes here?\n",
    "        '''\n",
    "\n",
    "rule index_ref:\n",
    "    input:\n",
    "        ref\n",
    "    output:\n",
    "        o1 = ref + '.amb',\n",
    "        o2 = ref + '.ann',\n",
    "        o3 = ref + '.bwt',\n",
    "        o4 = ref + '.pac',\n",
    "        o5 = ref + '.sa',\n",
    "        o6 = ref + '.fai',\n",
    "        o7 = refNoExt + '.dict'\n",
    "    shell:\n",
    "        'bwa index {input};'\n",
    "        'samtools faidx {input};'\n",
    "        'picard CreateSequenceDictionary REFERENCE={input} OUTPUT={output.o7}'\n",
    "\n",
    "rule align_fastqs: \n",
    "    input:\n",
    "        ref = ref,\n",
    "        r1 = ref + '.amb',\n",
    "        r2 = ref + '.ann',\n",
    "        r3 = ref + '.bwt',\n",
    "        r4 = ref + '.pac',\n",
    "        r5 = ref + '.sa',\n",
    "        fq1 = get_read1_fastq,\n",
    "        fq2 = get_read2_fastq\n",
    "    output:\n",
    "        'aligned/{sample}.bam'\n",
    "    params:\n",
    "        pl = 'ILLUMINA',\n",
    "        rg = '{sample}_rg',\n",
    "        sm = '{sample}'\n",
    "    shell:\n",
    "        'bwa mem -R \"@RG\\\\tID:{params.rg}\\\\tSM:{params.sm}\\\\tPL:{params.pl}\" {input.ref} {input.fq1} {input.fq2} | samtools sort -o {output}'\n",
    "        \n",
    "rule index_bams:\n",
    "    input:\n",
    "        'aligned/{sample}.bam'\n",
    "    output:\n",
    "        'aligned/{sample}.bam.bai'\n",
    "    shell:\n",
    "        'samtools index {input}'\n",
    "        \n",
    "        \n",
    "'''\n",
    "Command to run:\n",
    "gatk HaplotypeCaller -I <input file> -O <output file> -R <reference>\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!snakemake -ps snakefile_test5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls -lh called/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!grep -A5 \"^#CHROM\" called/PatientA.vcf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Put it all together"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add some comments and save the finalized pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile Genomics_pipeline\n",
    "\n",
    "# AUTHOR: BB\n",
    "\n",
    "'''\n",
    "\n",
    "'''\n",
    "\n",
    "# get user data:\n",
    "ref = 'ref_genome/chr5_ref.fasta'\n",
    "refNoExt = os.path.splitext(ref)[0]\n",
    "\n",
    "rawDataPath = 'raw_data/'\n",
    "sampleDict = {\n",
    "    'PatientA':['Patient_A.r1.fastq', 'Patient_A.r2.fastq'],\n",
    "    'PatientB':['Patient_B.r1.fastq', 'Patient_B.r2.fastq']\n",
    "}\n",
    "\n",
    "def get_read1_fastq(wildcards):\n",
    "    (read1, read2) = sampleDict[wildcards.sample]\n",
    "    return rawDataPath + read1\n",
    "\n",
    "def get_read2_fastq(wildcards):\n",
    "    (read1, read2) = sampleDict[wildcards.sample]\n",
    "    return rawDataPath + read2\n",
    "\n",
    "\n",
    "rule all:\n",
    "    input:\n",
    "        expand('called/{sample}.vcf', sample=sampleDict.keys())\n",
    "\n",
    "rule index_ref:\n",
    "    '''\n",
    "    \n",
    "    '''\n",
    "    input:\n",
    "        ref\n",
    "    output:\n",
    "        o1 = ref + '.amb',\n",
    "        o2 = ref + '.ann',\n",
    "        o3 = ref + '.bwt',\n",
    "        o4 = ref + '.pac',\n",
    "        o5 = ref + '.sa',\n",
    "        o6 = ref + '.fai',\n",
    "        o7 = refNoExt + '.dict'\n",
    "    shell:\n",
    "        'bwa index {input};'\n",
    "        'samtools faidx {input};'\n",
    "        'picard CreateSequenceDictionary REFERENCE={input} OUTPUT={output.o7}'\n",
    "\n",
    "rule align_fastqs: \n",
    "    '''\n",
    "\n",
    "    \n",
    "    bwa complains if using literal tabs, so\n",
    "    make sure your snakemake command prints\n",
    "    \"\\t\".\n",
    "    '''\n",
    "    input:\n",
    "        ref = ref,\n",
    "        r1 = ref + '.amb',\n",
    "        r2 = ref + '.ann',\n",
    "        r3 = ref + '.bwt',\n",
    "        r4 = ref + '.pac',\n",
    "        r5 = ref + '.sa',\n",
    "        fq1 = get_read1_fastq,\n",
    "        fq2 = get_read2_fastq\n",
    "    output:\n",
    "        'aligned/{sample}.bam'\n",
    "    params:\n",
    "        pl = 'ILLUMINA',\n",
    "        rg = '{sample}_rg',\n",
    "        sm = '{sample}'\n",
    "    shell:\n",
    "        'bwa mem -R \"@RG\\\\tID:{params.rg}\\\\tSM:{params.sm}\\\\tPL:{params.pl}\" {input.ref} {input.fq1} {input.fq2} | samtools sort -o {output}'\n",
    "        \n",
    "rule index_bams:\n",
    "    '''\n",
    "\n",
    "    '''\n",
    "    input:\n",
    "        'aligned/{sample}.bam'\n",
    "    output:\n",
    "        'aligned/{sample}.bam.bai'\n",
    "    shell:\n",
    "        'samtools index {input}'\n",
    "        \n",
    "rule call_variants:\n",
    "    '''\n",
    "\n",
    "    '''\n",
    "    input:\n",
    "        ref = ref,\n",
    "        r1 = ref + '.fai',\n",
    "        r2 = refNoExt + '.dict',\n",
    "        bam = 'aligned/{sample}.bam',\n",
    "        bai = 'aligned/{sample}.bam.bai'\n",
    "    output:\n",
    "        'called/{sample}.vcf'\n",
    "    shell:\n",
    "        'gatk HaplotypeCaller -I {input.bam} -O {output} -R {input.ref}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's remove all the files we've generated and run the pipeline as one sequence of rules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rm -r aligned/ called/ ref_genome/chr5_ref.dict ref_genome/chr5_ref.fasta.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's do a dry-run of our complete pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!snakemake -nps Genomics_pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great!  Now let's see the DAG (directed acyclic graph)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!snakemake -nps Genomics_pipeline --dag | dot -Tsvg > dag2.svg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![dag](dag2.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks good - no unexpected recursion or weird relationships.  Now let's run it for real!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!snakemake -ps Genomics_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take a peek at the final output files\n",
    "!for i in called/Patient*vcf; do echo $i; grep -A5 \"^#CHROM\" $i; echo \"\"; done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many variants were called for each patient?\n",
    "!grep -cv \"^#\" called/*vcf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
