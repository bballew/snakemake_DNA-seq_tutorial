{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First things first, let's check our working directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/ballewbj/snakemake_class/snakemake/Genomics_practice'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd  # some bash commands will work without additional characters in Jupyter notebooks if automagic is on"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To build our pipeline, we'll need to make sure we have access to some dependencies first.  You have a few options here:\n",
    "1. Use the JupyterLab binder button on the [github repo](https://github.com/marskar/snakemake/tree/master).  All of the depenencies are included in the environment.yml file used to build the binder container.\n",
    "2. Install dependencies locally:\n",
    "    - Clone the repo (`git clone https://github.com/marskar/snakemake.git`)\n",
    "    - Use conda to install the dependencies locally (`conda install -c bioconda <tool=version>`)\n",
    "3. Create a local environment:\n",
    "    - Clone the repo (`git clone https://github.com/marskar/snakemake.git`)\n",
    "    - Use the environment file to build a conda environment locally (`conda env create -f environment.yml`)\n",
    "    - Be sure to start up `jupyter notebook` from within this environment!\n",
    "\n",
    "Let's check the versions of the dependencies to ensure they're there and accessible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# conda environments:\r\n",
      "#\r\n",
      "base                     /anaconda3\r\n",
      "snakemake_class       *  /anaconda3/envs/snakemake_class\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "# if using option 3 above, check your environment:\n",
    "!conda env list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# packages in environment at /anaconda3/envs/snakemake_class:\r\n",
      "bwa                       0.7.17               ha441bb4_5    bioconda\r\n",
      "gatk4                     4.1.1.0                       0    bioconda\r\n",
      "gitpython                 2.1.11                     py_0    conda-forge\r\n",
      "picard                    2.19.0                        0    bioconda\r\n",
      "python                    3.6.7             h8dc6b48_1004    conda-forge\r\n",
      "python-dateutil           2.8.0                      py_0    conda-forge\r\n",
      "python-irodsclient        0.7.0                      py_0    conda-forge\r\n",
      "samtools                  1.9                 h7c4ea83_11    bioconda\r\n",
      "snakemake                 5.4.5                         0    bioconda\r\n",
      "snakemake-minimal         5.4.5                      py_0    bioconda\r\n"
     ]
    }
   ],
   "source": [
    "# check that we have the required dependencies\n",
    "!conda list | grep -Ei \"snakemake|samtools|picard|bwa|gatk|python\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're going to start with FASTQ files from real human samples, but instead of whole genome data, we're focusing on chromosome 5, position 100000000-101500000.  Our reference genome file also only includes a portion of chr5 (5:99900000-104100000).  This is to keep file sizes small and run times short!  Now, let's make sure we can see the raw files we intend to work on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 581168\r\n",
      "-rw-r--r--  1 ballewbj  NIH\\Domain Users    66M Apr 18 11:24 Patient_A.r1.fastq\r\n",
      "-rw-r--r--  1 ballewbj  NIH\\Domain Users    66M Apr 18 11:24 Patient_A.r2.fastq\r\n",
      "-rw-r--r--  1 ballewbj  NIH\\Domain Users    76M Apr 18 11:24 Patient_B.r1.fastq\r\n",
      "-rw-r--r--  1 ballewbj  NIH\\Domain Users    76M Apr 18 11:24 Patient_B.r2.fastq\r\n"
     ]
    }
   ],
   "source": [
    "ls -lh raw_data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@E00572:97:H5YN2CCXY:5:1101:1773:44327/1\r\n",
      "GATGGAGATGAGGAACTTGATGGAAACTGGAGCAAACGTGACTCTTGTTATGCTTTAGCAAAAATACCGGCAGGATTTTGTCCCTGCCCTAGAGATCTGTGGAATTTTGAACTTGAGAGAGAGGATTTAGAGCATCTGCCCCAAGAAAAT\r\n",
      "+\r\n",
      "<AAFF<JFFFFJJFJJJJ<JJJJFJJJJF-FJJ7FJFFJJJJJFJJJJJJJFJJJJJJ77FFFJJFFFJ<JFFF7-FFJJJFJJJFFFJJJ-7--<<FJJJJ--AA<-<7<F<7F--7A77J-7A-FF-<<A--7F<F--)-)))----7\r\n",
      "@E00572:97:H5YN2CCXY:5:1101:1803:49127/1\r\n",
      "GCCAAGGGAACCCCCAGCCCTACCCAGGGAAACCGGGAGTGATTGTGTAACTCCAGGAAACCATGCTTCTACCATGGATCTTTGCAACCCATGGATCAGGAGATCCCCCTGTGAGCTCATGCCACCAGGACCTTGGGTCTGACACACAGC\r\n",
      "+\r\n",
      "AAAAFJJJF<FJ-FJAFFJJJA<FFJAFFFFFFJJFAAJJJJJJFJJJFJJFJJJFJFJJJJJJJJJJJJJJJJJJFFJJJJJFA<7JFAAFJJ-AF7FFFJ-FF-F-AF<J77-A-7F-7FF-AA<JA<A-<<A)-AAF<F<FF--A7)\r\n"
     ]
    }
   ],
   "source": [
    "# what does a fastq look like?\n",
    "!head -n8 raw_data/Patient_A.r1.fastq  # to run a single line of bash, prepend with \"!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 8344\r\n",
      "-rw-r--r--  1 ballewbj  NIH\\Domain Users   4.1M Apr 18 14:00 chr5_ref.fasta\r\n"
     ]
    }
   ],
   "source": [
    "ls -lh ref_genome/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">5\r\n",
      "AATAGGAAATCAAAGGGAATTTTAAGAGCTATTTTGAGACAAAAAAAAAATGGCATAACA\r\n",
      "AAACTTATGGGATGCAGCAAAAGCATTGCTAGGAGAGAAGTTTATAGCAATAAATGCTTA\r\n",
      "TGCTATGAAAGAAGAAAGACTTCAAATAAACAACCTAGCTTTACCCTTTCAGAAAGTGGC\r\n"
     ]
    }
   ],
   "source": [
    "# what does a reference genome look like?\n",
    "!head -n4 ref_genome/chr5_ref.fasta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Goal:__ assemble a working DNA-seq pipeline!\n",
    "\n",
    "- Align sequencing data to a reference genome\n",
    "- Call variants in the aligned data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First rule: indexing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our first rule is going to take our reference genome file, and index it so that the alignment tool can read it.  We can write the rule in any text editor, but for this class, we'll write it here in the notebook and save it to a file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing snakefile_test1\n"
     ]
    }
   ],
   "source": [
    "%%writefile snakefile_test1\n",
    "\n",
    "ref = 'ref_genome/chr5_ref.fasta'\n",
    "refNoExt = os.path.splitext(ref)[0]\n",
    "\n",
    "rule index_ref:\n",
    "    input:\n",
    "        ref\n",
    "    output:\n",
    "        o1 = ref + '.amb',\n",
    "        o2 = ref + '.ann',\n",
    "        o3 = ref + '.bwt',\n",
    "        o4 = ref + '.pac',\n",
    "        o5 = ref + '.sa',\n",
    "        o6 = ref + '.fai',\n",
    "        o7 = refNoExt + '.dict'\n",
    "    shell:\n",
    "        'bwa index {input};'\n",
    "        'samtools faidx {input};'\n",
    "        'picard CreateSequenceDictionary REFERENCE={input} OUTPUT={output.o7}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test our first rule!  You can run this rule from the command line or here in the notebook using cell magic.  For our first test, we're going to try a __dry-run__ by using the `-n` flag.  If your snakefile is called something other than \"Snakefile,\" use `-s <filename>`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mBuilding DAG of jobs...\u001b[0m\r\n",
      "\u001b[33mJob counts:\r\n",
      "\tcount\tjobs\r\n",
      "\t1\tindex_ref\r\n",
      "\t1\u001b[0m\r\n",
      "\u001b[32m\u001b[0m\r\n",
      "\u001b[32m[Thu Apr 18 14:20:06 2019]\u001b[0m\r\n",
      "\u001b[32mrule index_ref:\r\n",
      "    input: ref_genome/chr5_ref.fasta\r\n",
      "    output: ref_genome/chr5_ref.fasta.amb, ref_genome/chr5_ref.fasta.ann, ref_genome/chr5_ref.fasta.bwt, ref_genome/chr5_ref.fasta.pac, ref_genome/chr5_ref.fasta.sa, ref_genome/chr5_ref.fasta.fai, ref_genome/chr5_ref.dict\r\n",
      "    jobid: 0\u001b[0m\r\n",
      "\u001b[32m\u001b[0m\r\n",
      "\u001b[33mJob counts:\r\n",
      "\tcount\tjobs\r\n",
      "\t1\tindex_ref\r\n",
      "\t1\u001b[0m\r\n",
      "\u001b[33mThis was a dry-run (flag -n). The order of jobs does not reflect the order of execution.\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!snakemake -ns snakefile_test1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks great!  Note that the dry-run does not actually execute any jobs; it shows the execution plan.  \n",
    "\n",
    "Now let's try running our pipeline for real.  Add the `-p` flag to print the job that's run for each rule."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mBuilding DAG of jobs...\u001b[0m\n",
      "\u001b[33mUsing shell: /bin/bash\u001b[0m\n",
      "\u001b[33mProvided cores: 1\u001b[0m\n",
      "\u001b[33mRules claiming more threads will be scaled down.\u001b[0m\n",
      "\u001b[33mJob counts:\n",
      "\tcount\tjobs\n",
      "\t1\tindex_ref\n",
      "\t1\u001b[0m\n",
      "\u001b[32m\u001b[0m\n",
      "\u001b[32m[Thu Apr 18 14:20:10 2019]\u001b[0m\n",
      "\u001b[32mrule index_ref:\n",
      "    input: ref_genome/chr5_ref.fasta\n",
      "    output: ref_genome/chr5_ref.fasta.amb, ref_genome/chr5_ref.fasta.ann, ref_genome/chr5_ref.fasta.bwt, ref_genome/chr5_ref.fasta.pac, ref_genome/chr5_ref.fasta.sa, ref_genome/chr5_ref.fasta.fai, ref_genome/chr5_ref.dict\n",
      "    jobid: 0\u001b[0m\n",
      "\u001b[32m\u001b[0m\n",
      "\u001b[33mbwa index ref_genome/chr5_ref.fasta;samtools faidx ref_genome/chr5_ref.fasta;picard CreateSequenceDictionary REFERENCE=ref_genome/chr5_ref.fasta OUTPUT=ref_genome/chr5_ref.dict\u001b[0m\n",
      "[bwa_index] Pack FASTA... 0.03 sec\n",
      "[bwa_index] Construct BWT for the packed sequence...\n",
      "[bwa_index] 0.99 seconds elapse.\n",
      "[bwa_index] Update BWT... 0.02 sec\n",
      "[bwa_index] Pack forward-only FASTA... 0.02 sec\n",
      "[bwa_index] Construct SA from BWT and Occ... 0.32 sec\n",
      "[main] Version: 0.7.17-r1188\n",
      "[main] CMD: bwa index ref_genome/chr5_ref.fasta\n",
      "[main] Real time: 1.396 sec; CPU: 1.382 sec\n",
      "INFO\t2019-04-18 14:20:12\tCreateSequenceDictionary\t\n",
      "\n",
      "********** NOTE: Picard's command line syntax is changing.\n",
      "**********\n",
      "********** For more information, please see:\n",
      "********** https://github.com/broadinstitute/picard/wiki/Command-Line-Syntax-Transition-For-Users-(Pre-Transition)\n",
      "**********\n",
      "********** The command line looks like this in the new syntax:\n",
      "**********\n",
      "**********    CreateSequenceDictionary -REFERENCE ref_genome/chr5_ref.fasta -OUTPUT ref_genome/chr5_ref.dict\n",
      "**********\n",
      "\n",
      "\n",
      "14:20:12.314 INFO  NativeLibraryLoader - Loading libgkl_compression.dylib from jar:file:/anaconda3/envs/snakemake_class/share/picard-2.19.0-0/picard.jar!/com/intel/gkl/native/libgkl_compression.dylib\n",
      "[Thu Apr 18 14:20:12 EDT 2019] CreateSequenceDictionary OUTPUT=ref_genome/chr5_ref.dict REFERENCE=ref_genome/chr5_ref.fasta    TRUNCATE_NAMES_AT_WHITESPACE=true NUM_SEQUENCES=2147483647 VERBOSITY=INFO QUIET=false VALIDATION_STRINGENCY=STRICT COMPRESSION_LEVEL=5 MAX_RECORDS_IN_RAM=500000 CREATE_INDEX=false CREATE_MD5_FILE=false GA4GH_CLIENT_SECRETS=client_secrets.json USE_JDK_DEFLATER=false USE_JDK_INFLATER=false\n",
      "[Thu Apr 18 14:20:12 EDT 2019] Executing as ballewbj@NCI-02034622-ML on Mac OS X 10.13.6 x86_64; OpenJDK 64-Bit Server VM 1.8.0_192-b01; Deflater: Intel; Inflater: Intel; Provider GCS is not available; Picard version: 2.19.0-SNAPSHOT\n",
      "[Thu Apr 18 14:20:12 EDT 2019] picard.sam.CreateSequenceDictionary done. Elapsed time: 0.00 minutes.\n",
      "Runtime.totalMemory()=514850816\n",
      "\u001b[32m[Thu Apr 18 14:20:12 2019]\u001b[0m\n",
      "\u001b[32mFinished job 0.\u001b[0m\n",
      "\u001b[32m1 of 1 steps (100%) done\u001b[0m\n",
      "\u001b[33mComplete log: /Users/ballewbj/snakemake_class/snakemake/Genomics_practice/.snakemake/log/2019-04-18T142010.120667.snakemake.log\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!snakemake -ps snakefile_test1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 22864\r\n",
      "-rw-r--r--  1 ballewbj  NIH\\Domain Users   161B Apr 18 14:20 chr5_ref.dict\r\n",
      "-rw-r--r--  1 ballewbj  NIH\\Domain Users   4.1M Apr 18 14:00 chr5_ref.fasta\r\n",
      "-rw-r--r--  1 ballewbj  NIH\\Domain Users    12B Apr 18 14:20 chr5_ref.fasta.amb\r\n",
      "-rw-r--r--  1 ballewbj  NIH\\Domain Users    36B Apr 18 14:20 chr5_ref.fasta.ann\r\n",
      "-rw-r--r--  1 ballewbj  NIH\\Domain Users   4.0M Apr 18 14:20 chr5_ref.fasta.bwt\r\n",
      "-rw-r--r--  1 ballewbj  NIH\\Domain Users    18B Apr 18 14:20 chr5_ref.fasta.fai\r\n",
      "-rw-r--r--  1 ballewbj  NIH\\Domain Users   1.0M Apr 18 14:20 chr5_ref.fasta.pac\r\n",
      "-rw-r--r--  1 ballewbj  NIH\\Domain Users   2.0M Apr 18 14:20 chr5_ref.fasta.sa\r\n"
     ]
    }
   ],
   "source": [
    "ls -lh ref_genome"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hooray!!  Our first rule worked.  Note that Snakemake stdout provides a beautiful log of steps run and errors encountered.\n",
    "\n",
    "What happens if we try to run it again?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mBuilding DAG of jobs...\u001b[0m\r\n",
      "\u001b[33mNothing to be done.\u001b[0m\r\n",
      "\u001b[33mComplete log: /Users/ballewbj/snakemake_class/snakemake/Genomics_practice/.snakemake/log/2019-04-18T142020.949510.snakemake.log\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!snakemake -ps snakefile_test1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Second rule: alignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our next rule is going to take the short reads in our FASTQ files, and align them to a reference sequence using a tool called [__bwa__](https://github.com/lh3/bwa).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rule align_fastqs: \n",
    "    input:\n",
    "        ref = ref,\n",
    "        r1 = ref + '.amb',\n",
    "        r2 = ref + '.ann',\n",
    "        r3 = ref + '.bwt',\n",
    "        r4 = ref + '.pac',\n",
    "        r5 = ref + '.sa',\n",
    "        fq1 = 'raw_data/Patient_A.r1.fastq',\n",
    "        fq2 = 'raw_data/Patient_A.r2.fastq'\n",
    "    output:\n",
    "        'aligned/PatientA.bam'\n",
    "    params:\n",
    "        pl = 'ILLUMINA',\n",
    "        rg = 'PatientA_rg',\n",
    "        sm = 'PatientA'\n",
    "    shell:\n",
    "        'bwa mem -R \"@RG\\tID:{params.rg}\\tSM:{params.sm}\\tPL:{params.pl}\" {input.ref} {input.fq1} {input.fq2} | samtools sort -o {output}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note how not all the listed input files are actually needed in the command line, but they are required for the command to run successfully (i.e. bwa will give an error if the index files are not there).  Snakemake recommends that you include all file dependencies in the input section, even if they're not used in the command invocation.\n",
    "\n",
    "This is a good example of the use of `params` in a rule.  Here, they're used to define the metadata for the bam file.\n",
    "\n",
    "Hold up.  We don't want to hard-code our sample files into a pipeline, or else we have to change the code for every sample! How do we handle this?\n",
    "\n",
    "![xkcd](https://imgs.xkcd.com/comics/the_general_problem.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLES = ['Patient_A.r1', 'Patient_A.r2', 'Patient_B.r1', 'Patient_B.r2',]\n",
    "\n",
    "rule align_fastqs: \n",
    "    input:\n",
    "        ref = ref,\n",
    "        r1 = ref + '.amb',\n",
    "        r2 = ref + '.ann',\n",
    "        r3 = ref + '.bwt',\n",
    "        r4 = ref + '.pac',\n",
    "        r5 = ref + '.sa',\n",
    "        fq = 'raw_data/{sample}.fastq'\n",
    "    output:\n",
    "        'aligned/{sample}.bam'\n",
    "    params:\n",
    "        pl = 'ILLUMINA',\n",
    "        rg = '{sample}_rg',\n",
    "        sm = '{sample}'\n",
    "    shell:\n",
    "        'bwa mem -R \"@RG\\tID:{params.rg}\\tSM:{params.sm}\\tPL:{params.pl}\" {input.ref} {input.fq} | samtools sort -o {output}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What if we use a list, as above?  This would run an alignment on each fastq individually, which would be fine if we had single-end reads.  But, we have paired-end reads, which means you've sequenced in both directions, and you need to align two related fastq files per sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rawDataPath = 'raw_data/'\n",
    "sampleDict = {\n",
    "    'PatientA':['Patient_A.r1.fastq', 'Patient_A.r2.fastq'],\n",
    "    'PatientB':['Patient_B.r1.fastq', 'Patient_B.r2.fastq']\n",
    "}\n",
    "\n",
    "def get_read1_fastq(wildcards):\n",
    "    (read1, read2) = sampleDict[wildcards.sample]\n",
    "    return rawDataPath + read1\n",
    "\n",
    "def get_read2_fastq(wildcards):\n",
    "    (read1, read2) = sampleDict[wildcards.sample]\n",
    "    return rawDataPath + read2\n",
    "\n",
    "rule align_fastqs: \n",
    "    input:\n",
    "        ref = ref,\n",
    "        r1 = ref + '.amb',\n",
    "        r2 = ref + '.ann',\n",
    "        r3 = ref + '.bwt',\n",
    "        r4 = ref + '.pac',\n",
    "        r5 = ref + '.sa',\n",
    "        fq1 = get_read1_fastq,\n",
    "        fq2 = get_read2_fastq\n",
    "    output:\n",
    "        'aligned/{sample}.bam'\n",
    "    params:\n",
    "        pl = 'ILLUMINA',\n",
    "        rg = '{sample}_rg',\n",
    "        sm = '{sample}'\n",
    "    shell:\n",
    "        'bwa mem -R \"@RG\\tID:{params.rg}\\tSM:{params.sm}\\tPL:{params.pl}\" {input.ref} {input.fq1} {input.fq2} | samtools sort -o {output}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What if we use a dict?  Much better!  Now our `rule align_fastqs` is generalizable.  If you were using this pipeline in real life, you'd probably require the user to provide a sample file where each line has the sample name, fastq1, and fastq2, and you'd read that in to a dict (rather than explicitly defining a dict like we did).\n",
    "\n",
    "Note that input (or params) can be the return value of a function, as in this example.\n",
    "\n",
    "Let's put the two rules together, and then try running them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing snakefile_test2\n"
     ]
    }
   ],
   "source": [
    "%%writefile snakefile_test2\n",
    "\n",
    "ref = 'ref_genome/chr5_ref.fasta'\n",
    "refNoExt = os.path.splitext(ref)[0]\n",
    "\n",
    "rawDataPath = 'raw_data/'\n",
    "sampleDict = {\n",
    "    'PatientA':['Patient_A.r1.fastq', 'Patient_A.r2.fastq'],\n",
    "    'PatientB':['Patient_B.r1.fastq', 'Patient_B.r2.fastq']\n",
    "}\n",
    "\n",
    "def get_read1_fastq(wildcards):\n",
    "    (read1, read2) = sampleDict[wildcards.sample]\n",
    "    return rawDataPath + read1\n",
    "\n",
    "def get_read2_fastq(wildcards):\n",
    "    (read1, read2) = sampleDict[wildcards.sample]\n",
    "    return rawDataPath + read2\n",
    "\n",
    "\n",
    "rule index_ref:\n",
    "    input:\n",
    "        ref\n",
    "    output:\n",
    "        o1 = ref + '.amb',\n",
    "        o2 = ref + '.ann',\n",
    "        o3 = ref + '.bwt',\n",
    "        o4 = ref + '.pac',\n",
    "        o5 = ref + '.sa',\n",
    "        o6 = ref + '.fai',\n",
    "        o7 = refNoExt + '.dict'\n",
    "    shell:\n",
    "        'bwa index {input};'\n",
    "        'samtools faidx {input};'\n",
    "        'picard CreateSequenceDictionary REFERENCE={input} OUTPUT={output.o7}'\n",
    "\n",
    "rule align_fastqs: \n",
    "    input:\n",
    "        ref = ref,\n",
    "        r1 = ref + '.amb',\n",
    "        r2 = ref + '.ann',\n",
    "        r3 = ref + '.bwt',\n",
    "        r4 = ref + '.pac',\n",
    "        r5 = ref + '.sa',\n",
    "        fq1 = get_read1_fastq,\n",
    "        fq2 = get_read2_fastq\n",
    "    output:\n",
    "        'aligned/{sample}.bam'\n",
    "    params:\n",
    "        pl = 'ILLUMINA',\n",
    "        rg = '{sample}_rg',\n",
    "        sm = '{sample}'\n",
    "    shell:\n",
    "        'bwa mem -R \"@RG\\tID:{params.rg}\\tSM:{params.sm}\\tPL:{params.pl}\" {input.ref} {input.fq1} {input.fq2} | samtools sort -o {output}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mBuilding DAG of jobs...\u001b[0m\n",
      "\u001b[33mNothing to be done.\u001b[0m\n",
      "\u001b[33mComplete log: /Users/ballewbj/snakemake_class/snakemake/Genomics_practice/.snakemake/log/2019-04-18T142043.026837.snakemake.log\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!snakemake -ps snakefile_test2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oh no!  What went wrong?  We haven't given snakemake a target file.  Let's add a `rule all`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing snakefile_test3\n"
     ]
    }
   ],
   "source": [
    "%%writefile snakefile_test3\n",
    "\n",
    "ref = 'ref_genome/chr5_ref.fasta'\n",
    "refNoExt = os.path.splitext(ref)[0]\n",
    "\n",
    "rawDataPath = 'raw_data/'\n",
    "sampleDict = {\n",
    "    'PatientA':['Patient_A.r1.fastq', 'Patient_A.r2.fastq'],\n",
    "    'PatientB':['Patient_B.r1.fastq', 'Patient_B.r2.fastq']\n",
    "}\n",
    "\n",
    "def get_read1_fastq(wildcards):\n",
    "    (read1, read2) = sampleDict[wildcards.sample]\n",
    "    return rawDataPath + read1\n",
    "\n",
    "def get_read2_fastq(wildcards):\n",
    "    (read1, read2) = sampleDict[wildcards.sample]\n",
    "    return rawDataPath + read2\n",
    "\n",
    "\n",
    "rule all:\n",
    "    input:\n",
    "        expand('aligned/{sample}.bam', sample=sampleDict.keys())\n",
    "\n",
    "rule index_ref:\n",
    "    input:\n",
    "        ref\n",
    "    output:\n",
    "        o1 = ref + '.amb',\n",
    "        o2 = ref + '.ann',\n",
    "        o3 = ref + '.bwt',\n",
    "        o4 = ref + '.pac',\n",
    "        o5 = ref + '.sa',\n",
    "        o6 = ref + '.fai',\n",
    "        o7 = refNoExt + '.dict'\n",
    "    shell:\n",
    "        'bwa index {input};'\n",
    "        'samtools faidx {input};'\n",
    "        'picard CreateSequenceDictionary REFERENCE={input} OUTPUT={output.o7}'\n",
    "\n",
    "rule align_fastqs: \n",
    "    input:\n",
    "        ref = ref,\n",
    "        r1 = ref + '.amb',\n",
    "        r2 = ref + '.ann',\n",
    "        r3 = ref + '.bwt',\n",
    "        r4 = ref + '.pac',\n",
    "        r5 = ref + '.sa',\n",
    "        fq1 = get_read1_fastq,\n",
    "        fq2 = get_read2_fastq\n",
    "    output:\n",
    "        'aligned/{sample}.bam'\n",
    "    params:\n",
    "        pl = 'ILLUMINA',\n",
    "        rg = '{sample}_rg',\n",
    "        sm = '{sample}'\n",
    "    shell:\n",
    "        'bwa mem -R \"@RG\\\\tID:{params.rg}\\\\tSM:{params.sm}\\\\tPL:{params.pl}\" {input.ref} {input.fq1} {input.fq2} | samtools sort -o {output}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now snakemake knows that `{sample}` should expand to PatientA and PatientB, and that the pipeline should end up producing the files `'aligned/{sample}.bam'`.  Let's try running it (this will take a minute or two):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mBuilding DAG of jobs...\u001b[0m\n",
      "\u001b[33mUsing shell: /bin/bash\u001b[0m\n",
      "\u001b[33mProvided cores: 1\u001b[0m\n",
      "\u001b[33mRules claiming more threads will be scaled down.\u001b[0m\n",
      "\u001b[33mJob counts:\n",
      "\tcount\tjobs\n",
      "\t2\talign_fastqs\n",
      "\t1\tall\n",
      "\t3\u001b[0m\n",
      "\u001b[32m\u001b[0m\n",
      "\u001b[32m[Thu Apr 18 14:20:52 2019]\u001b[0m\n",
      "\u001b[32mrule align_fastqs:\n",
      "    input: ref_genome/chr5_ref.fasta, ref_genome/chr5_ref.fasta.amb, ref_genome/chr5_ref.fasta.ann, ref_genome/chr5_ref.fasta.bwt, ref_genome/chr5_ref.fasta.pac, ref_genome/chr5_ref.fasta.sa, raw_data/Patient_B.r1.fastq, raw_data/Patient_B.r2.fastq\n",
      "    output: aligned/PatientB.bam\n",
      "    jobid: 2\n",
      "    wildcards: sample=PatientB\u001b[0m\n",
      "\u001b[32m\u001b[0m\n",
      "\u001b[33mbwa mem -R \"@RG\\tID:PatientB_rg\\tSM:PatientB\\tPL:ILLUMINA\" ref_genome/chr5_ref.fasta raw_data/Patient_B.r1.fastq raw_data/Patient_B.r2.fastq | samtools sort -o aligned/PatientB.bam\u001b[0m\n",
      "[M::bwa_idx_load_from_disk] read 0 ALT contigs\n",
      "[M::process] read 66674 sequences (10000123 bp)...\n",
      "[M::process] read 66674 sequences (10000097 bp)...\n",
      "[M::mem_pestat] # candidate unique pairs for (FF, FR, RF, RR): (2, 31731, 0, 2)\n",
      "[M::mem_pestat] skip orientation FF as there are not enough pairs\n",
      "[M::mem_pestat] analyzing insert size distribution for orientation FR...\n",
      "[M::mem_pestat] (25, 50, 75) percentile: (244, 278, 314)\n",
      "[M::mem_pestat] low and high boundaries for computing mean and std.dev: (104, 454)\n",
      "[M::mem_pestat] mean and std.dev: (280.89, 52.60)\n",
      "[M::mem_pestat] low and high boundaries for proper pairs: (34, 524)\n",
      "[M::mem_pestat] skip orientation RF as there are not enough pairs\n",
      "[M::mem_pestat] skip orientation RR as there are not enough pairs\n",
      "[M::mem_process_seqs] Processed 66674 reads in 5.265 CPU sec, 5.236 real sec\n",
      "[M::process] read 66672 sequences (10000078 bp)...\n",
      "[M::mem_pestat] # candidate unique pairs for (FF, FR, RF, RR): (3, 31745, 0, 0)\n",
      "[M::mem_pestat] skip orientation FF as there are not enough pairs\n",
      "[M::mem_pestat] analyzing insert size distribution for orientation FR...\n",
      "[M::mem_pestat] (25, 50, 75) percentile: (243, 277, 314)\n",
      "[M::mem_pestat] low and high boundaries for computing mean and std.dev: (101, 456)\n",
      "[M::mem_pestat] mean and std.dev: (279.38, 52.50)\n",
      "[M::mem_pestat] low and high boundaries for proper pairs: (30, 527)\n",
      "[M::mem_pestat] skip orientation RF as there are not enough pairs\n",
      "[M::mem_pestat] skip orientation RR as there are not enough pairs\n",
      "[M::mem_process_seqs] Processed 66674 reads in 4.987 CPU sec, 4.910 real sec\n",
      "[M::process] read 66670 sequences (10000020 bp)...\n",
      "[M::mem_pestat] # candidate unique pairs for (FF, FR, RF, RR): (2, 31650, 0, 1)\n",
      "[M::mem_pestat] skip orientation FF as there are not enough pairs\n",
      "[M::mem_pestat] analyzing insert size distribution for orientation FR...\n",
      "[M::mem_pestat] (25, 50, 75) percentile: (242, 276, 312)\n",
      "[M::mem_pestat] low and high boundaries for computing mean and std.dev: (102, 452)\n",
      "[M::mem_pestat] mean and std.dev: (278.34, 52.21)\n",
      "[M::mem_pestat] low and high boundaries for proper pairs: (32, 522)\n",
      "[M::mem_pestat] skip orientation RF as there are not enough pairs\n",
      "[M::mem_pestat] skip orientation RR as there are not enough pairs\n",
      "[M::mem_process_seqs] Processed 66672 reads in 5.006 CPU sec, 4.913 real sec\n",
      "[M::process] read 66676 sequences (10000036 bp)...\n",
      "[M::mem_pestat] # candidate unique pairs for (FF, FR, RF, RR): (1, 31707, 0, 0)\n",
      "[M::mem_pestat] skip orientation FF as there are not enough pairs\n",
      "[M::mem_pestat] analyzing insert size distribution for orientation FR...\n",
      "[M::mem_pestat] (25, 50, 75) percentile: (243, 277, 313)\n",
      "[M::mem_pestat] low and high boundaries for computing mean and std.dev: (103, 453)\n",
      "[M::mem_pestat] mean and std.dev: (279.15, 52.39)\n",
      "[M::mem_pestat] low and high boundaries for proper pairs: (33, 523)\n",
      "[M::mem_pestat] skip orientation RF as there are not enough pairs\n",
      "[M::mem_pestat] skip orientation RR as there are not enough pairs\n",
      "[M::mem_process_seqs] Processed 66670 reads in 5.077 CPU sec, 5.004 real sec\n",
      "[M::process] read 66672 sequences (10000088 bp)...\n",
      "[M::mem_pestat] # candidate unique pairs for (FF, FR, RF, RR): (3, 31707, 0, 1)\n",
      "[M::mem_pestat] skip orientation FF as there are not enough pairs\n",
      "[M::mem_pestat] analyzing insert size distribution for orientation FR...\n",
      "[M::mem_pestat] (25, 50, 75) percentile: (243, 276, 313)\n",
      "[M::mem_pestat] low and high boundaries for computing mean and std.dev: (103, 453)\n",
      "[M::mem_pestat] mean and std.dev: (278.80, 52.64)\n",
      "[M::mem_pestat] low and high boundaries for proper pairs: (33, 523)\n",
      "[M::mem_pestat] skip orientation RF as there are not enough pairs\n",
      "[M::mem_pestat] skip orientation RR as there are not enough pairs\n",
      "[M::mem_process_seqs] Processed 66676 reads in 5.753 CPU sec, 5.658 real sec\n",
      "[M::process] read 58410 sequences (8760675 bp)...\n",
      "[M::mem_pestat] # candidate unique pairs for (FF, FR, RF, RR): (0, 31749, 0, 0)\n",
      "[M::mem_pestat] skip orientation FF as there are not enough pairs\n",
      "[M::mem_pestat] analyzing insert size distribution for orientation FR...\n",
      "[M::mem_pestat] (25, 50, 75) percentile: (244, 278, 315)\n",
      "[M::mem_pestat] low and high boundaries for computing mean and std.dev: (102, 457)\n",
      "[M::mem_pestat] mean and std.dev: (280.56, 52.72)\n",
      "[M::mem_pestat] low and high boundaries for proper pairs: (31, 528)\n",
      "[M::mem_pestat] skip orientation RF as there are not enough pairs\n",
      "[M::mem_pestat] skip orientation RR as there are not enough pairs\n",
      "[M::mem_process_seqs] Processed 66672 reads in 5.223 CPU sec, 5.127 real sec\n",
      "[M::mem_pestat] # candidate unique pairs for (FF, FR, RF, RR): (2, 27840, 0, 0)\n",
      "[M::mem_pestat] skip orientation FF as there are not enough pairs\n",
      "[M::mem_pestat] analyzing insert size distribution for orientation FR...\n",
      "[M::mem_pestat] (25, 50, 75) percentile: (245, 279, 317)\n",
      "[M::mem_pestat] low and high boundaries for computing mean and std.dev: (101, 461)\n",
      "[M::mem_pestat] mean and std.dev: (282.17, 53.74)\n",
      "[M::mem_pestat] low and high boundaries for proper pairs: (29, 533)\n",
      "[M::mem_pestat] skip orientation RF as there are not enough pairs\n",
      "[M::mem_pestat] skip orientation RR as there are not enough pairs\n",
      "[M::mem_process_seqs] Processed 58410 reads in 4.355 CPU sec, 4.308 real sec\n",
      "[main] Version: 0.7.17-r1188\n",
      "[main] CMD: bwa mem -R @RG\\tID:PatientB_rg\\tSM:PatientB\\tPL:ILLUMINA ref_genome/chr5_ref.fasta raw_data/Patient_B.r1.fastq raw_data/Patient_B.r2.fastq\n",
      "[main] Real time: 35.297 sec; CPU: 35.781 sec\n",
      "\u001b[32m[Thu Apr 18 14:21:29 2019]\u001b[0m\n",
      "\u001b[32mFinished job 2.\u001b[0m\n",
      "\u001b[32m1 of 3 steps (33%) done\u001b[0m\n",
      "\u001b[32m\u001b[0m\n",
      "\u001b[32m[Thu Apr 18 14:21:29 2019]\u001b[0m\n",
      "\u001b[32mrule align_fastqs:\n",
      "    input: ref_genome/chr5_ref.fasta, ref_genome/chr5_ref.fasta.amb, ref_genome/chr5_ref.fasta.ann, ref_genome/chr5_ref.fasta.bwt, ref_genome/chr5_ref.fasta.pac, ref_genome/chr5_ref.fasta.sa, raw_data/Patient_A.r1.fastq, raw_data/Patient_A.r2.fastq\n",
      "    output: aligned/PatientA.bam\n",
      "    jobid: 1\n",
      "    wildcards: sample=PatientA\u001b[0m\n",
      "\u001b[32m\u001b[0m\n",
      "\u001b[33mbwa mem -R \"@RG\\tID:PatientA_rg\\tSM:PatientA\\tPL:ILLUMINA\" ref_genome/chr5_ref.fasta raw_data/Patient_A.r1.fastq raw_data/Patient_A.r2.fastq | samtools sort -o aligned/PatientA.bam\u001b[0m\n",
      "[M::bwa_idx_load_from_disk] read 0 ALT contigs\n",
      "[M::process] read 66678 sequences (10000219 bp)...\n",
      "[M::process] read 66674 sequences (10000016 bp)...\n",
      "[M::mem_pestat] # candidate unique pairs for (FF, FR, RF, RR): (4, 31683, 0, 0)\n",
      "[M::mem_pestat] skip orientation FF as there are not enough pairs\n",
      "[M::mem_pestat] analyzing insert size distribution for orientation FR...\n",
      "[M::mem_pestat] (25, 50, 75) percentile: (251, 285, 323)\n",
      "[M::mem_pestat] low and high boundaries for computing mean and std.dev: (107, 467)\n",
      "[M::mem_pestat] mean and std.dev: (287.82, 54.32)\n",
      "[M::mem_pestat] low and high boundaries for proper pairs: (35, 539)\n",
      "[M::mem_pestat] skip orientation RF as there are not enough pairs\n",
      "[M::mem_pestat] skip orientation RR as there are not enough pairs\n",
      "[M::mem_process_seqs] Processed 66678 reads in 5.341 CPU sec, 5.311 real sec\n",
      "[M::process] read 66674 sequences (10000261 bp)...\n",
      "[M::mem_pestat] # candidate unique pairs for (FF, FR, RF, RR): (1, 31690, 0, 1)\n",
      "[M::mem_pestat] skip orientation FF as there are not enough pairs\n",
      "[M::mem_pestat] analyzing insert size distribution for orientation FR...\n",
      "[M::mem_pestat] (25, 50, 75) percentile: (250, 285, 322)\n",
      "[M::mem_pestat] low and high boundaries for computing mean and std.dev: (106, 466)\n",
      "[M::mem_pestat] mean and std.dev: (287.19, 54.24)\n",
      "[M::mem_pestat] low and high boundaries for proper pairs: (34, 538)\n",
      "[M::mem_pestat] skip orientation RF as there are not enough pairs\n",
      "[M::mem_pestat] skip orientation RR as there are not enough pairs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[M::mem_process_seqs] Processed 66674 reads in 5.015 CPU sec, 4.921 real sec\n",
      "[M::process] read 66676 sequences (10000211 bp)...\n",
      "[M::mem_pestat] # candidate unique pairs for (FF, FR, RF, RR): (1, 31694, 0, 0)\n",
      "[M::mem_pestat] skip orientation FF as there are not enough pairs\n",
      "[M::mem_pestat] analyzing insert size distribution for orientation FR...\n",
      "[M::mem_pestat] (25, 50, 75) percentile: (249, 283, 320)\n",
      "[M::mem_pestat] low and high boundaries for computing mean and std.dev: (107, 462)\n",
      "[M::mem_pestat] mean and std.dev: (285.44, 53.83)\n",
      "[M::mem_pestat] low and high boundaries for proper pairs: (36, 533)\n",
      "[M::mem_pestat] skip orientation RF as there are not enough pairs\n",
      "[M::mem_pestat] skip orientation RR as there are not enough pairs\n",
      "[M::mem_process_seqs] Processed 66674 reads in 4.919 CPU sec, 4.829 real sec\n",
      "[M::process] read 66676 sequences (10000065 bp)...\n",
      "[M::mem_pestat] # candidate unique pairs for (FF, FR, RF, RR): (3, 31685, 0, 0)\n",
      "[M::mem_pestat] skip orientation FF as there are not enough pairs\n",
      "[M::mem_pestat] analyzing insert size distribution for orientation FR...\n",
      "[M::mem_pestat] (25, 50, 75) percentile: (249, 283, 320)\n",
      "[M::mem_pestat] low and high boundaries for computing mean and std.dev: (107, 462)\n",
      "[M::mem_pestat] mean and std.dev: (285.40, 53.25)\n",
      "[M::mem_pestat] low and high boundaries for proper pairs: (36, 533)\n",
      "[M::mem_pestat] skip orientation RF as there are not enough pairs\n",
      "[M::mem_pestat] skip orientation RR as there are not enough pairs\n",
      "[M::mem_process_seqs] Processed 66676 reads in 4.974 CPU sec, 4.882 real sec\n",
      "[M::process] read 61730 sequences (9258761 bp)...\n",
      "[M::mem_pestat] # candidate unique pairs for (FF, FR, RF, RR): (4, 31643, 0, 0)\n",
      "[M::mem_pestat] skip orientation FF as there are not enough pairs\n",
      "[M::mem_pestat] analyzing insert size distribution for orientation FR...\n",
      "[M::mem_pestat] (25, 50, 75) percentile: (249, 283, 320)\n",
      "[M::mem_pestat] low and high boundaries for computing mean and std.dev: (107, 462)\n",
      "[M::mem_pestat] mean and std.dev: (286.05, 54.10)\n",
      "[M::mem_pestat] low and high boundaries for proper pairs: (36, 533)\n",
      "[M::mem_pestat] skip orientation RF as there are not enough pairs\n",
      "[M::mem_pestat] skip orientation RR as there are not enough pairs\n",
      "[M::mem_process_seqs] Processed 66676 reads in 4.934 CPU sec, 4.838 real sec\n",
      "[M::mem_pestat] # candidate unique pairs for (FF, FR, RF, RR): (2, 29382, 0, 0)\n",
      "[M::mem_pestat] skip orientation FF as there are not enough pairs\n",
      "[M::mem_pestat] analyzing insert size distribution for orientation FR...\n",
      "[M::mem_pestat] (25, 50, 75) percentile: (250, 284, 322)\n",
      "[M::mem_pestat] low and high boundaries for computing mean and std.dev: (106, 466)\n",
      "[M::mem_pestat] mean and std.dev: (286.64, 53.74)\n",
      "[M::mem_pestat] low and high boundaries for proper pairs: (34, 538)\n",
      "[M::mem_pestat] skip orientation RF as there are not enough pairs\n",
      "[M::mem_pestat] skip orientation RR as there are not enough pairs\n",
      "[M::mem_process_seqs] Processed 61730 reads in 4.447 CPU sec, 4.393 real sec\n",
      "[main] Version: 0.7.17-r1188\n",
      "[main] CMD: bwa mem -R @RG\\tID:PatientA_rg\\tSM:PatientA\\tPL:ILLUMINA ref_genome/chr5_ref.fasta raw_data/Patient_A.r1.fastq raw_data/Patient_A.r2.fastq\n",
      "[main] Real time: 29.313 sec; CPU: 29.747 sec\n",
      "\u001b[32m[Thu Apr 18 14:22:00 2019]\u001b[0m\n",
      "\u001b[32mFinished job 1.\u001b[0m\n",
      "\u001b[32m2 of 3 steps (67%) done\u001b[0m\n",
      "\u001b[32m\u001b[0m\n",
      "\u001b[32m[Thu Apr 18 14:22:00 2019]\u001b[0m\n",
      "\u001b[32mlocalrule all:\n",
      "    input: aligned/PatientA.bam, aligned/PatientB.bam\n",
      "    jobid: 0\u001b[0m\n",
      "\u001b[32m\u001b[0m\n",
      "\u001b[32m[Thu Apr 18 14:22:00 2019]\u001b[0m\n",
      "\u001b[32mFinished job 0.\u001b[0m\n",
      "\u001b[32m3 of 3 steps (100%) done\u001b[0m\n",
      "\u001b[33mComplete log: /Users/ballewbj/snakemake_class/snakemake/Genomics_practice/.snakemake/log/2019-04-18T142052.288847.snakemake.log\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!snakemake -ps snakefile_test3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 105544\r\n",
      "-rw-r--r--  1 ballewbj  NIH\\Domain Users    24M Apr 18 14:22 PatientA.bam\r\n",
      "-rw-r--r--  1 ballewbj  NIH\\Domain Users    27M Apr 18 14:21 PatientB.bam\r\n"
     ]
    }
   ],
   "source": [
    "ls -lh aligned/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yay!  A few things of note:\n",
    "- We now have one aligned bam file per patient!\n",
    "- Snakemake automatically created the directory `aligned/` for us.\n",
    "- The stdout also includes a bunch of information from bwa.  There are ways to clean this up, but we're going to skip over that for now.\n",
    "- Snakemake saw that the indexed reference files were already created, so it did not re-run that rule."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Third rule: index bams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like the reference genome, the aligned bam files need to be indexed for the next tool to be able to read them.  We'll need to write the rule and update the rule all with the new target file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing snakefile_test4\n"
     ]
    }
   ],
   "source": [
    "%%writefile snakefile_test4\n",
    "\n",
    "ref = 'ref_genome/chr5_ref.fasta'\n",
    "refNoExt = os.path.splitext(ref)[0]\n",
    "\n",
    "rawDataPath = 'raw_data/'\n",
    "sampleDict = {\n",
    "    'PatientA':['Patient_A.r1.fastq', 'Patient_A.r2.fastq'],\n",
    "    'PatientB':['Patient_B.r1.fastq', 'Patient_B.r2.fastq']\n",
    "}\n",
    "\n",
    "def get_read1_fastq(wildcards):\n",
    "    (read1, read2) = sampleDict[wildcards.sample]\n",
    "    return rawDataPath + read1\n",
    "\n",
    "def get_read2_fastq(wildcards):\n",
    "    (read1, read2) = sampleDict[wildcards.sample]\n",
    "    return rawDataPath + read2\n",
    "\n",
    "\n",
    "rule all:\n",
    "    input:\n",
    "        expand('aligned/{sample}.bam.bai', sample=sampleDict.keys())\n",
    "\n",
    "rule index_ref:\n",
    "    input:\n",
    "        ref\n",
    "    output:\n",
    "        o1 = ref + '.amb',\n",
    "        o2 = ref + '.ann',\n",
    "        o3 = ref + '.bwt',\n",
    "        o4 = ref + '.pac',\n",
    "        o5 = ref + '.sa',\n",
    "        o6 = ref + '.fai',\n",
    "        o7 = refNoExt + '.dict'\n",
    "    shell:\n",
    "        'bwa index {input};'\n",
    "        'samtools faidx {input};'\n",
    "        'picard CreateSequenceDictionary REFERENCE={input} OUTPUT={output.o7}'\n",
    "\n",
    "rule align_fastqs: \n",
    "    input:\n",
    "        ref = ref,\n",
    "        r1 = ref + '.amb',\n",
    "        r2 = ref + '.ann',\n",
    "        r3 = ref + '.bwt',\n",
    "        r4 = ref + '.pac',\n",
    "        r5 = ref + '.sa',\n",
    "        fq1 = get_read1_fastq,\n",
    "        fq2 = get_read2_fastq\n",
    "    output:\n",
    "        'aligned/{sample}.bam'\n",
    "    params:\n",
    "        pl = 'ILLUMINA',\n",
    "        rg = '{sample}_rg',\n",
    "        sm = '{sample}'\n",
    "    shell:\n",
    "        'bwa mem -R \"@RG\\\\tID:{params.rg}\\\\tSM:{params.sm}\\\\tPL:{params.pl}\" {input.ref} {input.fq1} {input.fq2} | samtools sort -o {output}'\n",
    "        \n",
    "rule index_bams:\n",
    "    input:\n",
    "        'aligned/{sample}.bam'\n",
    "    output:\n",
    "        'aligned/{sample}.bam.bai'\n",
    "    shell:\n",
    "        'samtools index {input}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mBuilding DAG of jobs...\u001b[0m\n",
      "\u001b[33mUsing shell: /bin/bash\u001b[0m\n",
      "\u001b[33mProvided cores: 1\u001b[0m\n",
      "\u001b[33mRules claiming more threads will be scaled down.\u001b[0m\n",
      "\u001b[33mJob counts:\n",
      "\tcount\tjobs\n",
      "\t1\tall\n",
      "\t2\tindex_bams\n",
      "\t3\u001b[0m\n",
      "\u001b[32m\u001b[0m\n",
      "\u001b[32m[Thu Apr 18 14:22:14 2019]\u001b[0m\n",
      "\u001b[32mrule index_bams:\n",
      "    input: aligned/PatientB.bam\n",
      "    output: aligned/PatientB.bam.bai\n",
      "    jobid: 2\n",
      "    wildcards: sample=PatientB\u001b[0m\n",
      "\u001b[32m\u001b[0m\n",
      "\u001b[33msamtools index aligned/PatientB.bam\u001b[0m\n",
      "\u001b[32m[Thu Apr 18 14:22:14 2019]\u001b[0m\n",
      "\u001b[32mFinished job 2.\u001b[0m\n",
      "\u001b[32m1 of 3 steps (33%) done\u001b[0m\n",
      "\u001b[32m\u001b[0m\n",
      "\u001b[32m[Thu Apr 18 14:22:14 2019]\u001b[0m\n",
      "\u001b[32mrule index_bams:\n",
      "    input: aligned/PatientA.bam\n",
      "    output: aligned/PatientA.bam.bai\n",
      "    jobid: 1\n",
      "    wildcards: sample=PatientA\u001b[0m\n",
      "\u001b[32m\u001b[0m\n",
      "\u001b[33msamtools index aligned/PatientA.bam\u001b[0m\n",
      "\u001b[32m[Thu Apr 18 14:22:14 2019]\u001b[0m\n",
      "\u001b[32mFinished job 1.\u001b[0m\n",
      "\u001b[32m2 of 3 steps (67%) done\u001b[0m\n",
      "\u001b[32m\u001b[0m\n",
      "\u001b[32m[Thu Apr 18 14:22:14 2019]\u001b[0m\n",
      "\u001b[32mlocalrule all:\n",
      "    input: aligned/PatientA.bam.bai, aligned/PatientB.bam.bai\n",
      "    jobid: 0\u001b[0m\n",
      "\u001b[32m\u001b[0m\n",
      "\u001b[32m[Thu Apr 18 14:22:14 2019]\u001b[0m\n",
      "\u001b[32mFinished job 0.\u001b[0m\n",
      "\u001b[32m3 of 3 steps (100%) done\u001b[0m\n",
      "\u001b[33mComplete log: /Users/ballewbj/snakemake_class/snakemake/Genomics_practice/.snakemake/log/2019-04-18T142214.136216.snakemake.log\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!snakemake -ps snakefile_test4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 105576\r\n",
      "-rw-r--r--  1 ballewbj  NIH\\Domain Users    24M Apr 18 14:22 PatientA.bam\r\n",
      "-rw-r--r--  1 ballewbj  NIH\\Domain Users   6.4K Apr 18 14:22 PatientA.bam.bai\r\n",
      "-rw-r--r--  1 ballewbj  NIH\\Domain Users    27M Apr 18 14:21 PatientB.bam\r\n",
      "-rw-r--r--  1 ballewbj  NIH\\Domain Users   6.5K Apr 18 14:22 PatientB.bam.bai\r\n"
     ]
    }
   ],
   "source": [
    "ls -lh aligned/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fourth rule: calling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This fourth rule will compare our aligned sequences to the reference genome, look at places where there's a discrepancy, and report back those variants.  We'll need to write the rule and update the rule all with the new target file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing snakefile_test5\n"
     ]
    }
   ],
   "source": [
    "%%writefile snakefile_test5\n",
    "\n",
    "ref = 'ref_genome/chr5_ref.fasta'\n",
    "refNoExt = os.path.splitext(ref)[0]\n",
    "\n",
    "rawDataPath = 'raw_data/'\n",
    "sampleDict = {\n",
    "    'PatientA':['Patient_A.r1.fastq', 'Patient_A.r2.fastq'],\n",
    "    'PatientB':['Patient_B.r1.fastq', 'Patient_B.r2.fastq']\n",
    "}\n",
    "\n",
    "def get_read1_fastq(wildcards):\n",
    "    (read1, read2) = sampleDict[wildcards.sample]\n",
    "    return rawDataPath + read1\n",
    "\n",
    "def get_read2_fastq(wildcards):\n",
    "    (read1, read2) = sampleDict[wildcards.sample]\n",
    "    return rawDataPath + read2\n",
    "\n",
    "\n",
    "rule all:\n",
    "    input:\n",
    "        expand('called/{sample}.vcf', sample=sampleDict.keys())\n",
    "\n",
    "rule index_ref:\n",
    "    input:\n",
    "        ref\n",
    "    output:\n",
    "        o1 = ref + '.amb',\n",
    "        o2 = ref + '.ann',\n",
    "        o3 = ref + '.bwt',\n",
    "        o4 = ref + '.pac',\n",
    "        o5 = ref + '.sa',\n",
    "        o6 = ref + '.fai',\n",
    "        o7 = refNoExt + '.dict'\n",
    "    shell:\n",
    "        'bwa index {input};'\n",
    "        'samtools faidx {input};'\n",
    "        'picard CreateSequenceDictionary REFERENCE={input} OUTPUT={output.o7}'\n",
    "\n",
    "rule align_fastqs: \n",
    "    input:\n",
    "        ref = ref,\n",
    "        r1 = ref + '.amb',\n",
    "        r2 = ref + '.ann',\n",
    "        r3 = ref + '.bwt',\n",
    "        r4 = ref + '.pac',\n",
    "        r5 = ref + '.sa',\n",
    "        fq1 = get_read1_fastq,\n",
    "        fq2 = get_read2_fastq\n",
    "    output:\n",
    "        'aligned/{sample}.bam'\n",
    "    params:\n",
    "        pl = 'ILLUMINA',\n",
    "        rg = '{sample}_rg',\n",
    "        sm = '{sample}'\n",
    "    shell:\n",
    "        'bwa mem -R \"@RG\\\\tID:{params.rg}\\\\tSM:{params.sm}\\\\tPL:{params.pl}\" {input.ref} {input.fq1} {input.fq2} | samtools sort -o {output}'\n",
    "        \n",
    "rule index_bams:\n",
    "    input:\n",
    "        'aligned/{sample}.bam'\n",
    "    output:\n",
    "        'aligned/{sample}.bam.bai'\n",
    "    shell:\n",
    "        'samtools index {input}'\n",
    "        \n",
    "rule call_variants:\n",
    "    input:\n",
    "        ref = ref,\n",
    "        r1 = ref + '.fai',\n",
    "        r2 = refNoExt + '.dict',\n",
    "        bam = 'aligned/{sample}.bam',\n",
    "        bai = 'aligned/{sample}.bam.bai'\n",
    "    output:\n",
    "        'called/{sample}.vcf'\n",
    "    shell:\n",
    "        'gatk HaplotypeCaller -I {input.bam} -O {output} -R {input.ref}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mBuilding DAG of jobs...\u001b[0m\n",
      "\u001b[33mUsing shell: /bin/bash\u001b[0m\n",
      "\u001b[33mProvided cores: 1\u001b[0m\n",
      "\u001b[33mRules claiming more threads will be scaled down.\u001b[0m\n",
      "\u001b[33mJob counts:\n",
      "\tcount\tjobs\n",
      "\t1\tall\n",
      "\t2\tcall_variants\n",
      "\t3\u001b[0m\n",
      "\u001b[32m\u001b[0m\n",
      "\u001b[32m[Thu Apr 18 14:22:42 2019]\u001b[0m\n",
      "\u001b[32mrule call_variants:\n",
      "    input: ref_genome/chr5_ref.fasta, ref_genome/chr5_ref.fasta.fai, ref_genome/chr5_ref.dict, aligned/PatientB.bam, aligned/PatientB.bam.bai\n",
      "    output: called/PatientB.vcf\n",
      "    jobid: 2\n",
      "    wildcards: sample=PatientB\u001b[0m\n",
      "\u001b[32m\u001b[0m\n",
      "\u001b[33mgatk HaplotypeCaller -I aligned/PatientB.bam -O called/PatientB.vcf -R ref_genome/chr5_ref.fasta\u001b[0m\n",
      "Using GATK jar /anaconda3/envs/snakemake_class/share/gatk4-4.1.1.0-0/gatk-package-4.1.1.0-local.jar\n",
      "Running:\n",
      "    java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -jar /anaconda3/envs/snakemake_class/share/gatk4-4.1.1.0-0/gatk-package-4.1.1.0-local.jar HaplotypeCaller -I aligned/PatientB.bam -O called/PatientB.vcf -R ref_genome/chr5_ref.fasta\n",
      "14:22:45.224 INFO  NativeLibraryLoader - Loading libgkl_compression.dylib from jar:file:/anaconda3/envs/snakemake_class/share/gatk4-4.1.1.0-0/gatk-package-4.1.1.0-local.jar!/com/intel/gkl/native/libgkl_compression.dylib\n",
      "Apr 18, 2019 2:22:46 PM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine\n",
      "INFO: Failed to detect whether we are running on Google Compute Engine.\n",
      "14:22:46.900 INFO  HaplotypeCaller - ------------------------------------------------------------\n",
      "14:22:46.900 INFO  HaplotypeCaller - The Genome Analysis Toolkit (GATK) v4.1.1.0\n",
      "14:22:46.900 INFO  HaplotypeCaller - For support and documentation go to https://software.broadinstitute.org/gatk/\n",
      "14:22:46.901 INFO  HaplotypeCaller - Executing as ballewbj@NCI-02034622-ML on Mac OS X v10.13.6 x86_64\n",
      "14:22:46.901 INFO  HaplotypeCaller - Java runtime: OpenJDK 64-Bit Server VM v1.8.0_192-b01\n",
      "14:22:46.901 INFO  HaplotypeCaller - Start Date/Time: April 18, 2019 2:22:45 PM EDT\n",
      "14:22:46.901 INFO  HaplotypeCaller - ------------------------------------------------------------\n",
      "14:22:46.901 INFO  HaplotypeCaller - ------------------------------------------------------------\n",
      "14:22:46.901 INFO  HaplotypeCaller - HTSJDK Version: 2.19.0\n",
      "14:22:46.901 INFO  HaplotypeCaller - Picard Version: 2.19.0\n",
      "14:22:46.901 INFO  HaplotypeCaller - HTSJDK Defaults.COMPRESSION_LEVEL : 2\n",
      "14:22:46.901 INFO  HaplotypeCaller - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false\n",
      "14:22:46.901 INFO  HaplotypeCaller - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true\n",
      "14:22:46.901 INFO  HaplotypeCaller - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false\n",
      "14:22:46.901 INFO  HaplotypeCaller - Deflater: IntelDeflater\n",
      "14:22:46.901 INFO  HaplotypeCaller - Inflater: IntelInflater\n",
      "14:22:46.902 INFO  HaplotypeCaller - GCS max retries/reopens: 20\n",
      "14:22:46.902 INFO  HaplotypeCaller - Requester pays: disabled\n",
      "14:22:46.902 INFO  HaplotypeCaller - Initializing engine\n",
      "14:22:47.237 INFO  HaplotypeCaller - Done initializing engine\n",
      "14:22:47.242 INFO  HaplotypeCallerEngine - Disabling physical phasing, which is supported only for reference-model confidence output\n",
      "14:22:47.253 INFO  NativeLibraryLoader - Loading libgkl_utils.dylib from jar:file:/anaconda3/envs/snakemake_class/share/gatk4-4.1.1.0-0/gatk-package-4.1.1.0-local.jar!/com/intel/gkl/native/libgkl_utils.dylib\n",
      "14:22:47.257 WARN  NativeLibraryLoader - Unable to find native library: native/libgkl_pairhmm_omp.dylib\n",
      "14:22:47.257 INFO  PairHMM - OpenMP multi-threaded AVX-accelerated native PairHMM implementation is not supported\n",
      "14:22:47.257 INFO  NativeLibraryLoader - Loading libgkl_pairhmm.dylib from jar:file:/anaconda3/envs/snakemake_class/share/gatk4-4.1.1.0-0/gatk-package-4.1.1.0-local.jar!/com/intel/gkl/native/libgkl_pairhmm.dylib\n",
      "14:22:47.276 INFO  IntelPairHmm - Flush-to-zero (FTZ) is enabled when running PairHMM\n",
      "14:22:47.276 WARN  IntelPairHmm - Ignoring request for 4 threads; not using OpenMP implementation\n",
      "14:22:47.276 INFO  PairHMM - Using the AVX-accelerated native PairHMM implementation\n",
      "14:22:47.301 INFO  ProgressMeter - Starting traversal\n",
      "14:22:47.301 INFO  ProgressMeter -        Current Locus  Elapsed Minutes     Regions Processed   Regions/Minute\n",
      "14:22:57.350 INFO  ProgressMeter -             5:321009              0.2                  1490           8896.4\n",
      "14:23:07.413 INFO  ProgressMeter -             5:728775              0.3                  3470          10352.5\n",
      "14:23:17.558 INFO  ProgressMeter -            5:1078326              0.5                  5240          10391.0\n",
      "14:23:27.558 INFO  ProgressMeter -            5:3815077              0.7                 15000          22356.4\n",
      "14:23:27.720 INFO  HaplotypeCaller - 1188 read(s) filtered by: ((((((((MappingQualityReadFilter AND MappingQualityAvailableReadFilter) AND MappedReadFilter) AND NotSecondaryAlignmentReadFilter) AND NotDuplicateReadFilter) AND PassesVendorQualityCheckReadFilter) AND NonZeroReferenceLengthAlignmentReadFilter) AND GoodCigarReadFilter) AND WellformedReadFilter)\n",
      "  1188 read(s) filtered by: (((((((MappingQualityReadFilter AND MappingQualityAvailableReadFilter) AND MappedReadFilter) AND NotSecondaryAlignmentReadFilter) AND NotDuplicateReadFilter) AND PassesVendorQualityCheckReadFilter) AND NonZeroReferenceLengthAlignmentReadFilter) AND GoodCigarReadFilter)\n",
      "      1188 read(s) filtered by: ((((((MappingQualityReadFilter AND MappingQualityAvailableReadFilter) AND MappedReadFilter) AND NotSecondaryAlignmentReadFilter) AND NotDuplicateReadFilter) AND PassesVendorQualityCheckReadFilter) AND NonZeroReferenceLengthAlignmentReadFilter)\n",
      "          1188 read(s) filtered by: (((((MappingQualityReadFilter AND MappingQualityAvailableReadFilter) AND MappedReadFilter) AND NotSecondaryAlignmentReadFilter) AND NotDuplicateReadFilter) AND PassesVendorQualityCheckReadFilter)\n",
      "              1188 read(s) filtered by: ((((MappingQualityReadFilter AND MappingQualityAvailableReadFilter) AND MappedReadFilter) AND NotSecondaryAlignmentReadFilter) AND NotDuplicateReadFilter)\n",
      "                  1188 read(s) filtered by: (((MappingQualityReadFilter AND MappingQualityAvailableReadFilter) AND MappedReadFilter) AND NotSecondaryAlignmentReadFilter)\n",
      "                      1188 read(s) filtered by: ((MappingQualityReadFilter AND MappingQualityAvailableReadFilter) AND MappedReadFilter)\n",
      "                          1188 read(s) filtered by: (MappingQualityReadFilter AND MappingQualityAvailableReadFilter)\n",
      "                              1188 read(s) filtered by: MappingQualityReadFilter \n",
      "\n",
      "14:23:27.721 INFO  ProgressMeter -            5:4198556              0.7                 16284          24172.2\n",
      "14:23:27.721 INFO  ProgressMeter - Traversal complete. Processed 16284 total regions in 0.7 minutes.\n",
      "14:23:27.727 INFO  VectorLoglessPairHMM - Time spent in setup for JNI call : 0.061872381000000004\n",
      "14:23:27.727 INFO  PairHMM - Total compute time in PairHMM computeLogLikelihoods() : 9.062397772\n",
      "14:23:27.727 INFO  SmithWatermanAligner - Total compute time in java Smith-Waterman : 5.19 sec\n",
      "14:23:27.728 INFO  HaplotypeCaller - Shutting down engine\n",
      "[April 18, 2019 2:23:27 PM EDT] org.broadinstitute.hellbender.tools.walkers.haplotypecaller.HaplotypeCaller done. Elapsed time: 0.71 minutes.\n",
      "Runtime.totalMemory()=1361051648\n",
      "\u001b[32m[Thu Apr 18 14:23:27 2019]\u001b[0m\n",
      "\u001b[32mFinished job 2.\u001b[0m\n",
      "\u001b[32m1 of 3 steps (33%) done\u001b[0m\n",
      "\u001b[32m\u001b[0m\n",
      "\u001b[32m[Thu Apr 18 14:23:27 2019]\u001b[0m\n",
      "\u001b[32mrule call_variants:\n",
      "    input: ref_genome/chr5_ref.fasta, ref_genome/chr5_ref.fasta.fai, ref_genome/chr5_ref.dict, aligned/PatientA.bam, aligned/PatientA.bam.bai\n",
      "    output: called/PatientA.vcf\n",
      "    jobid: 1\n",
      "    wildcards: sample=PatientA\u001b[0m\n",
      "\u001b[32m\u001b[0m\n",
      "\u001b[33mgatk HaplotypeCaller -I aligned/PatientA.bam -O called/PatientA.vcf -R ref_genome/chr5_ref.fasta\u001b[0m\n",
      "Using GATK jar /anaconda3/envs/snakemake_class/share/gatk4-4.1.1.0-0/gatk-package-4.1.1.0-local.jar\n",
      "Running:\n",
      "    java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -jar /anaconda3/envs/snakemake_class/share/gatk4-4.1.1.0-0/gatk-package-4.1.1.0-local.jar HaplotypeCaller -I aligned/PatientA.bam -O called/PatientA.vcf -R ref_genome/chr5_ref.fasta\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14:23:30.426 INFO  NativeLibraryLoader - Loading libgkl_compression.dylib from jar:file:/anaconda3/envs/snakemake_class/share/gatk4-4.1.1.0-0/gatk-package-4.1.1.0-local.jar!/com/intel/gkl/native/libgkl_compression.dylib\n",
      "Apr 18, 2019 2:23:32 PM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine\n",
      "INFO: Failed to detect whether we are running on Google Compute Engine.\n",
      "14:23:32.128 INFO  HaplotypeCaller - ------------------------------------------------------------\n",
      "14:23:32.129 INFO  HaplotypeCaller - The Genome Analysis Toolkit (GATK) v4.1.1.0\n",
      "14:23:32.129 INFO  HaplotypeCaller - For support and documentation go to https://software.broadinstitute.org/gatk/\n",
      "14:23:32.129 INFO  HaplotypeCaller - Executing as ballewbj@NCI-02034622-ML on Mac OS X v10.13.6 x86_64\n",
      "14:23:32.129 INFO  HaplotypeCaller - Java runtime: OpenJDK 64-Bit Server VM v1.8.0_192-b01\n",
      "14:23:32.129 INFO  HaplotypeCaller - Start Date/Time: April 18, 2019 2:23:30 PM EDT\n",
      "14:23:32.129 INFO  HaplotypeCaller - ------------------------------------------------------------\n",
      "14:23:32.129 INFO  HaplotypeCaller - ------------------------------------------------------------\n",
      "14:23:32.130 INFO  HaplotypeCaller - HTSJDK Version: 2.19.0\n",
      "14:23:32.130 INFO  HaplotypeCaller - Picard Version: 2.19.0\n",
      "14:23:32.130 INFO  HaplotypeCaller - HTSJDK Defaults.COMPRESSION_LEVEL : 2\n",
      "14:23:32.130 INFO  HaplotypeCaller - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false\n",
      "14:23:32.130 INFO  HaplotypeCaller - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true\n",
      "14:23:32.130 INFO  HaplotypeCaller - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false\n",
      "14:23:32.130 INFO  HaplotypeCaller - Deflater: IntelDeflater\n",
      "14:23:32.130 INFO  HaplotypeCaller - Inflater: IntelInflater\n",
      "14:23:32.130 INFO  HaplotypeCaller - GCS max retries/reopens: 20\n",
      "14:23:32.130 INFO  HaplotypeCaller - Requester pays: disabled\n",
      "14:23:32.130 INFO  HaplotypeCaller - Initializing engine\n",
      "14:23:32.461 INFO  HaplotypeCaller - Done initializing engine\n",
      "14:23:32.466 INFO  HaplotypeCallerEngine - Disabling physical phasing, which is supported only for reference-model confidence output\n",
      "14:23:32.476 INFO  NativeLibraryLoader - Loading libgkl_utils.dylib from jar:file:/anaconda3/envs/snakemake_class/share/gatk4-4.1.1.0-0/gatk-package-4.1.1.0-local.jar!/com/intel/gkl/native/libgkl_utils.dylib\n",
      "14:23:32.480 WARN  NativeLibraryLoader - Unable to find native library: native/libgkl_pairhmm_omp.dylib\n",
      "14:23:32.480 INFO  PairHMM - OpenMP multi-threaded AVX-accelerated native PairHMM implementation is not supported\n",
      "14:23:32.480 INFO  NativeLibraryLoader - Loading libgkl_pairhmm.dylib from jar:file:/anaconda3/envs/snakemake_class/share/gatk4-4.1.1.0-0/gatk-package-4.1.1.0-local.jar!/com/intel/gkl/native/libgkl_pairhmm.dylib\n",
      "14:23:32.499 INFO  IntelPairHmm - Flush-to-zero (FTZ) is enabled when running PairHMM\n",
      "14:23:32.499 WARN  IntelPairHmm - Ignoring request for 4 threads; not using OpenMP implementation\n",
      "14:23:32.499 INFO  PairHMM - Using the AVX-accelerated native PairHMM implementation\n",
      "14:23:32.526 INFO  ProgressMeter - Starting traversal\n",
      "14:23:32.526 INFO  ProgressMeter -        Current Locus  Elapsed Minutes     Regions Processed   Regions/Minute\n",
      "14:23:42.532 INFO  ProgressMeter -             5:438415              0.2                  1810          10853.5\n",
      "14:23:52.539 INFO  ProgressMeter -             5:761942              0.3                  3460          10373.3\n",
      "14:24:02.541 INFO  ProgressMeter -            5:1202000              0.5                  5630          11254.7\n",
      "14:24:11.805 INFO  HaplotypeCaller - 1021 read(s) filtered by: ((((((((MappingQualityReadFilter AND MappingQualityAvailableReadFilter) AND MappedReadFilter) AND NotSecondaryAlignmentReadFilter) AND NotDuplicateReadFilter) AND PassesVendorQualityCheckReadFilter) AND NonZeroReferenceLengthAlignmentReadFilter) AND GoodCigarReadFilter) AND WellformedReadFilter)\n",
      "  1021 read(s) filtered by: (((((((MappingQualityReadFilter AND MappingQualityAvailableReadFilter) AND MappedReadFilter) AND NotSecondaryAlignmentReadFilter) AND NotDuplicateReadFilter) AND PassesVendorQualityCheckReadFilter) AND NonZeroReferenceLengthAlignmentReadFilter) AND GoodCigarReadFilter)\n",
      "      1021 read(s) filtered by: ((((((MappingQualityReadFilter AND MappingQualityAvailableReadFilter) AND MappedReadFilter) AND NotSecondaryAlignmentReadFilter) AND NotDuplicateReadFilter) AND PassesVendorQualityCheckReadFilter) AND NonZeroReferenceLengthAlignmentReadFilter)\n",
      "          1021 read(s) filtered by: (((((MappingQualityReadFilter AND MappingQualityAvailableReadFilter) AND MappedReadFilter) AND NotSecondaryAlignmentReadFilter) AND NotDuplicateReadFilter) AND PassesVendorQualityCheckReadFilter)\n",
      "              1021 read(s) filtered by: ((((MappingQualityReadFilter AND MappingQualityAvailableReadFilter) AND MappedReadFilter) AND NotSecondaryAlignmentReadFilter) AND NotDuplicateReadFilter)\n",
      "                  1021 read(s) filtered by: (((MappingQualityReadFilter AND MappingQualityAvailableReadFilter) AND MappedReadFilter) AND NotSecondaryAlignmentReadFilter)\n",
      "                      1021 read(s) filtered by: ((MappingQualityReadFilter AND MappingQualityAvailableReadFilter) AND MappedReadFilter)\n",
      "                          1021 read(s) filtered by: (MappingQualityReadFilter AND MappingQualityAvailableReadFilter)\n",
      "                              1021 read(s) filtered by: MappingQualityReadFilter \n",
      "\n",
      "14:24:11.805 INFO  ProgressMeter -            5:4199756              0.7                 16410          25066.8\n",
      "14:24:11.805 INFO  ProgressMeter - Traversal complete. Processed 16410 total regions in 0.7 minutes.\n",
      "14:24:11.811 INFO  VectorLoglessPairHMM - Time spent in setup for JNI call : 0.060568573\n",
      "14:24:11.811 INFO  PairHMM - Total compute time in PairHMM computeLogLikelihoods() : 6.932184837\n",
      "14:24:11.811 INFO  SmithWatermanAligner - Total compute time in java Smith-Waterman : 4.92 sec\n",
      "14:24:11.811 INFO  HaplotypeCaller - Shutting down engine\n",
      "[April 18, 2019 2:24:11 PM EDT] org.broadinstitute.hellbender.tools.walkers.haplotypecaller.HaplotypeCaller done. Elapsed time: 0.69 minutes.\n",
      "Runtime.totalMemory()=1533018112\n",
      "\u001b[32m[Thu Apr 18 14:24:12 2019]\u001b[0m\n",
      "\u001b[32mFinished job 1.\u001b[0m\n",
      "\u001b[32m2 of 3 steps (67%) done\u001b[0m\n",
      "\u001b[32m\u001b[0m\n",
      "\u001b[32m[Thu Apr 18 14:24:12 2019]\u001b[0m\n",
      "\u001b[32mlocalrule all:\n",
      "    input: called/PatientA.vcf, called/PatientB.vcf\n",
      "    jobid: 0\u001b[0m\n",
      "\u001b[32m\u001b[0m\n",
      "\u001b[32m[Thu Apr 18 14:24:12 2019]\u001b[0m\n",
      "\u001b[32mFinished job 0.\u001b[0m\n",
      "\u001b[32m3 of 3 steps (100%) done\u001b[0m\n",
      "\u001b[33mComplete log: /Users/ballewbj/snakemake_class/snakemake/Genomics_practice/.snakemake/log/2019-04-18T142242.885834.snakemake.log\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!snakemake -ps snakefile_test5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 1824\r\n",
      "-rw-r--r--  1 ballewbj  NIH\\Domain Users   423K Apr 18 14:24 PatientA.vcf\r\n",
      "-rw-r--r--  1 ballewbj  NIH\\Domain Users   4.1K Apr 18 14:24 PatientA.vcf.idx\r\n",
      "-rw-r--r--  1 ballewbj  NIH\\Domain Users   413K Apr 18 14:23 PatientB.vcf\r\n",
      "-rw-r--r--  1 ballewbj  NIH\\Domain Users   4.1K Apr 18 14:23 PatientB.vcf.idx\r\n"
     ]
    }
   ],
   "source": [
    "ls -lh called/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#CHROM\tPOS\tID\tREF\tALT\tQUAL\tFILTER\tINFO\tFORMAT\tPatientA\r\n",
      "5\t100327\t.\tG\tC\t1496.03\t.\tAC=2;AF=1.00;AN=2;DP=38;ExcessHet=3.0103;FS=0.000;MLEAC=2;MLEAF=1.00;MQ=60.00;QD=25.36;SOR=0.798\tGT:AD:DP:GQ:PL\t1/1:0,38:38:99:1510,114,0\r\n",
      "5\t100514\t.\tA\tG\t1864.03\t.\tAC=2;AF=1.00;AN=2;DP=45;ExcessHet=3.0103;FS=0.000;MLEAC=2;MLEAF=1.00;MQ=60.00;QD=28.73;SOR=0.929\tGT:AD:DP:GQ:PL\t1/1:0,45:45:99:1878,135,0\r\n",
      "5\t101444\t.\tT\tTTTTA\t1380.06\t.\tAC=2;AF=1.00;AN=2;DP=39;ExcessHet=3.0103;FS=0.000;MLEAC=2;MLEAF=1.00;MQ=60.00;QD=30.97;SOR=1.214\tGT:AD:DP:GQ:PL\t1/1:0,31:31:93:1394,93,0\r\n",
      "5\t101497\t.\tC\tT\t1283.03\t.\tAC=2;AF=1.00;AN=2;DP=33;ExcessHet=3.0103;FS=0.000;MLEAC=2;MLEAF=1.00;MQ=60.00;QD=27.24;SOR=1.022\tGT:AD:DP:GQ:PL\t1/1:0,33:33:99:1297,99,0\r\n",
      "5\t101748\t.\tT\tC\t1395.03\t.\tAC=2;AF=1.00;AN=2;DP=37;ExcessHet=3.0103;FS=0.000;MLEAC=2;MLEAF=1.00;MQ=60.00;QD=28.20;SOR=0.746\tGT:AD:DP:GQ:PL\t1/1:0,37:37:99:1409,111,0\r\n"
     ]
    }
   ],
   "source": [
    "!grep -A5 \"^#CHROM\" called/PatientA.vcf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Put it all together"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add some comments and save the finalized pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing Genomics_pipeline\n"
     ]
    }
   ],
   "source": [
    "%%writefile Genomics_pipeline\n",
    "\n",
    "# AUTHOR: BB\n",
    "\n",
    "'''\n",
    "This pipeline goes from fastq to vcf\n",
    "for paired-end germline data, and\n",
    "requires a reference fasta.\n",
    "'''\n",
    "\n",
    "# get user data:\n",
    "ref = 'ref_genome/chr5_ref.fasta'\n",
    "refNoExt = os.path.splitext(ref)[0]\n",
    "\n",
    "rawDataPath = 'raw_data/'\n",
    "sampleDict = {\n",
    "    'PatientA':['Patient_A.r1.fastq', 'Patient_A.r2.fastq'],\n",
    "    'PatientB':['Patient_B.r1.fastq', 'Patient_B.r2.fastq']\n",
    "}\n",
    "\n",
    "def get_read1_fastq(wildcards):\n",
    "    (read1, read2) = sampleDict[wildcards.sample]\n",
    "    return rawDataPath + read1\n",
    "\n",
    "def get_read2_fastq(wildcards):\n",
    "    (read1, read2) = sampleDict[wildcards.sample]\n",
    "    return rawDataPath + read2\n",
    "\n",
    "\n",
    "rule all:\n",
    "    input:\n",
    "        expand('called/{sample}.vcf', sample=sampleDict.keys())\n",
    "\n",
    "rule index_ref:\n",
    "    input:\n",
    "        ref\n",
    "    output:\n",
    "        o1 = ref + '.amb',\n",
    "        o2 = ref + '.ann',\n",
    "        o3 = ref + '.bwt',\n",
    "        o4 = ref + '.pac',\n",
    "        o5 = ref + '.sa',\n",
    "        o6 = ref + '.fai',\n",
    "        o7 = refNoExt + '.dict'\n",
    "    shell:\n",
    "        'bwa index {input};'\n",
    "        'samtools faidx {input};'\n",
    "        'picard CreateSequenceDictionary REFERENCE={input} OUTPUT={output.o7}'\n",
    "\n",
    "rule align_fastqs: \n",
    "    '''\n",
    "    Align paired-end reads to the indexed\n",
    "    reference genome.  Create metadata.\n",
    "    \n",
    "    bwa complains if using literal tabs, so\n",
    "    make sure your snakemake command prints\n",
    "    \"\\t\".\n",
    "    '''\n",
    "    input:\n",
    "        ref = ref,\n",
    "        r1 = ref + '.amb',\n",
    "        r2 = ref + '.ann',\n",
    "        r3 = ref + '.bwt',\n",
    "        r4 = ref + '.pac',\n",
    "        r5 = ref + '.sa',\n",
    "        fq1 = get_read1_fastq,\n",
    "        fq2 = get_read2_fastq\n",
    "    output:\n",
    "        'aligned/{sample}.bam'\n",
    "    params:\n",
    "        pl = 'ILLUMINA',\n",
    "        rg = '{sample}_rg',\n",
    "        sm = '{sample}'\n",
    "    shell:\n",
    "        'bwa mem -R \"@RG\\\\tID:{params.rg}\\\\tSM:{params.sm}\\\\tPL:{params.pl}\" {input.ref} {input.fq1} {input.fq2} | samtools sort -o {output}'\n",
    "        \n",
    "rule index_bams:\n",
    "    '''\n",
    "    Index aligned bams.\n",
    "    '''\n",
    "    input:\n",
    "        'aligned/{sample}.bam'\n",
    "    output:\n",
    "        'aligned/{sample}.bam.bai'\n",
    "    shell:\n",
    "        'samtools index {input}'\n",
    "        \n",
    "rule call_variants:\n",
    "    '''\n",
    "    Call variants from aligned bams\n",
    "    using GATK HaplotypeCaller.\n",
    "    '''\n",
    "    input:\n",
    "        ref = ref,\n",
    "        r1 = ref + '.fai',\n",
    "        r2 = refNoExt + '.dict',\n",
    "        bam = 'aligned/{sample}.bam',\n",
    "        bai = 'aligned/{sample}.bam.bai'\n",
    "    output:\n",
    "        'called/{sample}.vcf'\n",
    "    shell:\n",
    "        'gatk HaplotypeCaller -I {input.bam} -O {output} -R {input.ref}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's remove all the files we've generated and run the pipeline as one sequence of rules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "rm -r aligned/ called/ ref_genome/chr5_ref.dict ref_genome/chr5_ref.fasta.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's do a dry-run of our complete pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mBuilding DAG of jobs...\u001b[0m\n",
      "\u001b[33mJob counts:\n",
      "\tcount\tjobs\n",
      "\t2\talign_fastqs\n",
      "\t1\tall\n",
      "\t2\tcall_variants\n",
      "\t2\tindex_bams\n",
      "\t1\tindex_ref\n",
      "\t8\u001b[0m\n",
      "\u001b[32m\u001b[0m\n",
      "\u001b[32m[Thu Apr 18 14:25:17 2019]\u001b[0m\n",
      "\u001b[32mrule index_ref:\n",
      "    input: ref_genome/chr5_ref.fasta\n",
      "    output: ref_genome/chr5_ref.fasta.amb, ref_genome/chr5_ref.fasta.ann, ref_genome/chr5_ref.fasta.bwt, ref_genome/chr5_ref.fasta.pac, ref_genome/chr5_ref.fasta.sa, ref_genome/chr5_ref.fasta.fai, ref_genome/chr5_ref.dict\n",
      "    jobid: 3\u001b[0m\n",
      "\u001b[32m\u001b[0m\n",
      "\u001b[33mbwa index ref_genome/chr5_ref.fasta;samtools faidx ref_genome/chr5_ref.fasta;picard CreateSequenceDictionary REFERENCE=ref_genome/chr5_ref.fasta OUTPUT=ref_genome/chr5_ref.dict\u001b[0m\n",
      "\u001b[32m\u001b[0m\n",
      "\u001b[32m[Thu Apr 18 14:25:17 2019]\u001b[0m\n",
      "\u001b[32mrule align_fastqs:\n",
      "    input: ref_genome/chr5_ref.fasta, ref_genome/chr5_ref.fasta.amb, ref_genome/chr5_ref.fasta.ann, ref_genome/chr5_ref.fasta.bwt, ref_genome/chr5_ref.fasta.pac, ref_genome/chr5_ref.fasta.sa, raw_data/Patient_B.r1.fastq, raw_data/Patient_B.r2.fastq\n",
      "    output: aligned/PatientB.bam\n",
      "    jobid: 6\n",
      "    wildcards: sample=PatientB\u001b[0m\n",
      "\u001b[32m\u001b[0m\n",
      "\u001b[33mbwa mem -R \"@RG\\tID:PatientB_rg\\tSM:PatientB\\tPL:ILLUMINA\" ref_genome/chr5_ref.fasta raw_data/Patient_B.r1.fastq raw_data/Patient_B.r2.fastq | samtools sort -o aligned/PatientB.bam\u001b[0m\n",
      "\u001b[32m\u001b[0m\n",
      "\u001b[32m[Thu Apr 18 14:25:17 2019]\u001b[0m\n",
      "\u001b[32mrule align_fastqs:\n",
      "    input: ref_genome/chr5_ref.fasta, ref_genome/chr5_ref.fasta.amb, ref_genome/chr5_ref.fasta.ann, ref_genome/chr5_ref.fasta.bwt, ref_genome/chr5_ref.fasta.pac, ref_genome/chr5_ref.fasta.sa, raw_data/Patient_A.r1.fastq, raw_data/Patient_A.r2.fastq\n",
      "    output: aligned/PatientA.bam\n",
      "    jobid: 4\n",
      "    wildcards: sample=PatientA\u001b[0m\n",
      "\u001b[32m\u001b[0m\n",
      "\u001b[33mbwa mem -R \"@RG\\tID:PatientA_rg\\tSM:PatientA\\tPL:ILLUMINA\" ref_genome/chr5_ref.fasta raw_data/Patient_A.r1.fastq raw_data/Patient_A.r2.fastq | samtools sort -o aligned/PatientA.bam\u001b[0m\n",
      "\u001b[32m\u001b[0m\n",
      "\u001b[32m[Thu Apr 18 14:25:17 2019]\u001b[0m\n",
      "\u001b[32mrule index_bams:\n",
      "    input: aligned/PatientB.bam\n",
      "    output: aligned/PatientB.bam.bai\n",
      "    jobid: 7\n",
      "    wildcards: sample=PatientB\u001b[0m\n",
      "\u001b[32m\u001b[0m\n",
      "\u001b[33msamtools index aligned/PatientB.bam\u001b[0m\n",
      "\u001b[32m\u001b[0m\n",
      "\u001b[32m[Thu Apr 18 14:25:17 2019]\u001b[0m\n",
      "\u001b[32mrule index_bams:\n",
      "    input: aligned/PatientA.bam\n",
      "    output: aligned/PatientA.bam.bai\n",
      "    jobid: 5\n",
      "    wildcards: sample=PatientA\u001b[0m\n",
      "\u001b[32m\u001b[0m\n",
      "\u001b[33msamtools index aligned/PatientA.bam\u001b[0m\n",
      "\u001b[32m\u001b[0m\n",
      "\u001b[32m[Thu Apr 18 14:25:17 2019]\u001b[0m\n",
      "\u001b[32mrule call_variants:\n",
      "    input: ref_genome/chr5_ref.fasta, ref_genome/chr5_ref.fasta.fai, ref_genome/chr5_ref.dict, aligned/PatientA.bam, aligned/PatientA.bam.bai\n",
      "    output: called/PatientA.vcf\n",
      "    jobid: 1\n",
      "    wildcards: sample=PatientA\u001b[0m\n",
      "\u001b[32m\u001b[0m\n",
      "\u001b[33mgatk HaplotypeCaller -I aligned/PatientA.bam -O called/PatientA.vcf -R ref_genome/chr5_ref.fasta\u001b[0m\n",
      "\u001b[32m\u001b[0m\n",
      "\u001b[32m[Thu Apr 18 14:25:17 2019]\u001b[0m\n",
      "\u001b[32mrule call_variants:\n",
      "    input: ref_genome/chr5_ref.fasta, ref_genome/chr5_ref.fasta.fai, ref_genome/chr5_ref.dict, aligned/PatientB.bam, aligned/PatientB.bam.bai\n",
      "    output: called/PatientB.vcf\n",
      "    jobid: 2\n",
      "    wildcards: sample=PatientB\u001b[0m\n",
      "\u001b[32m\u001b[0m\n",
      "\u001b[33mgatk HaplotypeCaller -I aligned/PatientB.bam -O called/PatientB.vcf -R ref_genome/chr5_ref.fasta\u001b[0m\n",
      "\u001b[32m\u001b[0m\n",
      "\u001b[32m[Thu Apr 18 14:25:17 2019]\u001b[0m\n",
      "\u001b[32mlocalrule all:\n",
      "    input: called/PatientA.vcf, called/PatientB.vcf\n",
      "    jobid: 0\u001b[0m\n",
      "\u001b[32m\u001b[0m\n",
      "\u001b[33mJob counts:\n",
      "\tcount\tjobs\n",
      "\t2\talign_fastqs\n",
      "\t1\tall\n",
      "\t2\tcall_variants\n",
      "\t2\tindex_bams\n",
      "\t1\tindex_ref\n",
      "\t8\u001b[0m\n",
      "\u001b[33mThis was a dry-run (flag -n). The order of jobs does not reflect the order of execution.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!snakemake -nps Genomics_pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great!  Now let's see the DAG (directed acyclic graph)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mBuilding DAG of jobs...\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!snakemake -nps Genomics_pipeline --dag | dot -Tsvg > dag.svg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Genomics_pipeline             snakefile_test1\r\n",
      "Pipelines_for_genomics.ipynb  snakefile_test2\r\n",
      "dag.svg                       snakefile_test3\r\n",
      "\u001b[34mraw_data\u001b[m\u001b[m/                     snakefile_test4\r\n",
      "\u001b[34mref_genome\u001b[m\u001b[m/                   snakefile_test5\r\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![dag](dag.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks good - no unexpected recursion or weird relationships.  Now let's run it for real!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mBuilding DAG of jobs...\u001b[0m\n",
      "\u001b[33mUsing shell: /bin/bash\u001b[0m\n",
      "\u001b[33mProvided cores: 1\u001b[0m\n",
      "\u001b[33mRules claiming more threads will be scaled down.\u001b[0m\n",
      "\u001b[33mJob counts:\n",
      "\tcount\tjobs\n",
      "\t2\talign_fastqs\n",
      "\t1\tall\n",
      "\t2\tcall_variants\n",
      "\t2\tindex_bams\n",
      "\t1\tindex_ref\n",
      "\t8\u001b[0m\n",
      "\u001b[32m\u001b[0m\n",
      "\u001b[32m[Thu Apr 18 14:25:45 2019]\u001b[0m\n",
      "\u001b[32mrule index_ref:\n",
      "    input: ref_genome/chr5_ref.fasta\n",
      "    output: ref_genome/chr5_ref.fasta.amb, ref_genome/chr5_ref.fasta.ann, ref_genome/chr5_ref.fasta.bwt, ref_genome/chr5_ref.fasta.pac, ref_genome/chr5_ref.fasta.sa, ref_genome/chr5_ref.fasta.fai, ref_genome/chr5_ref.dict\n",
      "    jobid: 3\u001b[0m\n",
      "\u001b[32m\u001b[0m\n",
      "\u001b[33mbwa index ref_genome/chr5_ref.fasta;samtools faidx ref_genome/chr5_ref.fasta;picard CreateSequenceDictionary REFERENCE=ref_genome/chr5_ref.fasta OUTPUT=ref_genome/chr5_ref.dict\u001b[0m\n",
      "[bwa_index] Pack FASTA... 0.03 sec\n",
      "[bwa_index] Construct BWT for the packed sequence...\n",
      "[bwa_index] 1.04 seconds elapse.\n",
      "[bwa_index] Update BWT... 0.02 sec\n",
      "[bwa_index] Pack forward-only FASTA... 0.02 sec\n",
      "[bwa_index] Construct SA from BWT and Occ... 0.31 sec\n",
      "[main] Version: 0.7.17-r1188\n",
      "[main] CMD: bwa index ref_genome/chr5_ref.fasta\n",
      "[main] Real time: 1.425 sec; CPU: 1.416 sec\n",
      "INFO\t2019-04-18 14:25:47\tCreateSequenceDictionary\t\n",
      "\n",
      "********** NOTE: Picard's command line syntax is changing.\n",
      "**********\n",
      "********** For more information, please see:\n",
      "********** https://github.com/broadinstitute/picard/wiki/Command-Line-Syntax-Transition-For-Users-(Pre-Transition)\n",
      "**********\n",
      "********** The command line looks like this in the new syntax:\n",
      "**********\n",
      "**********    CreateSequenceDictionary -REFERENCE ref_genome/chr5_ref.fasta -OUTPUT ref_genome/chr5_ref.dict\n",
      "**********\n",
      "\n",
      "\n",
      "14:25:47.957 INFO  NativeLibraryLoader - Loading libgkl_compression.dylib from jar:file:/anaconda3/envs/snakemake_class/share/picard-2.19.0-0/picard.jar!/com/intel/gkl/native/libgkl_compression.dylib\n",
      "[Thu Apr 18 14:25:47 EDT 2019] CreateSequenceDictionary OUTPUT=ref_genome/chr5_ref.dict REFERENCE=ref_genome/chr5_ref.fasta    TRUNCATE_NAMES_AT_WHITESPACE=true NUM_SEQUENCES=2147483647 VERBOSITY=INFO QUIET=false VALIDATION_STRINGENCY=STRICT COMPRESSION_LEVEL=5 MAX_RECORDS_IN_RAM=500000 CREATE_INDEX=false CREATE_MD5_FILE=false GA4GH_CLIENT_SECRETS=client_secrets.json USE_JDK_DEFLATER=false USE_JDK_INFLATER=false\n",
      "[Thu Apr 18 14:25:47 EDT 2019] Executing as ballewbj@NCI-02034622-ML on Mac OS X 10.13.6 x86_64; OpenJDK 64-Bit Server VM 1.8.0_192-b01; Deflater: Intel; Inflater: Intel; Provider GCS is not available; Picard version: 2.19.0-SNAPSHOT\n",
      "[Thu Apr 18 14:25:48 EDT 2019] picard.sam.CreateSequenceDictionary done. Elapsed time: 0.00 minutes.\n",
      "Runtime.totalMemory()=514850816\n",
      "\u001b[32m[Thu Apr 18 14:25:48 2019]\u001b[0m\n",
      "\u001b[32mFinished job 3.\u001b[0m\n",
      "\u001b[32m1 of 8 steps (12%) done\u001b[0m\n",
      "\u001b[32m\u001b[0m\n",
      "\u001b[32m[Thu Apr 18 14:25:48 2019]\u001b[0m\n",
      "\u001b[32mrule align_fastqs:\n",
      "    input: ref_genome/chr5_ref.fasta, ref_genome/chr5_ref.fasta.amb, ref_genome/chr5_ref.fasta.ann, ref_genome/chr5_ref.fasta.bwt, ref_genome/chr5_ref.fasta.pac, ref_genome/chr5_ref.fasta.sa, raw_data/Patient_B.r1.fastq, raw_data/Patient_B.r2.fastq\n",
      "    output: aligned/PatientB.bam\n",
      "    jobid: 6\n",
      "    wildcards: sample=PatientB\u001b[0m\n",
      "\u001b[32m\u001b[0m\n",
      "\u001b[33mbwa mem -R \"@RG\\tID:PatientB_rg\\tSM:PatientB\\tPL:ILLUMINA\" ref_genome/chr5_ref.fasta raw_data/Patient_B.r1.fastq raw_data/Patient_B.r2.fastq | samtools sort -o aligned/PatientB.bam\u001b[0m\n",
      "[M::bwa_idx_load_from_disk] read 0 ALT contigs\n",
      "[M::process] read 66674 sequences (10000123 bp)...\n",
      "[M::process] read 66674 sequences (10000097 bp)...\n",
      "[M::mem_pestat] # candidate unique pairs for (FF, FR, RF, RR): (2, 31731, 0, 2)\n",
      "[M::mem_pestat] skip orientation FF as there are not enough pairs\n",
      "[M::mem_pestat] analyzing insert size distribution for orientation FR...\n",
      "[M::mem_pestat] (25, 50, 75) percentile: (244, 278, 314)\n",
      "[M::mem_pestat] low and high boundaries for computing mean and std.dev: (104, 454)\n",
      "[M::mem_pestat] mean and std.dev: (280.89, 52.60)\n",
      "[M::mem_pestat] low and high boundaries for proper pairs: (34, 524)\n",
      "[M::mem_pestat] skip orientation RF as there are not enough pairs\n",
      "[M::mem_pestat] skip orientation RR as there are not enough pairs\n",
      "[M::mem_process_seqs] Processed 66674 reads in 5.128 CPU sec, 5.085 real sec\n",
      "[M::process] read 66672 sequences (10000078 bp)...\n",
      "[M::mem_pestat] # candidate unique pairs for (FF, FR, RF, RR): (3, 31745, 0, 0)\n",
      "[M::mem_pestat] skip orientation FF as there are not enough pairs\n",
      "[M::mem_pestat] analyzing insert size distribution for orientation FR...\n",
      "[M::mem_pestat] (25, 50, 75) percentile: (243, 277, 314)\n",
      "[M::mem_pestat] low and high boundaries for computing mean and std.dev: (101, 456)\n",
      "[M::mem_pestat] mean and std.dev: (279.38, 52.50)\n",
      "[M::mem_pestat] low and high boundaries for proper pairs: (30, 527)\n",
      "[M::mem_pestat] skip orientation RF as there are not enough pairs\n",
      "[M::mem_pestat] skip orientation RR as there are not enough pairs\n",
      "[M::mem_process_seqs] Processed 66674 reads in 4.716 CPU sec, 4.618 real sec\n",
      "[M::process] read 66670 sequences (10000020 bp)...\n",
      "[M::mem_pestat] # candidate unique pairs for (FF, FR, RF, RR): (2, 31650, 0, 1)\n",
      "[M::mem_pestat] skip orientation FF as there are not enough pairs\n",
      "[M::mem_pestat] analyzing insert size distribution for orientation FR...\n",
      "[M::mem_pestat] (25, 50, 75) percentile: (242, 276, 312)\n",
      "[M::mem_pestat] low and high boundaries for computing mean and std.dev: (102, 452)\n",
      "[M::mem_pestat] mean and std.dev: (278.34, 52.21)\n",
      "[M::mem_pestat] low and high boundaries for proper pairs: (32, 522)\n",
      "[M::mem_pestat] skip orientation RF as there are not enough pairs\n",
      "[M::mem_pestat] skip orientation RR as there are not enough pairs\n",
      "[M::mem_process_seqs] Processed 66672 reads in 4.970 CPU sec, 4.874 real sec\n",
      "[M::process] read 66676 sequences (10000036 bp)...\n",
      "[M::mem_pestat] # candidate unique pairs for (FF, FR, RF, RR): (1, 31707, 0, 0)\n",
      "[M::mem_pestat] skip orientation FF as there are not enough pairs\n",
      "[M::mem_pestat] analyzing insert size distribution for orientation FR...\n",
      "[M::mem_pestat] (25, 50, 75) percentile: (243, 277, 313)\n",
      "[M::mem_pestat] low and high boundaries for computing mean and std.dev: (103, 453)\n",
      "[M::mem_pestat] mean and std.dev: (279.15, 52.39)\n",
      "[M::mem_pestat] low and high boundaries for proper pairs: (33, 523)\n",
      "[M::mem_pestat] skip orientation RF as there are not enough pairs\n",
      "[M::mem_pestat] skip orientation RR as there are not enough pairs\n",
      "[M::mem_process_seqs] Processed 66670 reads in 4.781 CPU sec, 4.680 real sec\n",
      "[M::process] read 66672 sequences (10000088 bp)...\n",
      "[M::mem_pestat] # candidate unique pairs for (FF, FR, RF, RR): (3, 31707, 0, 1)\n",
      "[M::mem_pestat] skip orientation FF as there are not enough pairs\n",
      "[M::mem_pestat] analyzing insert size distribution for orientation FR...\n",
      "[M::mem_pestat] (25, 50, 75) percentile: (243, 276, 313)\n",
      "[M::mem_pestat] low and high boundaries for computing mean and std.dev: (103, 453)\n",
      "[M::mem_pestat] mean and std.dev: (278.80, 52.64)\n",
      "[M::mem_pestat] low and high boundaries for proper pairs: (33, 523)\n",
      "[M::mem_pestat] skip orientation RF as there are not enough pairs\n",
      "[M::mem_pestat] skip orientation RR as there are not enough pairs\n",
      "[M::mem_process_seqs] Processed 66676 reads in 5.330 CPU sec, 5.232 real sec\n",
      "[M::process] read 58410 sequences (8760675 bp)...\n",
      "[M::mem_pestat] # candidate unique pairs for (FF, FR, RF, RR): (0, 31749, 0, 0)\n",
      "[M::mem_pestat] skip orientation FF as there are not enough pairs\n",
      "[M::mem_pestat] analyzing insert size distribution for orientation FR...\n",
      "[M::mem_pestat] (25, 50, 75) percentile: (244, 278, 315)\n",
      "[M::mem_pestat] low and high boundaries for computing mean and std.dev: (102, 457)\n",
      "[M::mem_pestat] mean and std.dev: (280.56, 52.72)\n",
      "[M::mem_pestat] low and high boundaries for proper pairs: (31, 528)\n",
      "[M::mem_pestat] skip orientation RF as there are not enough pairs\n",
      "[M::mem_pestat] skip orientation RR as there are not enough pairs\n",
      "[M::mem_process_seqs] Processed 66672 reads in 4.891 CPU sec, 4.782 real sec\n",
      "[M::mem_pestat] # candidate unique pairs for (FF, FR, RF, RR): (2, 27840, 0, 0)\n",
      "[M::mem_pestat] skip orientation FF as there are not enough pairs\n",
      "[M::mem_pestat] analyzing insert size distribution for orientation FR...\n",
      "[M::mem_pestat] (25, 50, 75) percentile: (245, 279, 317)\n",
      "[M::mem_pestat] low and high boundaries for computing mean and std.dev: (101, 461)\n",
      "[M::mem_pestat] mean and std.dev: (282.17, 53.74)\n",
      "[M::mem_pestat] low and high boundaries for proper pairs: (29, 533)\n",
      "[M::mem_pestat] skip orientation RF as there are not enough pairs\n",
      "[M::mem_pestat] skip orientation RR as there are not enough pairs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[M::mem_process_seqs] Processed 58410 reads in 4.047 CPU sec, 3.987 real sec\n",
      "[main] Version: 0.7.17-r1188\n",
      "[main] CMD: bwa mem -R @RG\\tID:PatientB_rg\\tSM:PatientB\\tPL:ILLUMINA ref_genome/chr5_ref.fasta raw_data/Patient_B.r1.fastq raw_data/Patient_B.r2.fastq\n",
      "[main] Real time: 33.386 sec; CPU: 33.966 sec\n",
      "\u001b[32m[Thu Apr 18 14:26:23 2019]\u001b[0m\n",
      "\u001b[32mFinished job 6.\u001b[0m\n",
      "\u001b[32m2 of 8 steps (25%) done\u001b[0m\n",
      "\u001b[32m\u001b[0m\n",
      "\u001b[32m[Thu Apr 18 14:26:23 2019]\u001b[0m\n",
      "\u001b[32mrule align_fastqs:\n",
      "    input: ref_genome/chr5_ref.fasta, ref_genome/chr5_ref.fasta.amb, ref_genome/chr5_ref.fasta.ann, ref_genome/chr5_ref.fasta.bwt, ref_genome/chr5_ref.fasta.pac, ref_genome/chr5_ref.fasta.sa, raw_data/Patient_A.r1.fastq, raw_data/Patient_A.r2.fastq\n",
      "    output: aligned/PatientA.bam\n",
      "    jobid: 4\n",
      "    wildcards: sample=PatientA\u001b[0m\n",
      "\u001b[32m\u001b[0m\n",
      "\u001b[33mbwa mem -R \"@RG\\tID:PatientA_rg\\tSM:PatientA\\tPL:ILLUMINA\" ref_genome/chr5_ref.fasta raw_data/Patient_A.r1.fastq raw_data/Patient_A.r2.fastq | samtools sort -o aligned/PatientA.bam\u001b[0m\n",
      "[M::bwa_idx_load_from_disk] read 0 ALT contigs\n",
      "[M::process] read 66678 sequences (10000219 bp)...\n",
      "[M::process] read 66674 sequences (10000016 bp)...\n",
      "[M::mem_pestat] # candidate unique pairs for (FF, FR, RF, RR): (4, 31683, 0, 0)\n",
      "[M::mem_pestat] skip orientation FF as there are not enough pairs\n",
      "[M::mem_pestat] analyzing insert size distribution for orientation FR...\n",
      "[M::mem_pestat] (25, 50, 75) percentile: (251, 285, 323)\n",
      "[M::mem_pestat] low and high boundaries for computing mean and std.dev: (107, 467)\n",
      "[M::mem_pestat] mean and std.dev: (287.82, 54.32)\n",
      "[M::mem_pestat] low and high boundaries for proper pairs: (35, 539)\n",
      "[M::mem_pestat] skip orientation RF as there are not enough pairs\n",
      "[M::mem_pestat] skip orientation RR as there are not enough pairs\n",
      "[M::mem_process_seqs] Processed 66678 reads in 4.854 CPU sec, 4.806 real sec\n",
      "[M::process] read 66674 sequences (10000261 bp)...\n",
      "[M::mem_pestat] # candidate unique pairs for (FF, FR, RF, RR): (1, 31690, 0, 1)\n",
      "[M::mem_pestat] skip orientation FF as there are not enough pairs\n",
      "[M::mem_pestat] analyzing insert size distribution for orientation FR...\n",
      "[M::mem_pestat] (25, 50, 75) percentile: (250, 285, 322)\n",
      "[M::mem_pestat] low and high boundaries for computing mean and std.dev: (106, 466)\n",
      "[M::mem_pestat] mean and std.dev: (287.19, 54.24)\n",
      "[M::mem_pestat] low and high boundaries for proper pairs: (34, 538)\n",
      "[M::mem_pestat] skip orientation RF as there are not enough pairs\n",
      "[M::mem_pestat] skip orientation RR as there are not enough pairs\n",
      "[M::mem_process_seqs] Processed 66674 reads in 4.825 CPU sec, 4.725 real sec\n",
      "[M::process] read 66676 sequences (10000211 bp)...\n",
      "[M::mem_pestat] # candidate unique pairs for (FF, FR, RF, RR): (1, 31694, 0, 0)\n",
      "[M::mem_pestat] skip orientation FF as there are not enough pairs\n",
      "[M::mem_pestat] analyzing insert size distribution for orientation FR...\n",
      "[M::mem_pestat] (25, 50, 75) percentile: (249, 283, 320)\n",
      "[M::mem_pestat] low and high boundaries for computing mean and std.dev: (107, 462)\n",
      "[M::mem_pestat] mean and std.dev: (285.44, 53.83)\n",
      "[M::mem_pestat] low and high boundaries for proper pairs: (36, 533)\n",
      "[M::mem_pestat] skip orientation RF as there are not enough pairs\n",
      "[M::mem_pestat] skip orientation RR as there are not enough pairs\n",
      "[M::mem_process_seqs] Processed 66674 reads in 4.839 CPU sec, 4.744 real sec\n",
      "[M::process] read 66676 sequences (10000065 bp)...\n",
      "[M::mem_pestat] # candidate unique pairs for (FF, FR, RF, RR): (3, 31685, 0, 0)\n",
      "[M::mem_pestat] skip orientation FF as there are not enough pairs\n",
      "[M::mem_pestat] analyzing insert size distribution for orientation FR...\n",
      "[M::mem_pestat] (25, 50, 75) percentile: (249, 283, 320)\n",
      "[M::mem_pestat] low and high boundaries for computing mean and std.dev: (107, 462)\n",
      "[M::mem_pestat] mean and std.dev: (285.40, 53.25)\n",
      "[M::mem_pestat] low and high boundaries for proper pairs: (36, 533)\n",
      "[M::mem_pestat] skip orientation RF as there are not enough pairs\n",
      "[M::mem_pestat] skip orientation RR as there are not enough pairs\n",
      "[M::mem_process_seqs] Processed 66676 reads in 4.878 CPU sec, 4.780 real sec\n",
      "[M::process] read 61730 sequences (9258761 bp)...\n",
      "[M::mem_pestat] # candidate unique pairs for (FF, FR, RF, RR): (4, 31643, 0, 0)\n",
      "[M::mem_pestat] skip orientation FF as there are not enough pairs\n",
      "[M::mem_pestat] analyzing insert size distribution for orientation FR...\n",
      "[M::mem_pestat] (25, 50, 75) percentile: (249, 283, 320)\n",
      "[M::mem_pestat] low and high boundaries for computing mean and std.dev: (107, 462)\n",
      "[M::mem_pestat] mean and std.dev: (286.05, 54.10)\n",
      "[M::mem_pestat] low and high boundaries for proper pairs: (36, 533)\n",
      "[M::mem_pestat] skip orientation RF as there are not enough pairs\n",
      "[M::mem_pestat] skip orientation RR as there are not enough pairs\n",
      "[M::mem_process_seqs] Processed 66676 reads in 4.857 CPU sec, 4.761 real sec\n",
      "[M::mem_pestat] # candidate unique pairs for (FF, FR, RF, RR): (2, 29382, 0, 0)\n",
      "[M::mem_pestat] skip orientation FF as there are not enough pairs\n",
      "[M::mem_pestat] analyzing insert size distribution for orientation FR...\n",
      "[M::mem_pestat] (25, 50, 75) percentile: (250, 284, 322)\n",
      "[M::mem_pestat] low and high boundaries for computing mean and std.dev: (106, 466)\n",
      "[M::mem_pestat] mean and std.dev: (286.64, 53.74)\n",
      "[M::mem_pestat] low and high boundaries for proper pairs: (34, 538)\n",
      "[M::mem_pestat] skip orientation RF as there are not enough pairs\n",
      "[M::mem_pestat] skip orientation RR as there are not enough pairs\n",
      "[M::mem_process_seqs] Processed 61730 reads in 4.399 CPU sec, 4.342 real sec\n",
      "[main] Version: 0.7.17-r1188\n",
      "[main] CMD: bwa mem -R @RG\\tID:PatientA_rg\\tSM:PatientA\\tPL:ILLUMINA ref_genome/chr5_ref.fasta raw_data/Patient_A.r1.fastq raw_data/Patient_A.r2.fastq\n",
      "[main] Real time: 28.292 sec; CPU: 28.763 sec\n",
      "\u001b[32m[Thu Apr 18 14:26:53 2019]\u001b[0m\n",
      "\u001b[32mFinished job 4.\u001b[0m\n",
      "\u001b[32m3 of 8 steps (38%) done\u001b[0m\n",
      "\u001b[32m\u001b[0m\n",
      "\u001b[32m[Thu Apr 18 14:26:53 2019]\u001b[0m\n",
      "\u001b[32mrule index_bams:\n",
      "    input: aligned/PatientB.bam\n",
      "    output: aligned/PatientB.bam.bai\n",
      "    jobid: 7\n",
      "    wildcards: sample=PatientB\u001b[0m\n",
      "\u001b[32m\u001b[0m\n",
      "\u001b[33msamtools index aligned/PatientB.bam\u001b[0m\n",
      "\u001b[32m[Thu Apr 18 14:26:53 2019]\u001b[0m\n",
      "\u001b[32mFinished job 7.\u001b[0m\n",
      "\u001b[32m4 of 8 steps (50%) done\u001b[0m\n",
      "\u001b[32m\u001b[0m\n",
      "\u001b[32m[Thu Apr 18 14:26:53 2019]\u001b[0m\n",
      "\u001b[32mrule call_variants:\n",
      "    input: ref_genome/chr5_ref.fasta, ref_genome/chr5_ref.fasta.fai, ref_genome/chr5_ref.dict, aligned/PatientB.bam, aligned/PatientB.bam.bai\n",
      "    output: called/PatientB.vcf\n",
      "    jobid: 2\n",
      "    wildcards: sample=PatientB\u001b[0m\n",
      "\u001b[32m\u001b[0m\n",
      "\u001b[33mgatk HaplotypeCaller -I aligned/PatientB.bam -O called/PatientB.vcf -R ref_genome/chr5_ref.fasta\u001b[0m\n",
      "Using GATK jar /anaconda3/envs/snakemake_class/share/gatk4-4.1.1.0-0/gatk-package-4.1.1.0-local.jar\n",
      "Running:\n",
      "    java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -jar /anaconda3/envs/snakemake_class/share/gatk4-4.1.1.0-0/gatk-package-4.1.1.0-local.jar HaplotypeCaller -I aligned/PatientB.bam -O called/PatientB.vcf -R ref_genome/chr5_ref.fasta\n",
      "14:26:55.610 INFO  NativeLibraryLoader - Loading libgkl_compression.dylib from jar:file:/anaconda3/envs/snakemake_class/share/gatk4-4.1.1.0-0/gatk-package-4.1.1.0-local.jar!/com/intel/gkl/native/libgkl_compression.dylib\n",
      "Apr 18, 2019 2:26:57 PM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine\n",
      "INFO: Failed to detect whether we are running on Google Compute Engine.\n",
      "14:26:57.291 INFO  HaplotypeCaller - ------------------------------------------------------------\n",
      "14:26:57.292 INFO  HaplotypeCaller - The Genome Analysis Toolkit (GATK) v4.1.1.0\n",
      "14:26:57.292 INFO  HaplotypeCaller - For support and documentation go to https://software.broadinstitute.org/gatk/\n",
      "14:26:57.292 INFO  HaplotypeCaller - Executing as ballewbj@NCI-02034622-ML on Mac OS X v10.13.6 x86_64\n",
      "14:26:57.292 INFO  HaplotypeCaller - Java runtime: OpenJDK 64-Bit Server VM v1.8.0_192-b01\n",
      "14:26:57.292 INFO  HaplotypeCaller - Start Date/Time: April 18, 2019 2:26:55 PM EDT\n",
      "14:26:57.292 INFO  HaplotypeCaller - ------------------------------------------------------------\n",
      "14:26:57.292 INFO  HaplotypeCaller - ------------------------------------------------------------\n",
      "14:26:57.293 INFO  HaplotypeCaller - HTSJDK Version: 2.19.0\n",
      "14:26:57.293 INFO  HaplotypeCaller - Picard Version: 2.19.0\n",
      "14:26:57.293 INFO  HaplotypeCaller - HTSJDK Defaults.COMPRESSION_LEVEL : 2\n",
      "14:26:57.293 INFO  HaplotypeCaller - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false\n",
      "14:26:57.293 INFO  HaplotypeCaller - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true\n",
      "14:26:57.293 INFO  HaplotypeCaller - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false\n",
      "14:26:57.293 INFO  HaplotypeCaller - Deflater: IntelDeflater\n",
      "14:26:57.293 INFO  HaplotypeCaller - Inflater: IntelInflater\n",
      "14:26:57.293 INFO  HaplotypeCaller - GCS max retries/reopens: 20\n",
      "14:26:57.293 INFO  HaplotypeCaller - Requester pays: disabled\n",
      "14:26:57.293 INFO  HaplotypeCaller - Initializing engine\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14:26:57.632 INFO  HaplotypeCaller - Done initializing engine\n",
      "14:26:57.638 INFO  HaplotypeCallerEngine - Disabling physical phasing, which is supported only for reference-model confidence output\n",
      "14:26:57.649 INFO  NativeLibraryLoader - Loading libgkl_utils.dylib from jar:file:/anaconda3/envs/snakemake_class/share/gatk4-4.1.1.0-0/gatk-package-4.1.1.0-local.jar!/com/intel/gkl/native/libgkl_utils.dylib\n",
      "14:26:57.651 WARN  NativeLibraryLoader - Unable to find native library: native/libgkl_pairhmm_omp.dylib\n",
      "14:26:57.651 INFO  PairHMM - OpenMP multi-threaded AVX-accelerated native PairHMM implementation is not supported\n",
      "14:26:57.651 INFO  NativeLibraryLoader - Loading libgkl_pairhmm.dylib from jar:file:/anaconda3/envs/snakemake_class/share/gatk4-4.1.1.0-0/gatk-package-4.1.1.0-local.jar!/com/intel/gkl/native/libgkl_pairhmm.dylib\n",
      "14:26:57.669 INFO  IntelPairHmm - Flush-to-zero (FTZ) is enabled when running PairHMM\n",
      "14:26:57.669 WARN  IntelPairHmm - Ignoring request for 4 threads; not using OpenMP implementation\n",
      "14:26:57.669 INFO  PairHMM - Using the AVX-accelerated native PairHMM implementation\n",
      "14:26:57.695 INFO  ProgressMeter - Starting traversal\n",
      "14:26:57.696 INFO  ProgressMeter -        Current Locus  Elapsed Minutes     Regions Processed   Regions/Minute\n",
      "14:27:07.708 INFO  ProgressMeter -             5:348221              0.2                  1620           9708.3\n",
      "14:27:18.058 INFO  ProgressMeter -             5:739406              0.3                  3530          10401.7\n",
      "14:27:28.078 INFO  ProgressMeter -            5:1210990              0.5                  5770          11394.9\n",
      "14:27:35.899 INFO  HaplotypeCaller - 1188 read(s) filtered by: ((((((((MappingQualityReadFilter AND MappingQualityAvailableReadFilter) AND MappedReadFilter) AND NotSecondaryAlignmentReadFilter) AND NotDuplicateReadFilter) AND PassesVendorQualityCheckReadFilter) AND NonZeroReferenceLengthAlignmentReadFilter) AND GoodCigarReadFilter) AND WellformedReadFilter)\n",
      "  1188 read(s) filtered by: (((((((MappingQualityReadFilter AND MappingQualityAvailableReadFilter) AND MappedReadFilter) AND NotSecondaryAlignmentReadFilter) AND NotDuplicateReadFilter) AND PassesVendorQualityCheckReadFilter) AND NonZeroReferenceLengthAlignmentReadFilter) AND GoodCigarReadFilter)\n",
      "      1188 read(s) filtered by: ((((((MappingQualityReadFilter AND MappingQualityAvailableReadFilter) AND MappedReadFilter) AND NotSecondaryAlignmentReadFilter) AND NotDuplicateReadFilter) AND PassesVendorQualityCheckReadFilter) AND NonZeroReferenceLengthAlignmentReadFilter)\n",
      "          1188 read(s) filtered by: (((((MappingQualityReadFilter AND MappingQualityAvailableReadFilter) AND MappedReadFilter) AND NotSecondaryAlignmentReadFilter) AND NotDuplicateReadFilter) AND PassesVendorQualityCheckReadFilter)\n",
      "              1188 read(s) filtered by: ((((MappingQualityReadFilter AND MappingQualityAvailableReadFilter) AND MappedReadFilter) AND NotSecondaryAlignmentReadFilter) AND NotDuplicateReadFilter)\n",
      "                  1188 read(s) filtered by: (((MappingQualityReadFilter AND MappingQualityAvailableReadFilter) AND MappedReadFilter) AND NotSecondaryAlignmentReadFilter)\n",
      "                      1188 read(s) filtered by: ((MappingQualityReadFilter AND MappingQualityAvailableReadFilter) AND MappedReadFilter)\n",
      "                          1188 read(s) filtered by: (MappingQualityReadFilter AND MappingQualityAvailableReadFilter)\n",
      "                              1188 read(s) filtered by: MappingQualityReadFilter \n",
      "\n",
      "14:27:35.899 INFO  ProgressMeter -            5:4198556              0.6                 16284          25575.0\n",
      "14:27:35.900 INFO  ProgressMeter - Traversal complete. Processed 16284 total regions in 0.6 minutes.\n",
      "14:27:35.904 INFO  VectorLoglessPairHMM - Time spent in setup for JNI call : 0.05956057000000001\n",
      "14:27:35.904 INFO  PairHMM - Total compute time in PairHMM computeLogLikelihoods() : 8.678672608000001\n",
      "14:27:35.904 INFO  SmithWatermanAligner - Total compute time in java Smith-Waterman : 4.73 sec\n",
      "14:27:35.905 INFO  HaplotypeCaller - Shutting down engine\n",
      "[April 18, 2019 2:27:35 PM EDT] org.broadinstitute.hellbender.tools.walkers.haplotypecaller.HaplotypeCaller done. Elapsed time: 0.67 minutes.\n",
      "Runtime.totalMemory()=1347420160\n",
      "\u001b[32m[Thu Apr 18 14:27:36 2019]\u001b[0m\n",
      "\u001b[32mFinished job 2.\u001b[0m\n",
      "\u001b[32m5 of 8 steps (62%) done\u001b[0m\n",
      "\u001b[32m\u001b[0m\n",
      "\u001b[32m[Thu Apr 18 14:27:36 2019]\u001b[0m\n",
      "\u001b[32mrule index_bams:\n",
      "    input: aligned/PatientA.bam\n",
      "    output: aligned/PatientA.bam.bai\n",
      "    jobid: 5\n",
      "    wildcards: sample=PatientA\u001b[0m\n",
      "\u001b[32m\u001b[0m\n",
      "\u001b[33msamtools index aligned/PatientA.bam\u001b[0m\n",
      "\u001b[32m[Thu Apr 18 14:27:36 2019]\u001b[0m\n",
      "\u001b[32mFinished job 5.\u001b[0m\n",
      "\u001b[32m6 of 8 steps (75%) done\u001b[0m\n",
      "\u001b[32m\u001b[0m\n",
      "\u001b[32m[Thu Apr 18 14:27:36 2019]\u001b[0m\n",
      "\u001b[32mrule call_variants:\n",
      "    input: ref_genome/chr5_ref.fasta, ref_genome/chr5_ref.fasta.fai, ref_genome/chr5_ref.dict, aligned/PatientA.bam, aligned/PatientA.bam.bai\n",
      "    output: called/PatientA.vcf\n",
      "    jobid: 1\n",
      "    wildcards: sample=PatientA\u001b[0m\n",
      "\u001b[32m\u001b[0m\n",
      "\u001b[33mgatk HaplotypeCaller -I aligned/PatientA.bam -O called/PatientA.vcf -R ref_genome/chr5_ref.fasta\u001b[0m\n",
      "Using GATK jar /anaconda3/envs/snakemake_class/share/gatk4-4.1.1.0-0/gatk-package-4.1.1.0-local.jar\n",
      "Running:\n",
      "    java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -jar /anaconda3/envs/snakemake_class/share/gatk4-4.1.1.0-0/gatk-package-4.1.1.0-local.jar HaplotypeCaller -I aligned/PatientA.bam -O called/PatientA.vcf -R ref_genome/chr5_ref.fasta\n",
      "14:27:38.374 INFO  NativeLibraryLoader - Loading libgkl_compression.dylib from jar:file:/anaconda3/envs/snakemake_class/share/gatk4-4.1.1.0-0/gatk-package-4.1.1.0-local.jar!/com/intel/gkl/native/libgkl_compression.dylib\n",
      "Apr 18, 2019 2:27:39 PM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine\n",
      "INFO: Failed to detect whether we are running on Google Compute Engine.\n",
      "14:27:39.552 INFO  HaplotypeCaller - ------------------------------------------------------------\n",
      "14:27:39.552 INFO  HaplotypeCaller - The Genome Analysis Toolkit (GATK) v4.1.1.0\n",
      "14:27:39.552 INFO  HaplotypeCaller - For support and documentation go to https://software.broadinstitute.org/gatk/\n",
      "14:27:39.552 INFO  HaplotypeCaller - Executing as ballewbj@NCI-02034622-ML on Mac OS X v10.13.6 x86_64\n",
      "14:27:39.552 INFO  HaplotypeCaller - Java runtime: OpenJDK 64-Bit Server VM v1.8.0_192-b01\n",
      "14:27:39.553 INFO  HaplotypeCaller - Start Date/Time: April 18, 2019 2:27:38 PM EDT\n",
      "14:27:39.553 INFO  HaplotypeCaller - ------------------------------------------------------------\n",
      "14:27:39.553 INFO  HaplotypeCaller - ------------------------------------------------------------\n",
      "14:27:39.553 INFO  HaplotypeCaller - HTSJDK Version: 2.19.0\n",
      "14:27:39.553 INFO  HaplotypeCaller - Picard Version: 2.19.0\n",
      "14:27:39.553 INFO  HaplotypeCaller - HTSJDK Defaults.COMPRESSION_LEVEL : 2\n",
      "14:27:39.553 INFO  HaplotypeCaller - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false\n",
      "14:27:39.553 INFO  HaplotypeCaller - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true\n",
      "14:27:39.553 INFO  HaplotypeCaller - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false\n",
      "14:27:39.553 INFO  HaplotypeCaller - Deflater: IntelDeflater\n",
      "14:27:39.553 INFO  HaplotypeCaller - Inflater: IntelInflater\n",
      "14:27:39.553 INFO  HaplotypeCaller - GCS max retries/reopens: 20\n",
      "14:27:39.554 INFO  HaplotypeCaller - Requester pays: disabled\n",
      "14:27:39.554 INFO  HaplotypeCaller - Initializing engine\n",
      "14:27:39.880 INFO  HaplotypeCaller - Done initializing engine\n",
      "14:27:39.885 INFO  HaplotypeCallerEngine - Disabling physical phasing, which is supported only for reference-model confidence output\n",
      "14:27:39.896 INFO  NativeLibraryLoader - Loading libgkl_utils.dylib from jar:file:/anaconda3/envs/snakemake_class/share/gatk4-4.1.1.0-0/gatk-package-4.1.1.0-local.jar!/com/intel/gkl/native/libgkl_utils.dylib\n",
      "14:27:39.899 WARN  NativeLibraryLoader - Unable to find native library: native/libgkl_pairhmm_omp.dylib\n",
      "14:27:39.899 INFO  PairHMM - OpenMP multi-threaded AVX-accelerated native PairHMM implementation is not supported\n",
      "14:27:39.899 INFO  NativeLibraryLoader - Loading libgkl_pairhmm.dylib from jar:file:/anaconda3/envs/snakemake_class/share/gatk4-4.1.1.0-0/gatk-package-4.1.1.0-local.jar!/com/intel/gkl/native/libgkl_pairhmm.dylib\n",
      "14:27:39.917 INFO  IntelPairHmm - Flush-to-zero (FTZ) is enabled when running PairHMM\n",
      "14:27:39.917 WARN  IntelPairHmm - Ignoring request for 4 threads; not using OpenMP implementation\n",
      "14:27:39.918 INFO  PairHMM - Using the AVX-accelerated native PairHMM implementation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14:27:39.943 INFO  ProgressMeter - Starting traversal\n",
      "14:27:39.943 INFO  ProgressMeter -        Current Locus  Elapsed Minutes     Regions Processed   Regions/Minute\n",
      "14:27:49.953 INFO  ProgressMeter -             5:540872              0.2                  2280          13666.3\n",
      "14:27:59.995 INFO  ProgressMeter -             5:903322              0.3                  4200          12567.3\n",
      "14:28:10.008 INFO  ProgressMeter -            5:1422749              0.5                  6800          13570.6\n",
      "14:28:14.057 INFO  HaplotypeCaller - 1021 read(s) filtered by: ((((((((MappingQualityReadFilter AND MappingQualityAvailableReadFilter) AND MappedReadFilter) AND NotSecondaryAlignmentReadFilter) AND NotDuplicateReadFilter) AND PassesVendorQualityCheckReadFilter) AND NonZeroReferenceLengthAlignmentReadFilter) AND GoodCigarReadFilter) AND WellformedReadFilter)\n",
      "  1021 read(s) filtered by: (((((((MappingQualityReadFilter AND MappingQualityAvailableReadFilter) AND MappedReadFilter) AND NotSecondaryAlignmentReadFilter) AND NotDuplicateReadFilter) AND PassesVendorQualityCheckReadFilter) AND NonZeroReferenceLengthAlignmentReadFilter) AND GoodCigarReadFilter)\n",
      "      1021 read(s) filtered by: ((((((MappingQualityReadFilter AND MappingQualityAvailableReadFilter) AND MappedReadFilter) AND NotSecondaryAlignmentReadFilter) AND NotDuplicateReadFilter) AND PassesVendorQualityCheckReadFilter) AND NonZeroReferenceLengthAlignmentReadFilter)\n",
      "          1021 read(s) filtered by: (((((MappingQualityReadFilter AND MappingQualityAvailableReadFilter) AND MappedReadFilter) AND NotSecondaryAlignmentReadFilter) AND NotDuplicateReadFilter) AND PassesVendorQualityCheckReadFilter)\n",
      "              1021 read(s) filtered by: ((((MappingQualityReadFilter AND MappingQualityAvailableReadFilter) AND MappedReadFilter) AND NotSecondaryAlignmentReadFilter) AND NotDuplicateReadFilter)\n",
      "                  1021 read(s) filtered by: (((MappingQualityReadFilter AND MappingQualityAvailableReadFilter) AND MappedReadFilter) AND NotSecondaryAlignmentReadFilter)\n",
      "                      1021 read(s) filtered by: ((MappingQualityReadFilter AND MappingQualityAvailableReadFilter) AND MappedReadFilter)\n",
      "                          1021 read(s) filtered by: (MappingQualityReadFilter AND MappingQualityAvailableReadFilter)\n",
      "                              1021 read(s) filtered by: MappingQualityReadFilter \n",
      "\n",
      "14:28:14.057 INFO  ProgressMeter -            5:4199756              0.6                 16410          28862.1\n",
      "14:28:14.057 INFO  ProgressMeter - Traversal complete. Processed 16410 total regions in 0.6 minutes.\n",
      "14:28:14.064 INFO  VectorLoglessPairHMM - Time spent in setup for JNI call : 0.054663761000000005\n",
      "14:28:14.064 INFO  PairHMM - Total compute time in PairHMM computeLogLikelihoods() : 6.252866576000001\n",
      "14:28:14.064 INFO  SmithWatermanAligner - Total compute time in java Smith-Waterman : 4.38 sec\n",
      "14:28:14.064 INFO  HaplotypeCaller - Shutting down engine\n",
      "[April 18, 2019 2:28:14 PM EDT] org.broadinstitute.hellbender.tools.walkers.haplotypecaller.HaplotypeCaller done. Elapsed time: 0.60 minutes.\n",
      "Runtime.totalMemory()=1531969536\n",
      "\u001b[32m[Thu Apr 18 14:28:14 2019]\u001b[0m\n",
      "\u001b[32mFinished job 1.\u001b[0m\n",
      "\u001b[32m7 of 8 steps (88%) done\u001b[0m\n",
      "\u001b[32m\u001b[0m\n",
      "\u001b[32m[Thu Apr 18 14:28:14 2019]\u001b[0m\n",
      "\u001b[32mlocalrule all:\n",
      "    input: called/PatientA.vcf, called/PatientB.vcf\n",
      "    jobid: 0\u001b[0m\n",
      "\u001b[32m\u001b[0m\n",
      "\u001b[32m[Thu Apr 18 14:28:14 2019]\u001b[0m\n",
      "\u001b[32mFinished job 0.\u001b[0m\n",
      "\u001b[32m8 of 8 steps (100%) done\u001b[0m\n",
      "\u001b[33mComplete log: /Users/ballewbj/snakemake_class/snakemake/Genomics_practice/.snakemake/log/2019-04-18T142545.742708.snakemake.log\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!snakemake -ps Genomics_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "called/PatientA.vcf\r\n",
      "#CHROM\tPOS\tID\tREF\tALT\tQUAL\tFILTER\tINFO\tFORMAT\tPatientA\r\n",
      "5\t100327\t.\tG\tC\t1496.03\t.\tAC=2;AF=1.00;AN=2;DP=38;ExcessHet=3.0103;FS=0.000;MLEAC=2;MLEAF=1.00;MQ=60.00;QD=25.36;SOR=0.798\tGT:AD:DP:GQ:PL\t1/1:0,38:38:99:1510,114,0\r\n",
      "5\t100514\t.\tA\tG\t1864.03\t.\tAC=2;AF=1.00;AN=2;DP=45;ExcessHet=3.0103;FS=0.000;MLEAC=2;MLEAF=1.00;MQ=60.00;QD=28.73;SOR=0.929\tGT:AD:DP:GQ:PL\t1/1:0,45:45:99:1878,135,0\r\n",
      "5\t101444\t.\tT\tTTTTA\t1380.06\t.\tAC=2;AF=1.00;AN=2;DP=39;ExcessHet=3.0103;FS=0.000;MLEAC=2;MLEAF=1.00;MQ=60.00;QD=30.97;SOR=1.214\tGT:AD:DP:GQ:PL\t1/1:0,31:31:93:1394,93,0\r\n",
      "5\t101497\t.\tC\tT\t1283.03\t.\tAC=2;AF=1.00;AN=2;DP=33;ExcessHet=3.0103;FS=0.000;MLEAC=2;MLEAF=1.00;MQ=60.00;QD=27.24;SOR=1.022\tGT:AD:DP:GQ:PL\t1/1:0,33:33:99:1297,99,0\r\n",
      "5\t101748\t.\tT\tC\t1395.03\t.\tAC=2;AF=1.00;AN=2;DP=37;ExcessHet=3.0103;FS=0.000;MLEAC=2;MLEAF=1.00;MQ=60.00;QD=28.20;SOR=0.746\tGT:AD:DP:GQ:PL\t1/1:0,37:37:99:1409,111,0\r\n",
      "\r\n",
      "called/PatientB.vcf\r\n",
      "#CHROM\tPOS\tID\tREF\tALT\tQUAL\tFILTER\tINFO\tFORMAT\tPatientB\r\n",
      "5\t100327\t.\tG\tC\t641.60\t.\tAC=1;AF=0.500;AN=2;BaseQRankSum=-0.099;DP=46;ExcessHet=3.0103;FS=1.113;MLEAC=1;MLEAF=0.500;MQ=60.00;MQRankSum=0.000;QD=13.95;ReadPosRankSum=1.374;SOR=0.892\tGT:AD:DP:GQ:PL\t0/1:26,20:46:99:649,0,844\r\n",
      "5\t100514\t.\tA\tG\t1268.03\t.\tAC=2;AF=1.00;AN=2;DP=33;ExcessHet=3.0103;FS=0.000;MLEAC=2;MLEAF=1.00;MQ=60.00;QD=25.36;SOR=1.179\tGT:AD:DP:GQ:PL\t1/1:0,33:33:99:1282,99,0\r\n",
      "5\t101444\t.\tT\tTTTTA\t396.64\t.\tAC=1;AF=0.500;AN=2;BaseQRankSum=1.929;DP=38;ExcessHet=3.0103;FS=0.000;MLEAC=1;MLEAF=0.500;MQ=60.00;MQRankSum=0.000;QD=13.22;ReadPosRankSum=-2.154;SOR=0.569\tGT:AD:DP:GQ:PL\t0/1:19,11:30:99:404,0,942\r\n",
      "5\t101497\t.\tC\tT\t531.60\t.\tAC=1;AF=0.500;AN=2;BaseQRankSum=1.501;DP=42;ExcessHet=3.0103;FS=1.242;MLEAC=1;MLEAF=0.500;MQ=60.00;MQRankSum=0.000;QD=12.66;ReadPosRankSum=0.454;SOR=0.839\tGT:AD:DP:GQ:PL\t0/1:26,16:42:99:539,0,828\r\n",
      "5\t101748\t.\tT\tC\t1248.03\t.\tAC=2;AF=1.00;AN=2;DP=31;ExcessHet=3.0103;FS=0.000;MLEAC=2;MLEAF=1.00;MQ=60.00;QD=28.73;SOR=0.756\tGT:AD:DP:GQ:PL\t1/1:0,31:31:93:1262,93,0\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "# take a peek at the final output files\n",
    "!for i in called/Patient*vcf; do echo $i; grep -A5 \"^#CHROM\" $i; echo \"\"; done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "called/PatientA.vcf:2284\r\n",
      "called/PatientB.vcf:2173\r\n"
     ]
    }
   ],
   "source": [
    "# how many variants were called for each patient?\n",
    "!grep -cv \"^#\" called/*vcf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
