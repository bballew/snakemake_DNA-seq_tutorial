{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First things first, let's check our working directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/jovyan/Genomics_practice'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# wget https://github.com/broadinstitute/gatk/releases/download/4.1.1.0/gatk-4.1.1.0.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To build our pipeline, we'll need to make sure we have access to some dependencies first.  All of these are included in the environment.yaml file used to build the binder container, but you can use conda to install them if you're working outside of the binder container (`conda install -c bioconda <tool=version>`).  Let's check the versions of the dependencies to ensure they're there and accessible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "snakemake:  5.4.5\n",
      "samtools:   samtools 1.9\n",
      "bwa:        Version: 0.7.17-r1188\n",
      "python:     \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Python 3.6.8 :: Anaconda, Inc.\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "echo -e \"snakemake:  $(snakemake --version)\"\n",
    "echo -e \"samtools:   $(samtools --version | head -n1)\"\n",
    "echo -e \"bwa:        $(bwa |& grep Version)\"\n",
    "echo -e \"gatk:       $(gatk --version)\"\n",
    "echo -e \"python:     $(python3 --version)\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're going to start with FASTQ files from real human samples, but instead of whole genome data, we're focusing on chromosome 5, position 100000000-101500000.  Our reference genome file also only includes a portion of chr5.  This is to keep file sizes small and run times short!  Now, let's make sure we can see the raw files we intend to work on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 284M\n",
      "-rw-r--r-- 1 jovyan jovyan 66M Apr 17 16:44 Patient_A.r1.fastq\n",
      "-rw-r--r-- 1 jovyan jovyan 66M Apr 17 16:44 Patient_A.r2.fastq\n",
      "-rw-r--r-- 1 jovyan jovyan 77M Apr 17 16:44 Patient_B.r1.fastq\n",
      "-rw-r--r-- 1 jovyan jovyan 77M Apr 17 16:44 Patient_B.r2.fastq\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "ls -lh raw_data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@E00572:97:H5YN2CCXY:5:1101:1773:44327/1\n",
      "GATGGAGATGAGGAACTTGATGGAAACTGGAGCAAACGTGACTCTTGTTATGCTTTAGCAAAAATACCGGCAGGATTTTGTCCCTGCCCTAGAGATCTGTGGAATTTTGAACTTGAGAGAGAGGATTTAGAGCATCTGCCCCAAGAAAAT\n",
      "+\n",
      "<AAFF<JFFFFJJFJJJJ<JJJJFJJJJF-FJJ7FJFFJJJJJFJJJJJJJFJJJJJJ77FFFJJFFFJ<JFFF7-FFJJJFJJJFFFJJJ-7--<<FJJJJ--AA<-<7<F<7F--7A77J-7A-FF-<<A--7F<F--)-)))----7\n",
      "@E00572:97:H5YN2CCXY:5:1101:1803:49127/1\n",
      "GCCAAGGGAACCCCCAGCCCTACCCAGGGAAACCGGGAGTGATTGTGTAACTCCAGGAAACCATGCTTCTACCATGGATCTTTGCAACCCATGGATCAGGAGATCCCCCTGTGAGCTCATGCCACCAGGACCTTGGGTCTGACACACAGC\n",
      "+\n",
      "AAAAFJJJF<FJ-FJAFFJJJA<FFJAFFFFFFJJFAAJJJJJJFJJJFJJFJJJFJFJJJJJJJJJJJJJJJJJJFFJJJJJFA<7JFAAFJJ-AF7FFFJ-FF-F-AF<J77-A-7F-7FF-AA<JA<A-<<A)-AAF<F<FF--A7)\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "# what does a fastq look like?\n",
    "head -n8 raw_data/Patient_A.r1.fastq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 4.1M\n",
      "-rw-r--r-- 1 jovyan jovyan 4.1M Apr 17 16:44 chr5_ref.fasta\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "ls -lh ref_genome/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">5:99900000-104100000\n",
      "AATAGGAAATCAAAGGGAATTTTAAGAGCTATTTTGAGACAAAAAAAAAATGGCATAACA\n",
      "AAACTTATGGGATGCAGCAAAAGCATTGCTAGGAGAGAAGTTTATAGCAATAAATGCTTA\n",
      "TGCTATGAAAGAAGAAAGACTTCAAATAAACAACCTAGCTTTACCCTTTCAGAAAGTGGC\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "# what does a reference genome look like?\n",
    "head -n4 ref_genome/chr5_ref.fasta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Goal:__ assemble a working DNA-seq pipeline!\n",
    "\n",
    "- Align sequencing data to a reference genome\n",
    "- Call variants in the aligned data\n",
    "- Annotate variants"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First rule: indexing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our first rule is going to take our reference genome file, and index it so that the alignment tool can read it.  We can write the rule in any text editor, but for this class, we'll write it here in the notebook and save it to a file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting snakefile_test1\n"
     ]
    }
   ],
   "source": [
    "%%writefile snakefile_test1\n",
    "\n",
    "ref = 'ref_genome/chr5_ref.fasta'\n",
    "\n",
    "rule index_ref:\n",
    "    '''\n",
    "    This rule creates the indices needed by\n",
    "    bwa in order to use a reference fasta.\n",
    "    '''\n",
    "    input:\n",
    "        ref\n",
    "    output:\n",
    "        ref + '.amb',\n",
    "        ref + '.ann',\n",
    "        ref + '.bwt',\n",
    "        ref + '.pac',\n",
    "        ref + '.sa'\n",
    "    shell:\n",
    "        'bwa index {input}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test our first rule!  You can run this rule from the command line or here in the notebook using cell magic.  For our first test, we're going to try a __dry-run__ by using the `-n` flag.  If your snakefile is called something other than \"Snakefile,\" use `-s <filename>`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building DAG of jobs...\n",
      "Job counts:\n",
      "\tcount\tjobs\n",
      "\t1\tindex_ref\n",
      "\t1\n",
      "\n",
      "[Wed Apr 17 18:26:17 2019]\n",
      "rule index_ref:\n",
      "    input: ref_genome/chr5_ref.fasta\n",
      "    output: ref_genome/chr5_ref.fasta.amb, ref_genome/chr5_ref.fasta.ann, ref_genome/chr5_ref.fasta.bwt, ref_genome/chr5_ref.fasta.pac, ref_genome/chr5_ref.fasta.sa\n",
      "    jobid: 0\n",
      "\n",
      "Job counts:\n",
      "\tcount\tjobs\n",
      "\t1\tindex_ref\n",
      "\t1\n",
      "This was a dry-run (flag -n). The order of jobs does not reflect the order of execution.\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "snakemake -ns snakefile_test1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks great!  Note that the dry-run does not actually execute any jobs; it shows the execution plan.  \n",
    "\n",
    "Now let's try running our pipeline for real.  Add the `-p` flag to print the job that's run for each rule."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building DAG of jobs...\n",
      "Using shell: /bin/bash\n",
      "Provided cores: 1\n",
      "Rules claiming more threads will be scaled down.\n",
      "Job counts:\n",
      "\tcount\tjobs\n",
      "\t1\tindex_ref\n",
      "\t1\n",
      "\n",
      "[Wed Apr 17 18:29:38 2019]\n",
      "rule index_ref:\n",
      "    input: ref_genome/chr5_ref.fasta\n",
      "    output: ref_genome/chr5_ref.fasta.amb, ref_genome/chr5_ref.fasta.ann, ref_genome/chr5_ref.fasta.bwt, ref_genome/chr5_ref.fasta.pac, ref_genome/chr5_ref.fasta.sa\n",
      "    jobid: 0\n",
      "\n",
      "bwa index ref_genome/chr5_ref.fasta\n",
      "[bwa_index] Pack FASTA... 0.07 sec\n",
      "[bwa_index] Construct BWT for the packed sequence...\n",
      "[bwa_index] 1.74 seconds elapse.\n",
      "[bwa_index] Update BWT... 0.05 sec\n",
      "[bwa_index] Pack forward-only FASTA... 0.04 sec\n",
      "[bwa_index] Construct SA from BWT and Occ... 0.56 sec\n",
      "[main] Version: 0.7.17-r1188\n",
      "[main] CMD: bwa index ref_genome/chr5_ref.fasta\n",
      "[main] Real time: 2.515 sec; CPU: 2.460 sec\n",
      "[Wed Apr 17 18:29:40 2019]\n",
      "Finished job 0.\n",
      "1 of 1 steps (100%) done\n",
      "Complete log: /home/jovyan/Genomics_practice/.snakemake/log/2019-04-17T182938.288375.snakemake.log\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "snakemake -ps snakefile_test1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hooray!!  Our first rule worked.  Note that Snakemake stdout provides a beautiful log of steps run and errors encountered.\n",
    "\n",
    "What happens if we try to run it again?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building DAG of jobs...\n",
      "Nothing to be done.\n",
      "Complete log: /home/jovyan/Genomics_practice/.snakemake/log/2019-04-17T183110.819471.snakemake.log\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "snakemake -ps snakefile_test1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Second rule: aligning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# include trimming?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our next rule is going to take the short reads in our FASTQ files, and align them to a reference sequence using a tool called [__bwa__](https://github.com/lh3/bwa).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-13-661d7e937908>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-13-661d7e937908>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    rule align_fastqs:\u001b[0m\n\u001b[0m                    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "rule align_fastqs: \n",
    "    input:\n",
    "        ref = ref,\n",
    "        r1 = ref + '.amb',\n",
    "        r2 = ref + '.ann',\n",
    "        r3 = ref + '.bwt',\n",
    "        r4 = ref + '.pac',\n",
    "        r5 = ref + '.sa',\n",
    "        fq1 = 'raw_data/Patient_A.r1.fastq',\n",
    "        fq2 = 'raw_data/Patient_A.r2.fastq'\n",
    "    output:\n",
    "        'aligned/PatientA.bam'\n",
    "    shell:\n",
    "        'bwa mem {input.ref} {input.fq1} {input.fq2} | samtools sort -o {output}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note how not all the listed input files are actually needed in the command line, but they are required for the command to run successfully.  Snakemake recommends that you include all file dependencies in the input section, even if they're not used in the command invocation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hold up.  We don't want to hard-code our sample files into a pipeline, or else we have to change code for every sample! How do we handle this?\n",
    "\n",
    "![xkcd](images/xkcd_generalization.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLES = ['Patient_A.r1', 'Patient_A.r2', 'Patient_B.r1', 'Patient_B.r2',]\n",
    "\n",
    "rule align_fastqs: \n",
    "    input:\n",
    "        ref = ref,\n",
    "        r1 = ref + '.amb',\n",
    "        r2 = ref + '.ann',\n",
    "        r3 = ref + '.bwt',\n",
    "        r4 = ref + '.pac',\n",
    "        r5 = ref + '.sa',\n",
    "        fq = 'raw_data/{sample}.fastq'\n",
    "    output:\n",
    "        'aligned/{sample}.bam'\n",
    "    shell:\n",
    "        'bwa mem {input.ref} {input.fq} | samtools sort -o {output}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What if we use a list, as above?  This would run an alignment on each fastq individually, which would be fine if we had single-end reads.  But, we have paired-end reads, which means you've sequenced in both directions, and you need to align two related fastq files per sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appending to snakefile_test1\n"
     ]
    }
   ],
   "source": [
    "rawDataPath = 'raw_data/'\n",
    "sampleDict = {\n",
    "    'PatientA':['Patient_A.r1.fastq', 'Patient_A.r2.fastq'],\n",
    "    'PatientB':['Patient_B.r1.fastq', 'Patient_B.r2.fastq']\n",
    "}\n",
    "\n",
    "def get_read1_fastq(wildcards):\n",
    "    (read1, read2) = sampleDict[wildcards.sample]\n",
    "    return rawDataPath + read1\n",
    "\n",
    "def get_read2_fastq(wildcards):\n",
    "    (read1, read2) = sampleDict[wildcards.sample]\n",
    "    return rawDataPath + read2\n",
    "\n",
    "rule align_fastqs: \n",
    "    input:\n",
    "        ref = ref,\n",
    "        r1 = ref + '.amb',\n",
    "        r2 = ref + '.ann',\n",
    "        r3 = ref + '.bwt',\n",
    "        r4 = ref + '.pac',\n",
    "        r5 = ref + '.sa',\n",
    "        fq1 = get_read1_fastq,\n",
    "        fq2 = get_read2_fastq\n",
    "    output:\n",
    "        'aligned/{sample}.bam'\n",
    "    shell:\n",
    "        'bwa mem {input.ref} {input.fq1} {input.fq2} | samtools sort -o {output}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What if we use a dict?  Much better!  Now our `rule align_fastqs` is generalizable.  If you were using this pipeline in real life, you'd probably require the user to provide a sample file where each line has the sample name, fastq1, and fastq2, and you'd read that in to a dict (rather than explicitly defining a dict like we did).\n",
    "\n",
    "Note that input (or params) can be the return value of a function, as in this example.\n",
    "\n",
    "Let's put the two rules together, and then try running them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing snakefile_test2\n"
     ]
    }
   ],
   "source": [
    "%%writefile snakefile_test2\n",
    "\n",
    "ref = 'ref_genome/chr5_ref.fasta'\n",
    "rawDataPath = 'raw_data/'\n",
    "sampleDict = {\n",
    "    'PatientA':['Patient_A.r1.fastq', 'Patient_A.r2.fastq'],\n",
    "    'PatientB':['Patient_B.r1.fastq', 'Patient_B.r2.fastq']\n",
    "}\n",
    "\n",
    "def get_read1_fastq(wildcards):\n",
    "    (read1, read2) = sampleDict[wildcards.sample]\n",
    "    return rawDataPath + read1\n",
    "\n",
    "def get_read2_fastq(wildcards):\n",
    "    (read1, read2) = sampleDict[wildcards.sample]\n",
    "    return rawDataPath + read2\n",
    "\n",
    "\n",
    "rule index_ref:\n",
    "    '''\n",
    "    This rule creates the indices needed by\n",
    "    bwa in order to use a reference fasta.\n",
    "    '''\n",
    "    input:\n",
    "        ref\n",
    "    output:\n",
    "        ref + '.amb',\n",
    "        ref + '.ann',\n",
    "        ref + '.bwt',\n",
    "        ref + '.pac',\n",
    "        ref + '.sa'\n",
    "    shell:\n",
    "        'bwa index {input}'\n",
    "\n",
    "rule align_fastqs: \n",
    "    input:\n",
    "        ref = ref,\n",
    "        r1 = ref + '.amb',\n",
    "        r2 = ref + '.ann',\n",
    "        r3 = ref + '.bwt',\n",
    "        r4 = ref + '.pac',\n",
    "        r5 = ref + '.sa',\n",
    "        fq1 = get_read1_fastq,\n",
    "        fq2 = get_read2_fastq\n",
    "    output:\n",
    "        'aligned/{sample}.bam'\n",
    "    shell:\n",
    "        'bwa mem {input.ref} {input.fq1} {input.fq2} | samtools sort -o {output}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building DAG of jobs...\n",
      "Nothing to be done.\n",
      "Complete log: /home/jovyan/Genomics_practice/.snakemake/log/2019-04-17T192800.221988.snakemake.log\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "snakemake -ps snakefile_test2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oh no!  What went wrong?  We haven't given snakemake a target file.  Let's add a `rule all`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting snakefile_test3\n"
     ]
    }
   ],
   "source": [
    "%%writefile snakefile_test3\n",
    "\n",
    "ref = 'ref_genome/chr5_ref.fasta'\n",
    "rawDataPath = 'raw_data/'\n",
    "sampleDict = {\n",
    "    'PatientA':['Patient_A.r1.fastq', 'Patient_A.r2.fastq'],\n",
    "    'PatientB':['Patient_B.r1.fastq', 'Patient_B.r2.fastq']\n",
    "}\n",
    "\n",
    "def get_read1_fastq(wildcards):\n",
    "    (read1, read2) = sampleDict[wildcards.sample]\n",
    "    return rawDataPath + read1\n",
    "\n",
    "def get_read2_fastq(wildcards):\n",
    "    (read1, read2) = sampleDict[wildcards.sample]\n",
    "    return rawDataPath + read2\n",
    "\n",
    "\n",
    "rule all:\n",
    "    input:\n",
    "        expand('aligned/{sample}.bam', sample=sampleDict.keys())\n",
    "\n",
    "rule index_ref:\n",
    "    '''\n",
    "    This rule creates the indices needed by\n",
    "    bwa in order to use a reference fasta.\n",
    "    '''\n",
    "    input:\n",
    "        ref\n",
    "    output:\n",
    "        ref + '.amb',\n",
    "        ref + '.ann',\n",
    "        ref + '.bwt',\n",
    "        ref + '.pac',\n",
    "        ref + '.sa'\n",
    "    shell:\n",
    "        'bwa index {input}'\n",
    "\n",
    "rule align_fastqs: \n",
    "    input:\n",
    "        ref = ref,\n",
    "        r1 = ref + '.amb',\n",
    "        r2 = ref + '.ann',\n",
    "        r3 = ref + '.bwt',\n",
    "        r4 = ref + '.pac',\n",
    "        r5 = ref + '.sa',\n",
    "        fq1 = get_read1_fastq,\n",
    "        fq2 = get_read2_fastq\n",
    "    output:\n",
    "        'aligned/{sample}.bam'\n",
    "    shell:\n",
    "        'bwa mem {input.ref} {input.fq1} {input.fq2} | samtools sort -o {output}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now snakemake knows that {sample} should expand to PatientA and PatientB, and that the pipeline should end up producing the files `'aligned/{sample}.bam'`.  Let's try running it (this will take a minute or two):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building DAG of jobs...\n",
      "Using shell: /bin/bash\n",
      "Provided cores: 1\n",
      "Rules claiming more threads will be scaled down.\n",
      "Job counts:\n",
      "\tcount\tjobs\n",
      "\t2\talign_fastqs\n",
      "\t1\tall\n",
      "\t3\n",
      "\n",
      "[Wed Apr 17 19:31:18 2019]\n",
      "rule align_fastqs:\n",
      "    input: ref_genome/chr5_ref.fasta, ref_genome/chr5_ref.fasta.amb, ref_genome/chr5_ref.fasta.ann, ref_genome/chr5_ref.fasta.bwt, ref_genome/chr5_ref.fasta.pac, ref_genome/chr5_ref.fasta.sa, raw_data/Patient_B.r1.fastq, raw_data/Patient_B.r2.fastq\n",
      "    output: aligned/PatientB.bam\n",
      "    jobid: 2\n",
      "    wildcards: sample=PatientB\n",
      "\n",
      "bwa mem ref_genome/chr5_ref.fasta raw_data/Patient_B.r1.fastq raw_data/Patient_B.r2.fastq | samtools sort -o aligned/PatientB.bam\n",
      "[M::bwa_idx_load_from_disk] read 0 ALT contigs\n",
      "[M::process] read 66674 sequences (10000123 bp)...\n",
      "[M::process] read 66674 sequences (10000097 bp)...\n",
      "[M::mem_pestat] # candidate unique pairs for (FF, FR, RF, RR): (2, 31731, 0, 2)\n",
      "[M::mem_pestat] skip orientation FF as there are not enough pairs\n",
      "[M::mem_pestat] analyzing insert size distribution for orientation FR...\n",
      "[M::mem_pestat] (25, 50, 75) percentile: (244, 278, 314)\n",
      "[M::mem_pestat] low and high boundaries for computing mean and std.dev: (104, 454)\n",
      "[M::mem_pestat] mean and std.dev: (280.89, 52.60)\n",
      "[M::mem_pestat] low and high boundaries for proper pairs: (34, 524)\n",
      "[M::mem_pestat] skip orientation RF as there are not enough pairs\n",
      "[M::mem_pestat] skip orientation RR as there are not enough pairs\n",
      "[M::mem_process_seqs] Processed 66674 reads in 6.331 CPU sec, 7.000 real sec\n",
      "[M::process] read 66672 sequences (10000078 bp)...\n",
      "[M::mem_pestat] # candidate unique pairs for (FF, FR, RF, RR): (3, 31745, 0, 0)\n",
      "[M::mem_pestat] skip orientation FF as there are not enough pairs\n",
      "[M::mem_pestat] analyzing insert size distribution for orientation FR...\n",
      "[M::mem_pestat] (25, 50, 75) percentile: (243, 277, 314)\n",
      "[M::mem_pestat] low and high boundaries for computing mean and std.dev: (101, 456)\n",
      "[M::mem_pestat] mean and std.dev: (279.38, 52.50)\n",
      "[M::mem_pestat] low and high boundaries for proper pairs: (30, 527)\n",
      "[M::mem_pestat] skip orientation RF as there are not enough pairs\n",
      "[M::mem_pestat] skip orientation RR as there are not enough pairs\n",
      "[M::mem_process_seqs] Processed 66674 reads in 6.071 CPU sec, 6.524 real sec\n",
      "[M::process] read 66670 sequences (10000020 bp)...\n",
      "[M::mem_pestat] # candidate unique pairs for (FF, FR, RF, RR): (2, 31650, 0, 1)\n",
      "[M::mem_pestat] skip orientation FF as there are not enough pairs\n",
      "[M::mem_pestat] analyzing insert size distribution for orientation FR...\n",
      "[M::mem_pestat] (25, 50, 75) percentile: (242, 276, 312)\n",
      "[M::mem_pestat] low and high boundaries for computing mean and std.dev: (102, 452)\n",
      "[M::mem_pestat] mean and std.dev: (278.34, 52.21)\n",
      "[M::mem_pestat] low and high boundaries for proper pairs: (32, 522)\n",
      "[M::mem_pestat] skip orientation RF as there are not enough pairs\n",
      "[M::mem_pestat] skip orientation RR as there are not enough pairs\n",
      "[M::mem_process_seqs] Processed 66672 reads in 6.418 CPU sec, 6.645 real sec\n",
      "[M::process] read 66676 sequences (10000036 bp)...\n",
      "[M::mem_pestat] # candidate unique pairs for (FF, FR, RF, RR): (1, 31707, 0, 0)\n",
      "[M::mem_pestat] skip orientation FF as there are not enough pairs\n",
      "[M::mem_pestat] analyzing insert size distribution for orientation FR...\n",
      "[M::mem_pestat] (25, 50, 75) percentile: (243, 277, 313)\n",
      "[M::mem_pestat] low and high boundaries for computing mean and std.dev: (103, 453)\n",
      "[M::mem_pestat] mean and std.dev: (279.15, 52.39)\n",
      "[M::mem_pestat] low and high boundaries for proper pairs: (33, 523)\n",
      "[M::mem_pestat] skip orientation RF as there are not enough pairs\n",
      "[M::mem_pestat] skip orientation RR as there are not enough pairs\n",
      "[M::mem_process_seqs] Processed 66670 reads in 6.143 CPU sec, 6.567 real sec\n",
      "[M::process] read 66672 sequences (10000088 bp)...\n",
      "[M::mem_pestat] # candidate unique pairs for (FF, FR, RF, RR): (3, 31707, 0, 1)\n",
      "[M::mem_pestat] skip orientation FF as there are not enough pairs\n",
      "[M::mem_pestat] analyzing insert size distribution for orientation FR...\n",
      "[M::mem_pestat] (25, 50, 75) percentile: (243, 276, 313)\n",
      "[M::mem_pestat] low and high boundaries for computing mean and std.dev: (103, 453)\n",
      "[M::mem_pestat] mean and std.dev: (278.80, 52.64)\n",
      "[M::mem_pestat] low and high boundaries for proper pairs: (33, 523)\n",
      "[M::mem_pestat] skip orientation RF as there are not enough pairs\n",
      "[M::mem_pestat] skip orientation RR as there are not enough pairs\n",
      "[M::mem_process_seqs] Processed 66676 reads in 6.061 CPU sec, 6.442 real sec\n",
      "[M::process] read 58410 sequences (8760675 bp)...\n",
      "[M::mem_pestat] # candidate unique pairs for (FF, FR, RF, RR): (0, 31749, 0, 0)\n",
      "[M::mem_pestat] skip orientation FF as there are not enough pairs\n",
      "[M::mem_pestat] analyzing insert size distribution for orientation FR...\n",
      "[M::mem_pestat] (25, 50, 75) percentile: (244, 278, 315)\n",
      "[M::mem_pestat] low and high boundaries for computing mean and std.dev: (102, 457)\n",
      "[M::mem_pestat] mean and std.dev: (280.56, 52.72)\n",
      "[M::mem_pestat] low and high boundaries for proper pairs: (31, 528)\n",
      "[M::mem_pestat] skip orientation RF as there are not enough pairs\n",
      "[M::mem_pestat] skip orientation RR as there are not enough pairs\n",
      "[M::mem_process_seqs] Processed 66672 reads in 5.907 CPU sec, 6.122 real sec\n",
      "[M::mem_pestat] # candidate unique pairs for (FF, FR, RF, RR): (2, 27840, 0, 0)\n",
      "[M::mem_pestat] skip orientation FF as there are not enough pairs\n",
      "[M::mem_pestat] analyzing insert size distribution for orientation FR...\n",
      "[M::mem_pestat] (25, 50, 75) percentile: (245, 279, 317)\n",
      "[M::mem_pestat] low and high boundaries for computing mean and std.dev: (101, 461)\n",
      "[M::mem_pestat] mean and std.dev: (282.17, 53.74)\n",
      "[M::mem_pestat] low and high boundaries for proper pairs: (29, 533)\n",
      "[M::mem_pestat] skip orientation RF as there are not enough pairs\n",
      "[M::mem_pestat] skip orientation RR as there are not enough pairs\n",
      "[M::mem_process_seqs] Processed 58410 reads in 5.234 CPU sec, 5.600 real sec\n",
      "[main] Version: 0.7.17-r1188\n",
      "[main] CMD: bwa mem ref_genome/chr5_ref.fasta raw_data/Patient_B.r1.fastq raw_data/Patient_B.r2.fastq\n",
      "[main] Real time: 45.530 sec; CPU: 42.556 sec\n",
      "[Wed Apr 17 19:32:07 2019]\n",
      "Finished job 2.\n",
      "1 of 3 steps (33%) done\n",
      "\n",
      "[Wed Apr 17 19:32:07 2019]\n",
      "rule align_fastqs:\n",
      "    input: ref_genome/chr5_ref.fasta, ref_genome/chr5_ref.fasta.amb, ref_genome/chr5_ref.fasta.ann, ref_genome/chr5_ref.fasta.bwt, ref_genome/chr5_ref.fasta.pac, ref_genome/chr5_ref.fasta.sa, raw_data/Patient_A.r1.fastq, raw_data/Patient_A.r2.fastq\n",
      "    output: aligned/PatientA.bam\n",
      "    jobid: 1\n",
      "    wildcards: sample=PatientA\n",
      "\n",
      "bwa mem ref_genome/chr5_ref.fasta raw_data/Patient_A.r1.fastq raw_data/Patient_A.r2.fastq | samtools sort -o aligned/PatientA.bam\n",
      "[M::bwa_idx_load_from_disk] read 0 ALT contigs\n",
      "[M::process] read 66678 sequences (10000219 bp)...\n",
      "[M::process] read 66674 sequences (10000016 bp)...\n",
      "[M::mem_pestat] # candidate unique pairs for (FF, FR, RF, RR): (4, 31683, 0, 0)\n",
      "[M::mem_pestat] skip orientation FF as there are not enough pairs\n",
      "[M::mem_pestat] analyzing insert size distribution for orientation FR...\n",
      "[M::mem_pestat] (25, 50, 75) percentile: (251, 285, 323)\n",
      "[M::mem_pestat] low and high boundaries for computing mean and std.dev: (107, 467)\n",
      "[M::mem_pestat] mean and std.dev: (287.82, 54.32)\n",
      "[M::mem_pestat] low and high boundaries for proper pairs: (35, 539)\n",
      "[M::mem_pestat] skip orientation RF as there are not enough pairs\n",
      "[M::mem_pestat] skip orientation RR as there are not enough pairs\n",
      "[M::mem_process_seqs] Processed 66678 reads in 6.888 CPU sec, 7.056 real sec\n",
      "[M::process] read 66674 sequences (10000261 bp)...\n",
      "[M::mem_pestat] # candidate unique pairs for (FF, FR, RF, RR): (1, 31690, 0, 1)\n",
      "[M::mem_pestat] skip orientation FF as there are not enough pairs\n",
      "[M::mem_pestat] analyzing insert size distribution for orientation FR...\n",
      "[M::mem_pestat] (25, 50, 75) percentile: (250, 285, 322)\n",
      "[M::mem_pestat] low and high boundaries for computing mean and std.dev: (106, 466)\n",
      "[M::mem_pestat] mean and std.dev: (287.19, 54.24)\n",
      "[M::mem_pestat] low and high boundaries for proper pairs: (34, 538)\n",
      "[M::mem_pestat] skip orientation RF as there are not enough pairs\n",
      "[M::mem_pestat] skip orientation RR as there are not enough pairs\n",
      "[M::mem_process_seqs] Processed 66674 reads in 6.245 CPU sec, 6.808 real sec\n",
      "[M::process] read 66676 sequences (10000211 bp)...\n",
      "[M::mem_pestat] # candidate unique pairs for (FF, FR, RF, RR): (1, 31694, 0, 0)\n",
      "[M::mem_pestat] skip orientation FF as there are not enough pairs\n",
      "[M::mem_pestat] analyzing insert size distribution for orientation FR...\n",
      "[M::mem_pestat] (25, 50, 75) percentile: (249, 283, 320)\n",
      "[M::mem_pestat] low and high boundaries for computing mean and std.dev: (107, 462)\n",
      "[M::mem_pestat] mean and std.dev: (285.44, 53.83)\n",
      "[M::mem_pestat] low and high boundaries for proper pairs: (36, 533)\n",
      "[M::mem_pestat] skip orientation RF as there are not enough pairs\n",
      "[M::mem_pestat] skip orientation RR as there are not enough pairs\n",
      "[M::mem_process_seqs] Processed 66674 reads in 6.515 CPU sec, 6.913 real sec\n",
      "[M::process] read 66676 sequences (10000065 bp)...\n",
      "[M::mem_pestat] # candidate unique pairs for (FF, FR, RF, RR): (3, 31685, 0, 0)\n",
      "[M::mem_pestat] skip orientation FF as there are not enough pairs\n",
      "[M::mem_pestat] analyzing insert size distribution for orientation FR...\n",
      "[M::mem_pestat] (25, 50, 75) percentile: (249, 283, 320)\n",
      "[M::mem_pestat] low and high boundaries for computing mean and std.dev: (107, 462)\n",
      "[M::mem_pestat] mean and std.dev: (285.40, 53.25)\n",
      "[M::mem_pestat] low and high boundaries for proper pairs: (36, 533)\n",
      "[M::mem_pestat] skip orientation RF as there are not enough pairs\n",
      "[M::mem_pestat] skip orientation RR as there are not enough pairs\n",
      "[M::mem_process_seqs] Processed 66676 reads in 6.200 CPU sec, 6.745 real sec\n",
      "[M::process] read 61730 sequences (9258761 bp)...\n",
      "[M::mem_pestat] # candidate unique pairs for (FF, FR, RF, RR): (4, 31643, 0, 0)\n",
      "[M::mem_pestat] skip orientation FF as there are not enough pairs\n",
      "[M::mem_pestat] analyzing insert size distribution for orientation FR...\n",
      "[M::mem_pestat] (25, 50, 75) percentile: (249, 283, 320)\n",
      "[M::mem_pestat] low and high boundaries for computing mean and std.dev: (107, 462)\n",
      "[M::mem_pestat] mean and std.dev: (286.05, 54.10)\n",
      "[M::mem_pestat] low and high boundaries for proper pairs: (36, 533)\n",
      "[M::mem_pestat] skip orientation RF as there are not enough pairs\n",
      "[M::mem_pestat] skip orientation RR as there are not enough pairs\n",
      "[M::mem_process_seqs] Processed 66676 reads in 6.426 CPU sec, 6.777 real sec\n",
      "[M::mem_pestat] # candidate unique pairs for (FF, FR, RF, RR): (2, 29382, 0, 0)\n",
      "[M::mem_pestat] skip orientation FF as there are not enough pairs\n",
      "[M::mem_pestat] analyzing insert size distribution for orientation FR...\n",
      "[M::mem_pestat] (25, 50, 75) percentile: (250, 284, 322)\n",
      "[M::mem_pestat] low and high boundaries for computing mean and std.dev: (106, 466)\n",
      "[M::mem_pestat] mean and std.dev: (286.64, 53.74)\n",
      "[M::mem_pestat] low and high boundaries for proper pairs: (34, 538)\n",
      "[M::mem_pestat] skip orientation RF as there are not enough pairs\n",
      "[M::mem_pestat] skip orientation RR as there are not enough pairs\n",
      "[M::mem_process_seqs] Processed 61730 reads in 5.633 CPU sec, 6.011 real sec\n",
      "[main] Version: 0.7.17-r1188\n",
      "[main] CMD: bwa mem ref_genome/chr5_ref.fasta raw_data/Patient_A.r1.fastq raw_data/Patient_A.r2.fastq\n",
      "[main] Real time: 40.912 sec; CPU: 38.283 sec\n",
      "[Wed Apr 17 19:32:50 2019]\n",
      "Finished job 1.\n",
      "2 of 3 steps (67%) done\n",
      "\n",
      "[Wed Apr 17 19:32:50 2019]\n",
      "localrule all:\n",
      "    input: aligned/PatientA.bam, aligned/PatientB.bam\n",
      "    jobid: 0\n",
      "\n",
      "[Wed Apr 17 19:32:50 2019]\n",
      "Finished job 0.\n",
      "3 of 3 steps (100%) done\n",
      "Complete log: /home/jovyan/Genomics_practice/.snakemake/log/2019-04-17T193118.925969.snakemake.log\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "snakemake -ps snakefile_test3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yay!  A few things of note:\n",
    "- We now have one aligned bam file per patient!\n",
    "- Snakemake automatically created the directory `aligned/` for us.\n",
    "- The stdout also includes a bunch of information from bwa.  There are ways to clean this up, but we're going to skip over that for now.\n",
    "- Snakemake saw that the indexed reference files were already created, so it did not re-run that rule."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Third rule: calling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This third rule will compare our aligned sequences to the reference genome, look at places where there's a discrepancy, and report back those variants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rule call_variants:\n",
    "    input:\n",
    "        ref = ,\n",
    "        bam = \n",
    "    output:\n",
    "    shell:\n",
    "        'gatk HaplotypeCaller -I:{input.bam} -O:{output} -R:{input.ref}'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
