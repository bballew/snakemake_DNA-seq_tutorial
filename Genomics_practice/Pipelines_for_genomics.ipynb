{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First things first, let's check our working directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pwd  # some bash commands will work without additional characters in Jupyter notebooks if automagic is on"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To build our pipeline, we'll need to make sure we have access to some dependencies first.  All of these are included in the environment.yaml file used to build the binder container, but you can use conda to install them if you're working outside of the binder container (`conda install -c bioconda <tool=version>`).  Let's check the versions of the dependencies to ensure they're there and accessible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash  # to run a whole cell in bash\n",
    "echo -e \"snakemake:  $(snakemake --version)\"\n",
    "echo -e \"samtools:   $(samtools --version | head -n1)\"\n",
    "echo -e \"picard:     $(picard --version)\"\n",
    "echo -e \"bwa:        $(bwa |& grep Version)\"\n",
    "echo -e \"gatk:       $(gatk --version |& grep 'The Genome Analysis Toolkit')\"\n",
    "echo -e \"python:     $(python3 --version |& grep Python)\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're going to start with FASTQ files from real human samples, but instead of whole genome data, we're focusing on chromosome 5, position 100000000-101500000.  Our reference genome file also only includes a portion of chr5.  This is to keep file sizes small and run times short!  Now, let's make sure we can see the raw files we intend to work on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls -lh raw_data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what does a fastq look like?\n",
    "!head -n8 raw_data/Patient_A.r1.fastq  # to run a single line of bash, prepend with \"!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls -lh ref_genome/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what does a reference genome look like?\n",
    "!head -n4 ref_genome/chr5_ref.fasta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Goal:__ assemble a working DNA-seq pipeline!\n",
    "\n",
    "- Align sequencing data to a reference genome\n",
    "- Call variants in the aligned data\n",
    "- Annotate variants"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First rule: indexing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our first rule is going to take our reference genome file, and index it so that the alignment tool can read it.  We can write the rule in any text editor, but for this class, we'll write it here in the notebook and save it to a file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile snakefile_test1\n",
    "\n",
    "ref = 'ref_genome/chr5_ref.fasta'\n",
    "tempRef = os.path.splitext(ref)[0]\n",
    "if ref.endswith(('.gz')):\n",
    "    refNoExt = os.path.splitext(tempRef)[0]\n",
    "else:\n",
    "    refNoExt = tempRef\n",
    "\n",
    "rule index_ref:\n",
    "    '''\n",
    "    This rule creates the indices needed by\n",
    "    bwa in order to use a reference fasta,\n",
    "    and by GATK to call variants.\n",
    "    '''\n",
    "    input:\n",
    "        ref\n",
    "    output:\n",
    "        o1 = ref + '.amb',\n",
    "        o2 = ref + '.ann',\n",
    "        o3 = ref + '.bwt',\n",
    "        o4 = ref + '.pac',\n",
    "        o5 = ref + '.sa',\n",
    "        o6 = ref + '.fai',\n",
    "        o7 = refNoExt + '.dict'\n",
    "    shell:\n",
    "        'bwa index {input};'\n",
    "        'samtools faidx {input};'\n",
    "        'picard CreateSequenceDictionary REFERENCE={input} OUTPUT={output.o7}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test our first rule!  You can run this rule from the command line or here in the notebook using cell magic.  For our first test, we're going to try a __dry-run__ by using the `-n` flag.  If your snakefile is called something other than \"Snakefile,\" use `-s <filename>`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!snakemake -ns snakefile_test1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks great!  Note that the dry-run does not actually execute any jobs; it shows the execution plan.  \n",
    "\n",
    "Now let's try running our pipeline for real.  Add the `-p` flag to print the job that's run for each rule."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!snakemake -ps snakefile_test1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hooray!!  Our first rule worked.  Note that Snakemake stdout provides a beautiful log of steps run and errors encountered.\n",
    "\n",
    "What happens if we try to run it again?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!snakemake -ps snakefile_test1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Second rule: alignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# include trimming?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our next rule is going to take the short reads in our FASTQ files, and align them to a reference sequence using a tool called [__bwa__](https://github.com/lh3/bwa).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rule align_fastqs: \n",
    "    input:\n",
    "        ref = ref,\n",
    "        r1 = ref + '.amb',\n",
    "        r2 = ref + '.ann',\n",
    "        r3 = ref + '.bwt',\n",
    "        r4 = ref + '.pac',\n",
    "        r5 = ref + '.sa',\n",
    "        fq1 = 'raw_data/Patient_A.r1.fastq',\n",
    "        fq2 = 'raw_data/Patient_A.r2.fastq'\n",
    "    output:\n",
    "        'aligned/PatientA.bam'\n",
    "    shell:\n",
    "        'bwa mem {input.ref} {input.fq1} {input.fq2} | samtools sort -o {output}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note how not all the listed input files are actually needed in the command line, but they are required for the command to run successfully (i.e. bwa will give an error if the index files are not there).  Snakemake recommends that you include all file dependencies in the input section, even if they're not used in the command invocation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hold up.  We don't want to hard-code our sample files into a pipeline, or else we have to change the code for every sample! How do we handle this?\n",
    "\n",
    "![xkcd](https://imgs.xkcd.com/comics/the_general_problem.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLES = ['Patient_A.r1', 'Patient_A.r2', 'Patient_B.r1', 'Patient_B.r2',]\n",
    "\n",
    "rule align_fastqs: \n",
    "    input:\n",
    "        ref = ref,\n",
    "        r1 = ref + '.amb',\n",
    "        r2 = ref + '.ann',\n",
    "        r3 = ref + '.bwt',\n",
    "        r4 = ref + '.pac',\n",
    "        r5 = ref + '.sa',\n",
    "        fq = 'raw_data/{sample}.fastq'\n",
    "    output:\n",
    "        'aligned/{sample}.bam'\n",
    "    shell:\n",
    "        'bwa mem {input.ref} {input.fq} | samtools sort -o {output}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What if we use a list, as above?  This would run an alignment on each fastq individually, which would be fine if we had single-end reads.  But, we have paired-end reads, which means you've sequenced in both directions, and you need to align two related fastq files per sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rawDataPath = 'raw_data/'\n",
    "sampleDict = {\n",
    "    'PatientA':['Patient_A.r1.fastq', 'Patient_A.r2.fastq'],\n",
    "    'PatientB':['Patient_B.r1.fastq', 'Patient_B.r2.fastq']\n",
    "}\n",
    "\n",
    "def get_read1_fastq(wildcards):\n",
    "    (read1, read2) = sampleDict[wildcards.sample]\n",
    "    return rawDataPath + read1\n",
    "\n",
    "def get_read2_fastq(wildcards):\n",
    "    (read1, read2) = sampleDict[wildcards.sample]\n",
    "    return rawDataPath + read2\n",
    "\n",
    "rule align_fastqs: \n",
    "    input:\n",
    "        ref = ref,\n",
    "        r1 = ref + '.amb',\n",
    "        r2 = ref + '.ann',\n",
    "        r3 = ref + '.bwt',\n",
    "        r4 = ref + '.pac',\n",
    "        r5 = ref + '.sa',\n",
    "        fq1 = get_read1_fastq,\n",
    "        fq2 = get_read2_fastq\n",
    "    output:\n",
    "        'aligned/{sample}.bam'\n",
    "    shell:\n",
    "        'bwa mem {input.ref} {input.fq1} {input.fq2} | samtools sort -o {output}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What if we use a dict?  Much better!  Now our `rule align_fastqs` is generalizable.  If you were using this pipeline in real life, you'd probably require the user to provide a sample file where each line has the sample name, fastq1, and fastq2, and you'd read that in to a dict (rather than explicitly defining a dict like we did).\n",
    "\n",
    "Note that input (or params) can be the return value of a function, as in this example.\n",
    "\n",
    "Let's put the two rules together, and then try running them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile snakefile_test2\n",
    "\n",
    "ref = 'ref_genome/chr5_ref.fasta'\n",
    "rawDataPath = 'raw_data/'\n",
    "sampleDict = {\n",
    "    'PatientA':['Patient_A.r1.fastq', 'Patient_A.r2.fastq'],\n",
    "    'PatientB':['Patient_B.r1.fastq', 'Patient_B.r2.fastq']\n",
    "}\n",
    "\n",
    "def get_read1_fastq(wildcards):\n",
    "    (read1, read2) = sampleDict[wildcards.sample]\n",
    "    return rawDataPath + read1\n",
    "\n",
    "def get_read2_fastq(wildcards):\n",
    "    (read1, read2) = sampleDict[wildcards.sample]\n",
    "    return rawDataPath + read2\n",
    "\n",
    "\n",
    "rule index_ref:\n",
    "    '''\n",
    "    This rule creates the indices needed by\n",
    "    bwa in order to use a reference fasta.\n",
    "    '''\n",
    "    input:\n",
    "        ref\n",
    "    output:\n",
    "        ref + '.amb',\n",
    "        ref + '.ann',\n",
    "        ref + '.bwt',\n",
    "        ref + '.pac',\n",
    "        ref + '.sa'\n",
    "    shell:\n",
    "        'bwa index {input}'\n",
    "\n",
    "rule align_fastqs: \n",
    "    input:\n",
    "        ref = ref,\n",
    "        r1 = ref + '.amb',\n",
    "        r2 = ref + '.ann',\n",
    "        r3 = ref + '.bwt',\n",
    "        r4 = ref + '.pac',\n",
    "        r5 = ref + '.sa',\n",
    "        fq1 = get_read1_fastq,\n",
    "        fq2 = get_read2_fastq\n",
    "    output:\n",
    "        'aligned/{sample}.bam'\n",
    "    shell:\n",
    "        'bwa mem {input.ref} {input.fq1} {input.fq2} | samtools sort -o {output}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!snakemake -ps snakefile_test2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oh no!  What went wrong?  We haven't given snakemake a target file.  Let's add a `rule all`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile snakefile_test3\n",
    "\n",
    "ref = 'ref_genome/chr5_ref.fasta'\n",
    "rawDataPath = 'raw_data/'\n",
    "sampleDict = {\n",
    "    'PatientA':['Patient_A.r1.fastq', 'Patient_A.r2.fastq'],\n",
    "    'PatientB':['Patient_B.r1.fastq', 'Patient_B.r2.fastq']\n",
    "}\n",
    "\n",
    "def get_read1_fastq(wildcards):\n",
    "    (read1, read2) = sampleDict[wildcards.sample]\n",
    "    return rawDataPath + read1\n",
    "\n",
    "def get_read2_fastq(wildcards):\n",
    "    (read1, read2) = sampleDict[wildcards.sample]\n",
    "    return rawDataPath + read2\n",
    "\n",
    "\n",
    "rule all:\n",
    "    input:\n",
    "        expand('aligned/{sample}.bam', sample=sampleDict.keys())\n",
    "\n",
    "rule index_ref:\n",
    "    '''\n",
    "    This rule creates the indices needed by\n",
    "    bwa in order to use a reference fasta.\n",
    "    '''\n",
    "    input:\n",
    "        ref\n",
    "    output:\n",
    "        ref + '.amb',\n",
    "        ref + '.ann',\n",
    "        ref + '.bwt',\n",
    "        ref + '.pac',\n",
    "        ref + '.sa'\n",
    "    shell:\n",
    "        'bwa index {input}'\n",
    "\n",
    "rule align_fastqs: \n",
    "    input:\n",
    "        ref = ref,\n",
    "        r1 = ref + '.amb',\n",
    "        r2 = ref + '.ann',\n",
    "        r3 = ref + '.bwt',\n",
    "        r4 = ref + '.pac',\n",
    "        r5 = ref + '.sa',\n",
    "        fq1 = get_read1_fastq,\n",
    "        fq2 = get_read2_fastq\n",
    "    output:\n",
    "        'aligned/{sample}.bam'\n",
    "    shell:\n",
    "        'bwa mem {input.ref} {input.fq1} {input.fq2} | samtools sort -o {output}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now snakemake knows that `{sample}` should expand to PatientA and PatientB, and that the pipeline should end up producing the files `'aligned/{sample}.bam'`.  Let's try running it (this will take a minute or two):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!snakemake -ps snakefile_test3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yay!  A few things of note:\n",
    "- We now have one aligned bam file per patient!\n",
    "- Snakemake automatically created the directory `aligned/` for us.\n",
    "- The stdout also includes a bunch of information from bwa.  There are ways to clean this up, but we're going to skip over that for now.\n",
    "- Snakemake saw that the indexed reference files were already created, so it did not re-run that rule."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Third rule: calling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This third rule will compare our aligned sequences to the reference genome, look at places where there's a discrepancy, and report back those variants.  We'll need to write the rule and update the rule all with the new target file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile snakefile_test4\n",
    "\n",
    "# need a fasta fai for ref\n",
    "\n",
    "ref = 'ref_genome/chr5_ref.fasta'\n",
    "rawDataPath = 'raw_data/'\n",
    "sampleDict = {\n",
    "    'PatientA':['Patient_A.r1.fastq', 'Patient_A.r2.fastq'],\n",
    "    'PatientB':['Patient_B.r1.fastq', 'Patient_B.r2.fastq']\n",
    "}\n",
    "\n",
    "def get_read1_fastq(wildcards):\n",
    "    (read1, read2) = sampleDict[wildcards.sample]\n",
    "    return rawDataPath + read1\n",
    "\n",
    "def get_read2_fastq(wildcards):\n",
    "    (read1, read2) = sampleDict[wildcards.sample]\n",
    "    return rawDataPath + read2\n",
    "\n",
    "\n",
    "rule all:\n",
    "    input:\n",
    "        expand('called/{sample}.vcf', sample=sampleDict.keys())\n",
    "\n",
    "rule index_ref:\n",
    "    '''\n",
    "    This rule creates the indices needed by\n",
    "    bwa in order to use a reference fasta.\n",
    "    '''\n",
    "    input:\n",
    "        ref\n",
    "    output:\n",
    "        ref + '.amb',\n",
    "        ref + '.ann',\n",
    "        ref + '.bwt',\n",
    "        ref + '.pac',\n",
    "        ref + '.sa'\n",
    "    shell:\n",
    "        'bwa index {input}'\n",
    "\n",
    "rule align_fastqs: \n",
    "    input:\n",
    "        ref = ref,\n",
    "        r1 = ref + '.amb',\n",
    "        r2 = ref + '.ann',\n",
    "        r3 = ref + '.bwt',\n",
    "        r4 = ref + '.pac',\n",
    "        r5 = ref + '.sa',\n",
    "        fq1 = get_read1_fastq,\n",
    "        fq2 = get_read2_fastq\n",
    "    output:\n",
    "        'aligned/{sample}.bam'\n",
    "    shell:\n",
    "        'bwa mem {input.ref} {input.fq1} {input.fq2} | samtools sort -o {output}'\n",
    "        \n",
    "rule call_variants:\n",
    "    input:\n",
    "        ref = ref,\n",
    "        bam = 'aligned/{sample}.bam'\n",
    "    output:\n",
    "        'called/{sample}.vcf'\n",
    "    shell:\n",
    "        'gatk HaplotypeCaller -I:{input.bam} -O:{output} -R:{input.ref}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!snakemake -ps snakefile_test4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
